11/26/2021 15:49:36 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 15:49:36 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit1/runs/Nov26_15-49-36_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit1,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit1,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 15:49:41 - INFO - datasets.utils.file_utils - HEAD request to https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/glue/glue.py timed out, retrying... [1.0]
11/26/2021 15:49:47 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue
11/26/2021 15:49:47 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:49:47 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.py
11/26/2021 15:49:47 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/dataset_infos.json to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/dataset_infos.json
11/26/2021 15:49:47 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.json
11/26/2021 15:49:47 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:49:47 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 15:49:47 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:49:47 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 15:49:47 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:00<00:00, 12.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 13.66it/s]
[INFO|configuration_utils.py:588] 2021-11-26 15:49:49,174 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:49:49,176 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 15:49:50,829 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:49:50,830 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:49:56,368 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/slzhang/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:49:56,369 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/slzhang/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:49:56,369 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:49:56,369 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:49:56,369 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/slzhang/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:588] 2021-11-26 15:49:57,196 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:49:57,197 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1340] 2021-11-26 15:49:58,044 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/slzhang/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1597] 2021-11-26 15:49:59,980 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertWithSinglehead: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertWithSinglehead from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertWithSinglehead from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1608] 2021-11-26 15:49:59,980 >> Some weights of BertWithSinglehead were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['s1_classifier.weight', 's1_classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/26/2021 15:50:00 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecb0af5ac5f5f4cf.arrow
11/26/2021 15:50:00 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f66158b4c3938527.arrow
11/26/2021 15:50:01 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8d605fec10ae3523.arrow
11/26/2021 15:50:01 - INFO - __main__ - Sample 5238 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 5238, 'input_ids': [101, 2966, 2852, 12952, 24373, 1113, 7303, 102, 7661, 112, 188, 1285, 131, 3460, 1159, 1113, 7303, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1.600000023841858, 'sentence1': 'Didier Reynders on Syria', 'sentence2': "Obama's day: Prime time on Syria", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:50:01 - INFO - __main__ - Sample 912 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 912, 'input_ids': [101, 138, 1299, 1110, 9374, 1103, 3751, 119, 102, 138, 1299, 1110, 3759, 170, 1610, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0.4000000059604645, 'sentence1': 'A man is cleaning the windows.', 'sentence2': 'A man is driving a car.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:50:01 - INFO - __main__ - Sample 204 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 204, 'input_ids': [101, 138, 1590, 3486, 170, 24181, 12253, 24886, 119, 102, 138, 1590, 1110, 8184, 1146, 170, 24181, 12253, 24886, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 3.25, 'sentence1': 'A woman holds a kangaroo.', 'sentence2': 'A woman is picking up a kangaroo.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:50:03 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue
11/26/2021 15:50:03 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981
11/26/2021 15:50:03 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.py
11/26/2021 15:50:03 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/dataset_infos.json
11/26/2021 15:50:03 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.json
[INFO|trainer.py:541] 2021-11-26 15:50:08,917 >> The following columns in the training set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: idx, sentence1, sentence2.
[INFO|trainer.py:1196] 2021-11-26 15:50:08,936 >> ***** Running training *****
[INFO|trainer.py:1197] 2021-11-26 15:50:08,936 >>   Num examples = 5749
[INFO|trainer.py:1198] 2021-11-26 15:50:08,936 >>   Num Epochs = 5
[INFO|trainer.py:1199] 2021-11-26 15:50:08,936 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2021-11-26 15:50:08,936 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:1201] 2021-11-26 15:50:08,936 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2021-11-26 15:50:08,936 >>   Total optimization steps = 225
[INFO|integrations.py:501] 2021-11-26 15:50:08,970 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: zsl (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.22
wandb: Syncing run ./models/stsb/exit1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zsl/huggingface
wandb: üöÄ View run at https://wandb.ai/zsl/huggingface/runs/2dcbdmt4
wandb: Run data is saved locally in /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155010-2dcbdmt4
wandb: Run `wandb offline` to turn off syncing.
  0%|          | 0/225 [00:00<?, ?it/s]/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/225 [00:11<41:36, 11.14s/it]  1%|‚ñè         | 3/225 [00:11<10:54,  2.95s/it]  2%|‚ñè         | 5/225 [00:11<05:24,  1.47s/it]  3%|‚ñé         | 7/225 [00:11<03:11,  1.14it/s]  4%|‚ñç         | 9/225 [00:11<02:04,  1.73it/s]  5%|‚ñç         | 11/225 [00:11<01:26,  2.49it/s]  6%|‚ñå         | 13/225 [00:12<01:02,  3.39it/s]  7%|‚ñã         | 15/225 [00:12<00:47,  4.41it/s]  8%|‚ñä         | 17/225 [00:12<00:37,  5.56it/s]  8%|‚ñä         | 19/225 [00:12<00:30,  6.68it/s]  9%|‚ñâ         | 21/225 [00:12<00:26,  7.81it/s] 10%|‚ñà         | 23/225 [00:12<00:22,  8.85it/s] 11%|‚ñà         | 25/225 [00:13<00:20,  9.75it/s] 12%|‚ñà‚ñè        | 27/225 [00:13<00:18, 10.58it/s] 13%|‚ñà‚ñé        | 29/225 [00:13<00:17, 11.32it/s] 14%|‚ñà‚ñç        | 31/225 [00:13<00:16, 11.87it/s] 15%|‚ñà‚ñç        | 33/225 [00:13<00:16, 11.99it/s] 16%|‚ñà‚ñå        | 35/225 [00:13<00:15, 12.08it/s] 16%|‚ñà‚ñã        | 37/225 [00:13<00:15, 12.19it/s] 17%|‚ñà‚ñã        | 39/225 [00:14<00:15, 12.27it/s] 18%|‚ñà‚ñä        | 41/225 [00:14<00:16, 11.35it/s] 19%|‚ñà‚ñâ        | 43/225 [00:14<00:20,  9.02it/s] 20%|‚ñà‚ñà        | 45/225 [00:14<00:21,  8.54it/s] 20%|‚ñà‚ñà        | 46/225 [00:15<00:22,  8.06it/s] 21%|‚ñà‚ñà        | 47/225 [00:15<00:23,  7.50it/s] 21%|‚ñà‚ñà‚ñè       | 48/225 [00:15<00:26,  6.78it/s] 22%|‚ñà‚ñà‚ñè       | 49/225 [00:15<00:26,  6.76it/s] 22%|‚ñà‚ñà‚ñè       | 50/225 [00:15<00:26,  6.56it/s] 23%|‚ñà‚ñà‚ñé       | 51/225 [00:15<00:25,  6.92it/s] 23%|‚ñà‚ñà‚ñé       | 52/225 [00:16<00:25,  6.91it/s] 24%|‚ñà‚ñà‚ñé       | 53/225 [00:16<00:25,  6.77it/s] 24%|‚ñà‚ñà‚ñç       | 54/225 [00:16<00:27,  6.23it/s] 24%|‚ñà‚ñà‚ñç       | 55/225 [00:16<00:24,  6.95it/s] 25%|‚ñà‚ñà‚ñå       | 57/225 [00:16<00:19,  8.79it/s] 26%|‚ñà‚ñà‚ñå       | 59/225 [00:16<00:16, 10.00it/s] 27%|‚ñà‚ñà‚ñã       | 61/225 [00:16<00:15, 10.77it/s] 28%|‚ñà‚ñà‚ñä       | 63/225 [00:17<00:14, 11.38it/s] 29%|‚ñà‚ñà‚ñâ       | 65/225 [00:17<00:13, 11.65it/s] 30%|‚ñà‚ñà‚ñâ       | 67/225 [00:17<00:13, 11.89it/s] 31%|‚ñà‚ñà‚ñà       | 69/225 [00:17<00:12, 12.36it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/225 [00:17<00:12, 12.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 73/225 [00:17<00:12, 12.52it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 75/225 [00:18<00:11, 12.60it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 77/225 [00:18<00:11, 12.74it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 79/225 [00:18<00:11, 12.74it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 81/225 [00:18<00:11, 12.64it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/225 [00:18<00:11, 12.88it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/225 [00:18<00:10, 12.79it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 87/225 [00:18<00:10, 12.82it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/225 [00:19<00:10, 12.97it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 91/225 [00:19<00:10, 12.90it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/225 [00:19<00:10, 13.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/225 [00:19<00:10, 12.55it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/225 [00:19<00:10, 12.76it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/225 [00:19<00:09, 12.71it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 101/225 [00:20<00:09, 12.82it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 103/225 [00:20<00:09, 12.72it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/225 [00:20<00:09, 12.74it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/225 [00:20<00:09, 12.64it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/225 [00:20<00:09, 12.64it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/225 [00:20<00:09, 12.52it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/225 [00:21<00:08, 12.50it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 115/225 [00:21<00:08, 12.53it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 117/225 [00:21<00:08, 12.58it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/225 [00:21<00:08, 12.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/225 [00:21<00:08, 12.53it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 123/225 [00:21<00:08, 12.36it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/225 [00:22<00:08, 12.36it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/225 [00:22<00:07, 12.34it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 129/225 [00:22<00:07, 12.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/225 [00:22<00:07, 12.27it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/225 [00:22<00:07, 12.31it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/225 [00:22<00:07, 12.33it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 137/225 [00:22<00:07, 12.30it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 139/225 [00:23<00:07, 12.27it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/225 [00:23<00:06, 12.37it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 143/225 [00:23<00:06, 12.43it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 145/225 [00:23<00:06, 12.55it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/225 [00:23<00:06, 12.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 149/225 [00:23<00:05, 13.01it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 151/225 [00:24<00:05, 13.05it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 153/225 [00:24<00:05, 13.19it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/225 [00:24<00:05, 13.30it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 157/225 [00:24<00:05, 13.35it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 159/225 [00:24<00:05, 13.17it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 161/225 [00:24<00:04, 13.24it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 163/225 [00:24<00:04, 13.08it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 165/225 [00:25<00:04, 12.97it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/225 [00:25<00:04, 12.85it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/225 [00:25<00:04, 12.74it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 171/225 [00:25<00:04, 12.61it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 173/225 [00:25<00:04, 12.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/225 [00:25<00:04, 12.39it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 177/225 [00:26<00:03, 12.37it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/225 [00:26<00:03, 12.43it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/225 [00:26<00:03, 12.46it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/225 [00:26<00:03, 12.43it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 185/225 [00:26<00:03, 12.35it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/225 [00:26<00:03, 12.32it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/225 [00:27<00:02, 12.38it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 191/225 [00:27<00:02, 12.71it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 193/225 [00:27<00:03, 10.19it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/225 [00:27<00:03,  8.73it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 196/225 [00:27<00:03,  8.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/225 [00:28<00:03,  7.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/225 [00:28<00:03,  7.09it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 199/225 [00:28<00:03,  6.50it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/225 [00:28<00:03,  6.28it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 201/225 [00:28<00:03,  6.43it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 202/225 [00:28<00:03,  6.76it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/225 [00:29<00:03,  6.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/225 [00:29<00:03,  6.62it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 205/225 [00:29<00:02,  6.77it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/225 [00:29<00:02,  8.56it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/225 [00:29<00:01,  9.82it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/225 [00:29<00:01, 10.67it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 213/225 [00:30<00:01, 11.29it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 215/225 [00:30<00:00, 11.72it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/225 [00:30<00:00,  8.88it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 219/225 [00:30<00:00,  9.99it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/225 [00:30<00:00, 10.69it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/225 [00:31<00:00, 11.24it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [00:31<00:00, 11.71it/s][INFO|trainer.py:1409] 2021-11-26 15:50:45,174 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 36.2376, 'train_samples_per_second': 793.236, 'train_steps_per_second': 6.209, 'train_loss': 7.049262152777778, 'epoch': 5.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [00:31<00:00, 11.71it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [00:31<00:00,  7.19it/s]
[INFO|trainer.py:1995] 2021-11-26 15:50:45,292 >> Saving model checkpoint to ./models/stsb/exit1
[INFO|configuration_utils.py:417] 2021-11-26 15:50:45,297 >> Configuration saved in ./models/stsb/exit1/config.json
[INFO|modeling_utils.py:1058] 2021-11-26 15:50:46,572 >> Model weights saved in ./models/stsb/exit1/pytorch_model.bin
[INFO|tokenization_utils_base.py:2034] 2021-11-26 15:50:46,576 >> tokenizer config file saved in ./models/stsb/exit1/tokenizer_config.json
[INFO|tokenization_utils_base.py:2040] 2021-11-26 15:50:46,579 >> Special tokens file saved in ./models/stsb/exit1/special_tokens_map.json
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     7.0493
  train_runtime            = 0:00:36.23
  train_samples            =       5749
  train_samples_per_second =    793.236
  train_steps_per_second   =      6.209

11/26/2021 15:50:46 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:541] 2021-11-26 15:50:46,731 >> The following columns in the evaluation set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: idx, sentence1, sentence2.
[INFO|trainer.py:2243] 2021-11-26 15:50:46,735 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2021-11-26 15:50:46,735 >>   Num examples = 1500
[INFO|trainer.py:2248] 2021-11-26 15:50:46,735 >>   Batch size = 32
  0%|          | 0/47 [00:00<?, ?it/s] 11%|‚ñà         | 5/47 [00:00<00:00, 42.37it/s] 21%|‚ñà‚ñà‚ñè       | 10/47 [00:00<00:01, 36.33it/s] 30%|‚ñà‚ñà‚ñâ       | 14/47 [00:00<00:00, 35.01it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 18/47 [00:00<00:00, 33.76it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 22/47 [00:00<00:00, 33.31it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 26/47 [00:00<00:00, 32.71it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 30/47 [00:00<00:00, 32.17it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 34/47 [00:01<00:00, 31.70it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 38/47 [00:01<00:00, 31.83it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 42/47 [00:01<00:00, 31.90it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 46/47 [00:01<00:00, 31.87it/s]11/26/2021 15:50:49 - INFO - datasets.metric - Removing /home/slzhang/.cache/huggingface/metrics/glue/stsb/default_experiment-1-0.arrow
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:02<00:00, 16.92it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_combined_score     =     0.0802
  eval_loss               =     4.7354
  eval_pearson            =     0.0818
  eval_runtime            = 0:00:02.78
  eval_samples            =       1500
  eval_samples_per_second =    538.554
  eval_spearmanr          =     0.0786
  eval_steps_per_second   =     16.875
wandb: Waiting for W&B process to finish, PID 3568475
wandb: Program ended successfully.
wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.03MB of 0.03MB uploaded (0.00MB deduped)wandb: | 0.03MB of 0.03MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155010-2dcbdmt4/logs/debug.log
wandb: Find internal logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155010-2dcbdmt4/logs/debug-internal.log
wandb: Run summary:
wandb:              train/train_runtime 36.2376
wandb:   train/train_samples_per_second 793.236
wandb:     train/train_steps_per_second 6.209
wandb:                 train/total_flos 169561885367040.0
wandb:                 train/train_loss 7.04926
wandb:                      train/epoch 5.0
wandb:                train/global_step 225
wandb:                         _runtime 39
wandb:                       _timestamp 1637913049
wandb:                            _step 1
wandb:                        eval/loss 4.73539
wandb:                     eval/pearson 0.08182
wandb:                   eval/spearmanr 0.07857
wandb:              eval/combined_score 0.08019
wandb:                     eval/runtime 2.7852
wandb:          eval/samples_per_second 538.554
wandb:            eval/steps_per_second 16.875
wandb: Run history:
wandb:              train/train_runtime ‚ñÅ
wandb:   train/train_samples_per_second ‚ñÅ
wandb:     train/train_steps_per_second ‚ñÅ
wandb:                 train/total_flos ‚ñÅ
wandb:                 train/train_loss ‚ñÅ
wandb:                      train/epoch ‚ñÅ‚ñÅ
wandb:                train/global_step ‚ñÅ‚ñÅ
wandb:                         _runtime ‚ñÅ‚ñà
wandb:                       _timestamp ‚ñÅ‚ñà
wandb:                            _step ‚ñÅ‚ñà
wandb:                        eval/loss ‚ñÅ
wandb:                     eval/pearson ‚ñÅ
wandb:                   eval/spearmanr ‚ñÅ
wandb:              eval/combined_score ‚ñÅ
wandb:                     eval/runtime ‚ñÅ
wandb:          eval/samples_per_second ‚ñÅ
wandb:            eval/steps_per_second ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ./models/stsb/exit1: https://wandb.ai/zsl/huggingface/runs/2dcbdmt4

11/26/2021 15:51:02 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 15:51:02 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit2/runs/Nov26_15-51-02_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit2,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit2,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 15:51:04 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue
11/26/2021 15:51:04 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:51:04 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.py
11/26/2021 15:51:04 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/dataset_infos.json to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/dataset_infos.json
11/26/2021 15:51:04 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.json
11/26/2021 15:51:04 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:51:04 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 15:51:04 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:51:04 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 15:51:04 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 300.84it/s]
[INFO|configuration_utils.py:588] 2021-11-26 15:51:05,681 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:51:05,683 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 15:51:07,495 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:51:07,497 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:51:12,503 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/slzhang/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:51:12,504 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/slzhang/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:51:12,505 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:51:12,505 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:51:12,505 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/slzhang/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:588] 2021-11-26 15:51:13,333 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:51:13,335 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1340] 2021-11-26 15:51:14,201 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/slzhang/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1597] 2021-11-26 15:51:16,206 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertWithSinglehead: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertWithSinglehead from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertWithSinglehead from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1608] 2021-11-26 15:51:16,207 >> Some weights of BertWithSinglehead were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['s1_classifier.bias', 's1_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/26/2021 15:51:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecb0af5ac5f5f4cf.arrow
11/26/2021 15:51:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f66158b4c3938527.arrow
11/26/2021 15:51:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8d605fec10ae3523.arrow
11/26/2021 15:51:17 - INFO - __main__ - Sample 5238 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 5238, 'input_ids': [101, 2966, 2852, 12952, 24373, 1113, 7303, 102, 7661, 112, 188, 1285, 131, 3460, 1159, 1113, 7303, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1.600000023841858, 'sentence1': 'Didier Reynders on Syria', 'sentence2': "Obama's day: Prime time on Syria", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:51:17 - INFO - __main__ - Sample 912 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 912, 'input_ids': [101, 138, 1299, 1110, 9374, 1103, 3751, 119, 102, 138, 1299, 1110, 3759, 170, 1610, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0.4000000059604645, 'sentence1': 'A man is cleaning the windows.', 'sentence2': 'A man is driving a car.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:51:17 - INFO - __main__ - Sample 204 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 204, 'input_ids': [101, 138, 1590, 3486, 170, 24181, 12253, 24886, 119, 102, 138, 1590, 1110, 8184, 1146, 170, 24181, 12253, 24886, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 3.25, 'sentence1': 'A woman holds a kangaroo.', 'sentence2': 'A woman is picking up a kangaroo.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:51:19 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue
11/26/2021 15:51:19 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981
11/26/2021 15:51:19 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.py
11/26/2021 15:51:19 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/dataset_infos.json
11/26/2021 15:51:19 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.json
[INFO|trainer.py:541] 2021-11-26 15:51:25,602 >> The following columns in the training set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, sentence2, idx.
[INFO|trainer.py:1196] 2021-11-26 15:51:25,624 >> ***** Running training *****
[INFO|trainer.py:1197] 2021-11-26 15:51:25,624 >>   Num examples = 5749
[INFO|trainer.py:1198] 2021-11-26 15:51:25,624 >>   Num Epochs = 5
[INFO|trainer.py:1199] 2021-11-26 15:51:25,624 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2021-11-26 15:51:25,624 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:1201] 2021-11-26 15:51:25,624 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2021-11-26 15:51:25,624 >>   Total optimization steps = 225
[INFO|integrations.py:501] 2021-11-26 15:51:25,662 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: zsl (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.22
wandb: Syncing run ./models/stsb/exit2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zsl/huggingface
wandb: üöÄ View run at https://wandb.ai/zsl/huggingface/runs/1sfgl6b7
wandb: Run data is saved locally in /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155127-1sfgl6b7
wandb: Run `wandb offline` to turn off syncing.
  0%|          | 0/225 [00:00<?, ?it/s]/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/225 [00:17<1:04:41, 17.33s/it]  1%|          | 2/225 [00:17<26:59,  7.26s/it]    1%|‚ñè         | 3/225 [00:17<14:54,  4.03s/it]  2%|‚ñè         | 4/225 [00:17<09:08,  2.48s/it]  2%|‚ñè         | 5/225 [00:17<05:57,  1.63s/it]  3%|‚ñé         | 6/225 [00:18<04:10,  1.14s/it]  3%|‚ñé         | 7/225 [00:18<03:05,  1.17it/s]  4%|‚ñé         | 8/225 [00:18<02:14,  1.62it/s]  4%|‚ñç         | 9/225 [00:18<01:39,  2.16it/s]  4%|‚ñç         | 10/225 [00:18<01:15,  2.83it/s]  5%|‚ñç         | 11/225 [00:18<01:03,  3.38it/s]  5%|‚ñå         | 12/225 [00:19<00:58,  3.63it/s]  6%|‚ñå         | 13/225 [00:19<00:48,  4.36it/s]  6%|‚ñå         | 14/225 [00:19<00:42,  5.01it/s]  7%|‚ñã         | 15/225 [00:19<00:40,  5.19it/s]  7%|‚ñã         | 16/225 [00:19<00:40,  5.20it/s]  8%|‚ñä         | 17/225 [00:19<00:34,  5.96it/s]  8%|‚ñä         | 18/225 [00:20<00:43,  4.78it/s]  8%|‚ñä         | 19/225 [00:20<00:54,  3.79it/s]  9%|‚ñâ         | 20/225 [00:20<00:52,  3.93it/s]  9%|‚ñâ         | 21/225 [00:20<00:47,  4.27it/s] 10%|‚ñâ         | 22/225 [00:21<00:46,  4.41it/s] 10%|‚ñà         | 23/225 [00:21<00:48,  4.20it/s] 11%|‚ñà         | 24/225 [00:21<00:55,  3.62it/s] 11%|‚ñà         | 25/225 [00:22<00:53,  3.74it/s] 12%|‚ñà‚ñè        | 26/225 [00:22<00:51,  3.90it/s] 12%|‚ñà‚ñè        | 27/225 [00:22<00:51,  3.85it/s] 12%|‚ñà‚ñè        | 28/225 [00:22<00:52,  3.72it/s] 13%|‚ñà‚ñé        | 29/225 [00:23<00:47,  4.14it/s] 13%|‚ñà‚ñé        | 30/225 [00:23<00:39,  4.97it/s] 14%|‚ñà‚ñç        | 31/225 [00:23<00:33,  5.79it/s] 14%|‚ñà‚ñç        | 32/225 [00:23<00:35,  5.41it/s] 15%|‚ñà‚ñç        | 33/225 [00:23<00:35,  5.42it/s] 15%|‚ñà‚ñå        | 34/225 [00:23<00:30,  6.20it/s] 16%|‚ñà‚ñå        | 35/225 [00:23<00:27,  6.89it/s] 16%|‚ñà‚ñå        | 36/225 [00:24<00:30,  6.17it/s] 16%|‚ñà‚ñã        | 37/225 [00:24<00:31,  5.98it/s] 17%|‚ñà‚ñã        | 38/225 [00:24<00:28,  6.66it/s] 17%|‚ñà‚ñã        | 39/225 [00:24<00:25,  7.24it/s] 18%|‚ñà‚ñä        | 40/225 [00:24<00:28,  6.48it/s] 18%|‚ñà‚ñä        | 41/225 [00:24<00:31,  5.82it/s] 19%|‚ñà‚ñä        | 42/225 [00:25<00:28,  6.32it/s] 19%|‚ñà‚ñâ        | 43/225 [00:25<00:27,  6.68it/s] 20%|‚ñà‚ñâ        | 44/225 [00:25<00:28,  6.43it/s] 20%|‚ñà‚ñà        | 45/225 [00:25<00:28,  6.35it/s] 20%|‚ñà‚ñà        | 46/225 [00:25<00:30,  5.83it/s] 21%|‚ñà‚ñà        | 47/225 [00:25<00:27,  6.56it/s] 21%|‚ñà‚ñà‚ñè       | 48/225 [00:25<00:24,  7.12it/s] 22%|‚ñà‚ñà‚ñè       | 49/225 [00:26<00:26,  6.73it/s] 22%|‚ñà‚ñà‚ñè       | 50/225 [00:26<00:30,  5.81it/s] 23%|‚ñà‚ñà‚ñé       | 51/225 [00:26<00:27,  6.32it/s] 23%|‚ñà‚ñà‚ñé       | 52/225 [00:26<00:25,  6.89it/s] 24%|‚ñà‚ñà‚ñé       | 53/225 [00:26<00:26,  6.62it/s] 24%|‚ñà‚ñà‚ñç       | 54/225 [00:26<00:28,  6.08it/s] 24%|‚ñà‚ñà‚ñç       | 55/225 [00:27<00:25,  6.55it/s] 25%|‚ñà‚ñà‚ñç       | 56/225 [00:27<00:23,  7.09it/s] 25%|‚ñà‚ñà‚ñå       | 57/225 [00:27<00:30,  5.56it/s] 26%|‚ñà‚ñà‚ñå       | 58/225 [00:27<00:30,  5.43it/s] 26%|‚ñà‚ñà‚ñå       | 59/225 [00:27<00:27,  6.02it/s] 27%|‚ñà‚ñà‚ñã       | 60/225 [00:27<00:25,  6.52it/s] 27%|‚ñà‚ñà‚ñã       | 61/225 [00:28<00:28,  5.68it/s] 28%|‚ñà‚ñà‚ñä       | 62/225 [00:28<00:27,  5.84it/s] 28%|‚ñà‚ñà‚ñä       | 63/225 [00:28<00:25,  6.42it/s] 28%|‚ñà‚ñà‚ñä       | 64/225 [00:28<00:23,  6.98it/s] 29%|‚ñà‚ñà‚ñâ       | 65/225 [00:28<00:23,  6.69it/s] 29%|‚ñà‚ñà‚ñâ       | 66/225 [00:28<00:27,  5.84it/s] 30%|‚ñà‚ñà‚ñâ       | 67/225 [00:28<00:24,  6.37it/s] 30%|‚ñà‚ñà‚ñà       | 68/225 [00:29<00:22,  6.92it/s] 31%|‚ñà‚ñà‚ñà       | 69/225 [00:29<00:24,  6.24it/s] 31%|‚ñà‚ñà‚ñà       | 70/225 [00:29<00:26,  5.81it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/225 [00:29<00:23,  6.49it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 72/225 [00:29<00:21,  7.07it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 73/225 [00:29<00:27,  5.55it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 74/225 [00:30<00:26,  5.71it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 75/225 [00:30<00:23,  6.47it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 76/225 [00:30<00:20,  7.12it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 77/225 [00:30<00:19,  7.61it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 78/225 [00:30<00:22,  6.60it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 79/225 [00:30<00:26,  5.43it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 80/225 [00:31<00:23,  6.19it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 81/225 [00:31<00:21,  6.84it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 82/225 [00:31<00:19,  7.53it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/225 [00:31<00:24,  5.91it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 84/225 [00:31<00:26,  5.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/225 [00:31<00:23,  5.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 86/225 [00:31<00:20,  6.65it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 87/225 [00:32<00:22,  6.05it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 88/225 [00:32<00:24,  5.54it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/225 [00:32<00:22,  6.07it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 90/225 [00:32<00:20,  6.68it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 91/225 [00:32<00:18,  7.18it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 92/225 [00:32<00:18,  7.26it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/225 [00:33<00:21,  6.12it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/225 [00:33<00:19,  6.72it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/225 [00:33<00:18,  7.20it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/225 [00:33<00:16,  7.76it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/225 [00:33<00:15,  8.19it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 98/225 [00:33<00:17,  7.36it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/225 [00:33<00:20,  6.05it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 100/225 [00:34<00:22,  5.50it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 101/225 [00:34<00:24,  4.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/225 [00:34<00:27,  4.40it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 103/225 [00:35<00:33,  3.61it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 104/225 [00:35<00:32,  3.74it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/225 [00:35<00:29,  4.00it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 106/225 [00:35<00:30,  3.90it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/225 [00:36<00:32,  3.66it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/225 [00:36<00:33,  3.45it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/225 [00:36<00:34,  3.36it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/225 [00:36<00:28,  3.99it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/225 [00:37<00:28,  4.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 112/225 [00:37<00:27,  4.15it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 114/225 [00:37<00:19,  5.79it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 115/225 [00:37<00:18,  5.79it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/225 [00:37<00:19,  5.45it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 118/225 [00:38<00:16,  6.60it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/225 [00:38<00:15,  6.86it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 120/225 [00:38<00:14,  7.32it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/225 [00:38<00:13,  7.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/225 [00:38<00:12,  7.92it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 123/225 [00:38<00:12,  8.14it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/225 [00:38<00:12,  7.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/225 [00:38<00:12,  8.01it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 126/225 [00:39<00:11,  8.42it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/225 [00:39<00:12,  8.16it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 128/225 [00:39<00:12,  7.86it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 129/225 [00:39<00:12,  7.95it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/225 [00:39<00:11,  8.02it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/225 [00:39<00:12,  7.49it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 132/225 [00:39<00:11,  8.03it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/225 [00:39<00:10,  8.48it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 134/225 [00:40<00:10,  8.74it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 136/225 [00:40<00:09,  9.48it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/225 [00:40<00:08,  9.75it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 140/225 [00:40<00:08,  9.93it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 142/225 [00:40<00:08, 10.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/225 [00:41<00:08,  9.61it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 146/225 [00:41<00:08,  9.80it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 148/225 [00:41<00:07,  9.95it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 150/225 [00:41<00:07, 10.04it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/225 [00:41<00:07, 10.14it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 154/225 [00:42<00:06, 10.15it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 156/225 [00:42<00:06, 10.13it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/225 [00:42<00:06, 10.08it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 160/225 [00:42<00:06, 10.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 162/225 [00:42<00:06, 10.12it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 164/225 [00:43<00:06, 10.12it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/225 [00:43<00:06,  9.80it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/225 [00:43<00:06,  9.65it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 168/225 [00:43<00:06,  9.25it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/225 [00:43<00:06,  8.85it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 170/225 [00:43<00:06,  8.92it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 171/225 [00:43<00:06,  8.74it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/225 [00:43<00:05,  8.87it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 173/225 [00:44<00:05,  8.94it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 174/225 [00:44<00:05,  9.03it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/225 [00:44<00:05,  9.08it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 176/225 [00:44<00:05,  9.14it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 177/225 [00:44<00:05,  9.15it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 178/225 [00:44<00:05,  9.18it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/225 [00:44<00:05,  8.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/225 [00:44<00:05,  8.29it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/225 [00:44<00:05,  8.49it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 182/225 [00:45<00:05,  8.59it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/225 [00:45<00:04,  8.63it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 184/225 [00:45<00:04,  8.74it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 185/225 [00:45<00:04,  8.91it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 186/225 [00:45<00:04,  8.71it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/225 [00:45<00:04,  8.35it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 188/225 [00:45<00:04,  8.50it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/225 [00:45<00:04,  8.61it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 190/225 [00:46<00:03,  8.83it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 191/225 [00:46<00:03,  8.77it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 192/225 [00:46<00:04,  7.94it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 193/225 [00:46<00:04,  6.93it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 194/225 [00:46<00:04,  7.42it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/225 [00:46<00:03,  7.83it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 196/225 [00:46<00:04,  6.99it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/225 [00:47<00:04,  5.61it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/225 [00:47<00:04,  6.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 199/225 [00:47<00:03,  6.95it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/225 [00:47<00:04,  6.03it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 201/225 [00:47<00:04,  5.12it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 202/225 [00:48<00:04,  4.64it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/225 [00:48<00:04,  4.44it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/225 [00:48<00:05,  3.81it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 205/225 [00:49<00:05,  3.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 206/225 [00:49<00:05,  3.78it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/225 [00:49<00:04,  4.07it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 208/225 [00:49<00:04,  3.73it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/225 [00:50<00:04,  3.26it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 210/225 [00:50<00:04,  3.42it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/225 [00:50<00:03,  3.56it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 212/225 [00:50<00:03,  3.98it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 213/225 [00:50<00:02,  4.80it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 214/225 [00:51<00:02,  5.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 215/225 [00:51<00:01,  5.13it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 216/225 [00:51<00:01,  5.98it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/225 [00:51<00:01,  6.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 218/225 [00:51<00:01,  6.16it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 219/225 [00:51<00:00,  6.89it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 220/225 [00:52<00:00,  6.35it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/225 [00:52<00:00,  6.18it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 222/225 [00:52<00:00,  6.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/225 [00:52<00:00,  7.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 224/225 [00:52<00:00,  6.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [00:52<00:00,  6.06it/s][INFO|trainer.py:1409] 2021-11-26 15:52:25,265 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 59.6414, 'train_samples_per_second': 481.964, 'train_steps_per_second': 3.773, 'train_loss': 7.496421440972222, 'epoch': 5.0}100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [00:52<00:00,  6.06it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [00:52<00:00,  4.25it/s]
[INFO|trainer.py:1995] 2021-11-26 15:52:25,387 >> Saving model checkpoint to ./models/stsb/exit2
[INFO|configuration_utils.py:417] 2021-11-26 15:52:25,393 >> Configuration saved in ./models/stsb/exit2/config.json
[INFO|modeling_utils.py:1058] 2021-11-26 15:52:29,133 >> Model weights saved in ./models/stsb/exit2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2034] 2021-11-26 15:52:29,141 >> tokenizer config file saved in ./models/stsb/exit2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2040] 2021-11-26 15:52:29,147 >> Special tokens file saved in ./models/stsb/exit2/special_tokens_map.json
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     7.4964
  train_runtime            = 0:00:59.64
  train_samples            =       5749
  train_samples_per_second =    481.964
  train_steps_per_second   =      3.773

11/26/2021 15:52:29 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:541] 2021-11-26 15:52:29,335 >> The following columns in the evaluation set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, sentence2, idx.
[INFO|trainer.py:2243] 2021-11-26 15:52:29,342 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2021-11-26 15:52:29,342 >>   Num examples = 1500
[INFO|trainer.py:2248] 2021-11-26 15:52:29,342 >>   Batch size = 32
  0%|          | 0/47 [00:00<?, ?it/s]  9%|‚ñä         | 4/47 [00:00<00:01, 31.19it/s] 17%|‚ñà‚ñã        | 8/47 [00:00<00:01, 24.89it/s] 23%|‚ñà‚ñà‚ñé       | 11/47 [00:00<00:01, 24.44it/s] 30%|‚ñà‚ñà‚ñâ       | 14/47 [00:00<00:01, 24.54it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 17/47 [00:00<00:01, 24.31it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 20/47 [00:00<00:01, 18.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 23/47 [00:01<00:01, 16.79it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 26/47 [00:01<00:01, 18.66it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 29/47 [00:01<00:00, 19.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 32/47 [00:01<00:01, 14.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 35/47 [00:01<00:00, 16.61it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 38/47 [00:01<00:00, 18.05it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 41/47 [00:02<00:00, 18.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 44/47 [00:02<00:00, 15.18it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:02<00:00, 16.78it/s]11/26/2021 15:52:31 - INFO - datasets.metric - Removing /home/slzhang/.cache/huggingface/metrics/glue/stsb/default_experiment-1-0.arrow
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:02<00:00, 18.06it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_combined_score     =     0.0438
  eval_loss               =     4.9003
  eval_pearson            =     0.0454
  eval_runtime            = 0:00:02.62
  eval_samples            =       1500
  eval_samples_per_second =    570.361
  eval_spearmanr          =     0.0423
  eval_steps_per_second   =     17.871
wandb: Waiting for W&B process to finish, PID 3570722
wandb: Program ended successfully.
wandb: - 0.02MB of 0.02MB uploaded (0.00MB deduped)wandb: \ 0.04MB of 0.04MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155127-1sfgl6b7/logs/debug.log
wandb: Find internal logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155127-1sfgl6b7/logs/debug-internal.log
wandb: Run summary:
wandb:              train/train_runtime 59.6414
wandb:   train/train_samples_per_second 481.964
wandb:     train/train_steps_per_second 3.773
wandb:                 train/total_flos 326034881698560.0
wandb:                 train/train_loss 7.49642
wandb:                      train/epoch 5.0
wandb:                train/global_step 225
wandb:                         _runtime 64
wandb:                       _timestamp 1637913151
wandb:                            _step 1
wandb:                        eval/loss 4.90027
wandb:                     eval/pearson 0.04538
wandb:                   eval/spearmanr 0.04232
wandb:              eval/combined_score 0.04385
wandb:                     eval/runtime 2.6299
wandb:          eval/samples_per_second 570.361
wandb:            eval/steps_per_second 17.871
wandb: Run history:
wandb:              train/train_runtime ‚ñÅ
wandb:   train/train_samples_per_second ‚ñÅ
wandb:     train/train_steps_per_second ‚ñÅ
wandb:                 train/total_flos ‚ñÅ
wandb:                 train/train_loss ‚ñÅ
wandb:                      train/epoch ‚ñÅ‚ñÅ
wandb:                train/global_step ‚ñÅ‚ñÅ
wandb:                         _runtime ‚ñÅ‚ñà
wandb:                       _timestamp ‚ñÅ‚ñà
wandb:                            _step ‚ñÅ‚ñà
wandb:                        eval/loss ‚ñÅ
wandb:                     eval/pearson ‚ñÅ
wandb:                   eval/spearmanr ‚ñÅ
wandb:              eval/combined_score ‚ñÅ
wandb:                     eval/runtime ‚ñÅ
wandb:          eval/samples_per_second ‚ñÅ
wandb:            eval/steps_per_second ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ./models/stsb/exit2: https://wandb.ai/zsl/huggingface/runs/1sfgl6b7

11/26/2021 15:52:45 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 15:52:45 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit3/runs/Nov26_15-52-45_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit3,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit3,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 15:52:48 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue
11/26/2021 15:52:48 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:52:48 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.py
11/26/2021 15:52:48 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/dataset_infos.json to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/dataset_infos.json
11/26/2021 15:52:48 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.json
11/26/2021 15:52:48 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:52:48 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 15:52:48 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:52:48 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 15:52:48 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 227.38it/s]
[INFO|configuration_utils.py:588] 2021-11-26 15:52:49,263 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:52:49,265 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 15:52:51,135 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:52:51,136 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:52:58,222 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/slzhang/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:52:58,222 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/slzhang/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:52:58,222 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:52:58,223 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:52:58,223 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/slzhang/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:588] 2021-11-26 15:52:59,160 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:52:59,163 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1340] 2021-11-26 15:53:00,017 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/slzhang/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1597] 2021-11-26 15:53:02,237 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertWithSinglehead: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertWithSinglehead from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertWithSinglehead from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1608] 2021-11-26 15:53:02,238 >> Some weights of BertWithSinglehead were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['s1_classifier.weight', 's1_classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/26/2021 15:53:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecb0af5ac5f5f4cf.arrow
11/26/2021 15:53:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f66158b4c3938527.arrow
11/26/2021 15:53:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8d605fec10ae3523.arrow
11/26/2021 15:53:03 - INFO - __main__ - Sample 5238 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 5238, 'input_ids': [101, 2966, 2852, 12952, 24373, 1113, 7303, 102, 7661, 112, 188, 1285, 131, 3460, 1159, 1113, 7303, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1.600000023841858, 'sentence1': 'Didier Reynders on Syria', 'sentence2': "Obama's day: Prime time on Syria", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:53:03 - INFO - __main__ - Sample 912 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 912, 'input_ids': [101, 138, 1299, 1110, 9374, 1103, 3751, 119, 102, 138, 1299, 1110, 3759, 170, 1610, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0.4000000059604645, 'sentence1': 'A man is cleaning the windows.', 'sentence2': 'A man is driving a car.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:53:03 - INFO - __main__ - Sample 204 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 204, 'input_ids': [101, 138, 1590, 3486, 170, 24181, 12253, 24886, 119, 102, 138, 1590, 1110, 8184, 1146, 170, 24181, 12253, 24886, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 3.25, 'sentence1': 'A woman holds a kangaroo.', 'sentence2': 'A woman is picking up a kangaroo.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:53:05 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue
11/26/2021 15:53:05 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981
11/26/2021 15:53:05 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.py
11/26/2021 15:53:05 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/dataset_infos.json
11/26/2021 15:53:05 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.json
[INFO|trainer.py:541] 2021-11-26 15:53:12,214 >> The following columns in the training set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: idx, sentence1, sentence2.
[INFO|trainer.py:1196] 2021-11-26 15:53:12,232 >> ***** Running training *****
[INFO|trainer.py:1197] 2021-11-26 15:53:12,232 >>   Num examples = 5749
[INFO|trainer.py:1198] 2021-11-26 15:53:12,232 >>   Num Epochs = 5
[INFO|trainer.py:1199] 2021-11-26 15:53:12,232 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2021-11-26 15:53:12,232 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:1201] 2021-11-26 15:53:12,232 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2021-11-26 15:53:12,232 >>   Total optimization steps = 225
[INFO|integrations.py:501] 2021-11-26 15:53:12,268 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: zsl (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.22
wandb: Syncing run ./models/stsb/exit3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zsl/huggingface
wandb: üöÄ View run at https://wandb.ai/zsl/huggingface/runs/2ano2ph7
wandb: Run data is saved locally in /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155316-2ano2ph7
wandb: Run `wandb offline` to turn off syncing.
  0%|          | 0/225 [00:00<?, ?it/s]/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/225 [00:14<54:50, 14.69s/it]  1%|          | 2/225 [00:14<22:46,  6.13s/it]  1%|‚ñè         | 3/225 [00:14<12:31,  3.38s/it]  2%|‚ñè         | 4/225 [00:15<07:43,  2.10s/it]  2%|‚ñè         | 5/225 [00:15<05:05,  1.39s/it]  3%|‚ñé         | 6/225 [00:15<03:30,  1.04it/s]  3%|‚ñé         | 7/225 [00:15<02:32,  1.43it/s]  4%|‚ñé         | 8/225 [00:15<02:09,  1.67it/s]  4%|‚ñç         | 9/225 [00:16<01:39,  2.18it/s]  4%|‚ñç         | 10/225 [00:16<01:16,  2.79it/s]  5%|‚ñç         | 11/225 [00:16<01:01,  3.49it/s]  5%|‚ñå         | 12/225 [00:16<00:51,  4.11it/s]  6%|‚ñå         | 13/225 [00:16<00:44,  4.79it/s]  6%|‚ñå         | 14/225 [00:16<00:38,  5.43it/s]  7%|‚ñã         | 15/225 [00:16<00:35,  5.99it/s]  7%|‚ñã         | 16/225 [00:16<00:32,  6.44it/s]  8%|‚ñä         | 17/225 [00:17<00:31,  6.59it/s]  8%|‚ñä         | 18/225 [00:17<00:29,  6.98it/s]  8%|‚ñä         | 19/225 [00:17<00:28,  7.24it/s]  9%|‚ñâ         | 20/225 [00:17<00:27,  7.38it/s]  9%|‚ñâ         | 21/225 [00:17<00:27,  7.52it/s] 10%|‚ñâ         | 22/225 [00:17<00:26,  7.63it/s] 10%|‚ñà         | 23/225 [00:17<00:26,  7.60it/s] 11%|‚ñà         | 24/225 [00:17<00:26,  7.64it/s] 11%|‚ñà         | 25/225 [00:18<00:25,  7.79it/s] 12%|‚ñà‚ñè        | 26/225 [00:18<00:25,  7.93it/s] 12%|‚ñà‚ñè        | 27/225 [00:18<00:24,  7.92it/s] 12%|‚ñà‚ñè        | 28/225 [00:18<00:25,  7.63it/s] 13%|‚ñà‚ñé        | 29/225 [00:18<00:24,  7.85it/s] 13%|‚ñà‚ñé        | 30/225 [00:18<00:25,  7.64it/s] 14%|‚ñà‚ñç        | 31/225 [00:18<00:31,  6.24it/s] 14%|‚ñà‚ñç        | 32/225 [00:19<00:30,  6.32it/s] 15%|‚ñà‚ñç        | 33/225 [00:19<00:29,  6.56it/s] 15%|‚ñà‚ñå        | 34/225 [00:19<00:34,  5.54it/s] 16%|‚ñà‚ñå        | 35/225 [00:19<00:38,  4.90it/s] 16%|‚ñà‚ñå        | 36/225 [00:20<00:40,  4.64it/s] 16%|‚ñà‚ñã        | 37/225 [00:20<00:43,  4.32it/s] 17%|‚ñà‚ñã        | 38/225 [00:20<00:56,  3.32it/s] 17%|‚ñà‚ñã        | 39/225 [00:21<00:59,  3.15it/s] 18%|‚ñà‚ñä        | 40/225 [00:21<00:59,  3.12it/s] 18%|‚ñà‚ñä        | 41/225 [00:21<00:56,  3.23it/s] 19%|‚ñà‚ñä        | 42/225 [00:22<01:02,  2.93it/s] 19%|‚ñà‚ñâ        | 43/225 [00:22<01:01,  2.97it/s] 20%|‚ñà‚ñâ        | 44/225 [00:22<00:54,  3.31it/s] 20%|‚ñà‚ñà        | 45/225 [00:22<00:44,  4.02it/s] 20%|‚ñà‚ñà        | 46/225 [00:22<00:40,  4.44it/s] 21%|‚ñà‚ñà        | 47/225 [00:23<00:40,  4.35it/s] 21%|‚ñà‚ñà‚ñè       | 48/225 [00:23<00:35,  5.02it/s] 22%|‚ñà‚ñà‚ñè       | 49/225 [00:23<00:31,  5.65it/s] 22%|‚ñà‚ñà‚ñè       | 50/225 [00:23<00:27,  6.27it/s] 23%|‚ñà‚ñà‚ñé       | 51/225 [00:23<00:30,  5.71it/s] 23%|‚ñà‚ñà‚ñé       | 52/225 [00:23<00:30,  5.65it/s] 24%|‚ñà‚ñà‚ñé       | 53/225 [00:24<00:28,  6.08it/s] 24%|‚ñà‚ñà‚ñç       | 54/225 [00:24<00:29,  5.75it/s] 24%|‚ñà‚ñà‚ñç       | 55/225 [00:24<00:32,  5.25it/s] 25%|‚ñà‚ñà‚ñç       | 56/225 [00:24<00:29,  5.80it/s] 25%|‚ñà‚ñà‚ñå       | 57/225 [00:24<00:26,  6.36it/s] 26%|‚ñà‚ñà‚ñå       | 58/225 [00:25<00:29,  5.72it/s] 26%|‚ñà‚ñà‚ñå       | 59/225 [00:25<00:32,  5.04it/s] 27%|‚ñà‚ñà‚ñã       | 60/225 [00:25<00:30,  5.49it/s] 27%|‚ñà‚ñà‚ñã       | 61/225 [00:25<00:27,  6.04it/s] 28%|‚ñà‚ñà‚ñä       | 62/225 [00:25<00:29,  5.56it/s] 28%|‚ñà‚ñà‚ñä       | 63/225 [00:25<00:29,  5.45it/s] 28%|‚ñà‚ñà‚ñä       | 64/225 [00:26<00:26,  6.00it/s] 29%|‚ñà‚ñà‚ñâ       | 65/225 [00:26<00:24,  6.47it/s] 29%|‚ñà‚ñà‚ñâ       | 66/225 [00:26<00:30,  5.29it/s] 30%|‚ñà‚ñà‚ñâ       | 67/225 [00:26<00:28,  5.57it/s] 30%|‚ñà‚ñà‚ñà       | 68/225 [00:26<00:25,  6.06it/s] 31%|‚ñà‚ñà‚ñà       | 69/225 [00:26<00:24,  6.34it/s] 31%|‚ñà‚ñà‚ñà       | 70/225 [00:27<00:23,  6.71it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/225 [00:27<00:23,  6.46it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 72/225 [00:27<00:27,  5.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 73/225 [00:27<00:25,  5.96it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 74/225 [00:27<00:23,  6.44it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 75/225 [00:27<00:25,  5.89it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 76/225 [00:28<00:26,  5.58it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 77/225 [00:28<00:24,  6.04it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 78/225 [00:28<00:26,  5.56it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 79/225 [00:28<00:29,  4.96it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 80/225 [00:28<00:26,  5.52it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 81/225 [00:28<00:23,  6.09it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 82/225 [00:29<00:25,  5.56it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/225 [00:29<00:26,  5.36it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 84/225 [00:29<00:23,  5.94it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/225 [00:29<00:22,  6.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 86/225 [00:29<00:24,  5.73it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 87/225 [00:30<00:25,  5.47it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 88/225 [00:30<00:23,  5.91it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/225 [00:30<00:21,  6.32it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 90/225 [00:30<00:25,  5.34it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 91/225 [00:30<00:23,  5.74it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 92/225 [00:30<00:21,  6.22it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/225 [00:30<00:19,  6.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/225 [00:31<00:22,  5.87it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/225 [00:31<00:23,  5.44it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/225 [00:31<00:30,  4.27it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/225 [00:32<00:31,  4.00it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 98/225 [00:32<00:27,  4.66it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/225 [00:32<00:24,  5.25it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 100/225 [00:32<00:25,  4.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 101/225 [00:32<00:23,  5.23it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/225 [00:32<00:21,  5.73it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 103/225 [00:32<00:20,  5.96it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 104/225 [00:33<00:23,  5.07it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/225 [00:33<00:22,  5.41it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 106/225 [00:33<00:19,  5.97it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/225 [00:33<00:18,  6.41it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/225 [00:33<00:23,  5.02it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/225 [00:34<00:29,  3.89it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/225 [00:34<00:29,  3.88it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/225 [00:34<00:30,  3.79it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 112/225 [00:35<00:37,  2.99it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/225 [00:35<00:38,  2.95it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 114/225 [00:36<00:36,  3.03it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 115/225 [00:36<00:32,  3.33it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/225 [00:36<00:35,  3.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 117/225 [00:37<00:37,  2.87it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 118/225 [00:37<00:31,  3.36it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/225 [00:37<00:25,  4.11it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 120/225 [00:37<00:23,  4.51it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/225 [00:37<00:23,  4.38it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/225 [00:37<00:20,  5.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 123/225 [00:38<00:17,  5.70it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/225 [00:38<00:18,  5.42it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/225 [00:38<00:19,  5.20it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 126/225 [00:38<00:17,  5.60it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/225 [00:38<00:17,  5.51it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 128/225 [00:39<00:19,  4.88it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 129/225 [00:39<00:17,  5.48it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/225 [00:39<00:15,  6.04it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/225 [00:39<00:16,  5.72it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 132/225 [00:39<00:18,  4.99it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/225 [00:39<00:16,  5.54it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 134/225 [00:40<00:15,  5.98it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/225 [00:40<00:14,  6.39it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 136/225 [00:40<00:16,  5.31it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 137/225 [00:40<00:15,  5.53it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/225 [00:40<00:14,  5.99it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 139/225 [00:40<00:13,  6.33it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 140/225 [00:41<00:16,  5.22it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/225 [00:41<00:15,  5.47it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 142/225 [00:41<00:13,  6.01it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 143/225 [00:41<00:13,  5.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/225 [00:41<00:15,  5.13it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 145/225 [00:41<00:14,  5.71it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 146/225 [00:42<00:12,  6.19it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/225 [00:42<00:13,  5.57it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 148/225 [00:42<00:13,  5.53it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 149/225 [00:42<00:12,  5.96it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 150/225 [00:42<00:13,  5.50it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 151/225 [00:43<00:16,  4.59it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/225 [00:43<00:14,  5.18it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 153/225 [00:43<00:14,  4.96it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 154/225 [00:43<00:13,  5.22it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/225 [00:43<00:14,  4.84it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 156/225 [00:44<00:12,  5.50it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 157/225 [00:44<00:11,  6.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/225 [00:44<00:11,  5.71it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 159/225 [00:44<00:12,  5.50it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 160/225 [00:44<00:10,  6.06it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 161/225 [00:44<00:09,  6.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 162/225 [00:45<00:09,  6.41it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 163/225 [00:45<00:11,  5.45it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 164/225 [00:45<00:10,  5.67it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 165/225 [00:45<00:10,  5.46it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/225 [00:45<00:11,  5.00it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/225 [00:45<00:10,  5.51it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 168/225 [00:46<00:09,  6.04it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/225 [00:46<00:11,  4.70it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 170/225 [00:46<00:10,  5.29it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 171/225 [00:46<00:09,  5.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/225 [00:46<00:09,  5.64it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 173/225 [00:47<00:10,  4.95it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 174/225 [00:47<00:09,  5.56it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/225 [00:47<00:08,  6.00it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 176/225 [00:47<00:09,  5.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 177/225 [00:48<00:12,  3.87it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 178/225 [00:48<00:11,  3.96it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/225 [00:48<00:12,  3.71it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/225 [00:49<00:14,  3.05it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/225 [00:49<00:14,  3.11it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 182/225 [00:49<00:14,  3.03it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/225 [00:50<00:14,  2.92it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 184/225 [00:50<00:14,  2.89it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 185/225 [00:50<00:13,  2.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 186/225 [00:51<00:11,  3.27it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/225 [00:51<00:09,  4.03it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 188/225 [00:51<00:09,  3.74it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/225 [00:51<00:07,  4.51it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 190/225 [00:51<00:06,  5.02it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 191/225 [00:51<00:07,  4.61it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 192/225 [00:52<00:06,  5.27it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 193/225 [00:52<00:05,  5.92it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 194/225 [00:52<00:05,  5.75it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/225 [00:52<00:05,  5.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 196/225 [00:52<00:05,  5.76it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/225 [00:52<00:04,  6.25it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/225 [00:53<00:05,  5.22it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 199/225 [00:53<00:04,  5.78it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/225 [00:53<00:03,  6.37it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 201/225 [00:53<00:04,  5.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 202/225 [00:53<00:04,  5.07it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/225 [00:54<00:03,  5.70it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/225 [00:54<00:03,  6.18it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 205/225 [00:54<00:03,  6.22it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 206/225 [00:54<00:02,  6.74it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/225 [00:54<00:02,  7.18it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 208/225 [00:54<00:02,  7.31it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/225 [00:54<00:02,  7.59it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 210/225 [00:54<00:01,  7.99it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/225 [00:55<00:01,  8.27it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 212/225 [00:55<00:01,  8.52it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 213/225 [00:55<00:01,  8.67it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 214/225 [00:55<00:01,  8.77it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 215/225 [00:55<00:01,  8.73it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 216/225 [00:55<00:01,  8.71it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/225 [00:55<00:00,  8.68it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 218/225 [00:55<00:00,  8.80it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 219/225 [00:55<00:00,  8.89it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 220/225 [00:56<00:00,  8.76it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/225 [00:56<00:00,  8.72it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 222/225 [00:56<00:00,  8.63it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/225 [00:56<00:00,  8.56it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 224/225 [00:56<00:00,  8.59it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [00:56<00:00,  8.75it/s][INFO|trainer.py:1409] 2021-11-26 15:54:17,155 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 64.923, 'train_samples_per_second': 442.755, 'train_steps_per_second': 3.466, 'train_loss': 7.7695540364583335, 'epoch': 5.0}100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [00:56<00:00,  8.75it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [00:56<00:00,  3.97it/s]
[INFO|trainer.py:1995] 2021-11-26 15:54:17,274 >> Saving model checkpoint to ./models/stsb/exit3
[INFO|configuration_utils.py:417] 2021-11-26 15:54:17,282 >> Configuration saved in ./models/stsb/exit3/config.json
[INFO|modeling_utils.py:1058] 2021-11-26 15:54:19,155 >> Model weights saved in ./models/stsb/exit3/pytorch_model.bin
[INFO|tokenization_utils_base.py:2034] 2021-11-26 15:54:19,161 >> tokenizer config file saved in ./models/stsb/exit3/tokenizer_config.json
[INFO|tokenization_utils_base.py:2040] 2021-11-26 15:54:19,163 >> Special tokens file saved in ./models/stsb/exit3/special_tokens_map.json
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     7.7696
  train_runtime            = 0:01:04.92
  train_samples            =       5749
  train_samples_per_second =    442.755
  train_steps_per_second   =      3.466

11/26/2021 15:54:19 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:541] 2021-11-26 15:54:19,310 >> The following columns in the evaluation set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: idx, sentence1, sentence2.
[INFO|trainer.py:2243] 2021-11-26 15:54:19,317 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2021-11-26 15:54:19,317 >>   Num examples = 1500
[INFO|trainer.py:2248] 2021-11-26 15:54:19,318 >>   Batch size = 32
  0%|          | 0/47 [00:00<?, ?it/s]  6%|‚ñã         | 3/47 [00:00<00:01, 29.35it/s] 13%|‚ñà‚ñé        | 6/47 [00:00<00:01, 23.61it/s] 19%|‚ñà‚ñâ        | 9/47 [00:00<00:01, 19.08it/s] 26%|‚ñà‚ñà‚ñå       | 12/47 [00:00<00:01, 19.20it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 15/47 [00:00<00:01, 20.08it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 18/47 [00:00<00:01, 20.52it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 21/47 [00:01<00:01, 20.90it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 24/47 [00:01<00:01, 21.26it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 27/47 [00:01<00:00, 20.93it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 30/47 [00:01<00:00, 21.31it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 33/47 [00:01<00:00, 21.60it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 36/47 [00:01<00:00, 21.84it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 39/47 [00:01<00:00, 21.65it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 42/47 [00:01<00:00, 21.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 45/47 [00:02<00:00, 18.32it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:02<00:00, 16.60it/s]11/26/2021 15:54:21 - INFO - datasets.metric - Removing /home/slzhang/.cache/huggingface/metrics/glue/stsb/default_experiment-1-0.arrow
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:02<00:00, 19.31it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_combined_score     =     0.1901
  eval_loss               =     4.8692
  eval_pearson            =     0.1955
  eval_runtime            = 0:00:02.46
  eval_samples            =       1500
  eval_samples_per_second =    608.245
  eval_spearmanr          =     0.1847
  eval_steps_per_second   =     19.058
Traceback (most recent call last):
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 706, in urlopen
    chunked=chunked,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connection.py", line 421, in connect
    tls_in_tls=tls_in_tls,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 450, in ssl_wrap_socket
    sock, context, tls_in_tls, server_hostname=server_hostname
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 423, in wrap_socket
    session=session
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 870, in _create
    self.do_handshake()
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 1139, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 756, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/util/retry.py", line 532, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 706, in urlopen
    chunked=chunked,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connection.py", line 421, in connect
    tls_in_tls=tls_in_tls,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 450, in ssl_wrap_socket
    sock, context, tls_in_tls, server_hostname=server_hostname
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 423, in wrap_socket
    session=session
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 870, in _create
    self.do_handshake()
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 1139, in do_handshake
    self._sslobj.do_handshake()
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run_glue.py", line 583, in <module>
    main()
  File "run_glue.py", line 574, in main
    trainer.create_model_card(**kwargs)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/transformers/trainer.py", line 2603, in create_model_card
    dataset_args=dataset_args,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/transformers/modelcard.py", line 604, in from_trainer
    hyperparameters=hyperparameters,
  File "<string>", line 14, in __init__
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/transformers/modelcard.py", line 390, in __post_init__
    model_info = HfApi().model_info(self.finetuned_from)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/huggingface_hub/hf_api.py", line 516, in model_info
    r = requests.get(path, headers=headers, timeout=timeout)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/api.py", line 76, in get
    return request('get', url, params=params, **kwargs)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
wandb: Waiting for W&B process to finish, PID 3573611
wandb: Program failed with code 1.  Press ctrl-c to abort syncing.
wandb: - 0.02MB of 0.02MB uploaded (0.00MB deduped)wandb: \ 0.05MB of 0.05MB uploaded (0.00MB deduped)wandb: | 0.05MB of 0.05MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155316-2ano2ph7/logs/debug.log
wandb: Find internal logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155316-2ano2ph7/logs/debug-internal.log
wandb: Run summary:
wandb:              train/train_runtime 64.923
wandb:   train/train_samples_per_second 442.755
wandb:     train/train_steps_per_second 3.466
wandb:                 train/total_flos 482507878030080.0
wandb:                 train/train_loss 7.76955
wandb:                      train/epoch 5.0
wandb:                train/global_step 225
wandb:                         _runtime 64
wandb:                       _timestamp 1637913261
wandb:                            _step 1
wandb:                        eval/loss 4.86919
wandb:                     eval/pearson 0.19553
wandb:                   eval/spearmanr 0.1847
wandb:              eval/combined_score 0.19011
wandb:                     eval/runtime 2.4661
wandb:          eval/samples_per_second 608.245
wandb:            eval/steps_per_second 19.058
wandb: Run history:
wandb:              train/train_runtime ‚ñÅ
wandb:   train/train_samples_per_second ‚ñÅ
wandb:     train/train_steps_per_second ‚ñÅ
wandb:                 train/total_flos ‚ñÅ
wandb:                 train/train_loss ‚ñÅ
wandb:                      train/epoch ‚ñÅ‚ñÅ
wandb:                train/global_step ‚ñÅ‚ñÅ
wandb:                         _runtime ‚ñÅ‚ñà
wandb:                       _timestamp ‚ñÅ‚ñà
wandb:                            _step ‚ñÅ‚ñà
wandb:                        eval/loss ‚ñÅ
wandb:                     eval/pearson ‚ñÅ
wandb:                   eval/spearmanr ‚ñÅ
wandb:              eval/combined_score ‚ñÅ
wandb:                     eval/runtime ‚ñÅ
wandb:          eval/samples_per_second ‚ñÅ
wandb:            eval/steps_per_second ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ./models/stsb/exit3: https://wandb.ai/zsl/huggingface/runs/2ano2ph7

11/26/2021 15:54:41 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 15:54:41 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit4/runs/Nov26_15-54-41_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit4,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit4,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 15:54:43 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue
11/26/2021 15:54:43 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:54:43 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.py
11/26/2021 15:54:43 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/dataset_infos.json to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/dataset_infos.json
11/26/2021 15:54:43 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.json
11/26/2021 15:54:43 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:54:43 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 15:54:43 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:54:43 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 15:54:43 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 275.43it/s]
[INFO|configuration_utils.py:588] 2021-11-26 15:54:44,629 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:54:44,631 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 15:54:46,374 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:54:46,375 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:54:51,559 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/slzhang/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:54:51,560 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/slzhang/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:54:51,560 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:54:51,560 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:54:51,560 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/slzhang/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:588] 2021-11-26 15:54:52,379 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:54:52,381 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1340] 2021-11-26 15:54:53,241 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/slzhang/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1597] 2021-11-26 15:54:55,020 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertWithSinglehead: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertWithSinglehead from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertWithSinglehead from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1608] 2021-11-26 15:54:55,020 >> Some weights of BertWithSinglehead were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['s1_classifier.weight', 's1_classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/26/2021 15:54:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecb0af5ac5f5f4cf.arrow
11/26/2021 15:54:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f66158b4c3938527.arrow
11/26/2021 15:54:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8d605fec10ae3523.arrow
11/26/2021 15:54:56 - INFO - __main__ - Sample 5238 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 5238, 'input_ids': [101, 2966, 2852, 12952, 24373, 1113, 7303, 102, 7661, 112, 188, 1285, 131, 3460, 1159, 1113, 7303, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1.600000023841858, 'sentence1': 'Didier Reynders on Syria', 'sentence2': "Obama's day: Prime time on Syria", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:54:56 - INFO - __main__ - Sample 912 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 912, 'input_ids': [101, 138, 1299, 1110, 9374, 1103, 3751, 119, 102, 138, 1299, 1110, 3759, 170, 1610, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0.4000000059604645, 'sentence1': 'A man is cleaning the windows.', 'sentence2': 'A man is driving a car.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:54:56 - INFO - __main__ - Sample 204 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 204, 'input_ids': [101, 138, 1590, 3486, 170, 24181, 12253, 24886, 119, 102, 138, 1590, 1110, 8184, 1146, 170, 24181, 12253, 24886, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 3.25, 'sentence1': 'A woman holds a kangaroo.', 'sentence2': 'A woman is picking up a kangaroo.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:54:59 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue
11/26/2021 15:54:59 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981
11/26/2021 15:54:59 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.py
11/26/2021 15:54:59 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/dataset_infos.json
11/26/2021 15:54:59 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.json
[INFO|trainer.py:541] 2021-11-26 15:55:05,975 >> The following columns in the training set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, idx, sentence2.
[INFO|trainer.py:1196] 2021-11-26 15:55:05,997 >> ***** Running training *****
[INFO|trainer.py:1197] 2021-11-26 15:55:05,997 >>   Num examples = 5749
[INFO|trainer.py:1198] 2021-11-26 15:55:05,997 >>   Num Epochs = 5
[INFO|trainer.py:1199] 2021-11-26 15:55:05,997 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2021-11-26 15:55:05,997 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:1201] 2021-11-26 15:55:05,997 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2021-11-26 15:55:05,998 >>   Total optimization steps = 225
[INFO|integrations.py:501] 2021-11-26 15:55:06,026 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: zsl (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.22
wandb: Syncing run ./models/stsb/exit4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zsl/huggingface
wandb: üöÄ View run at https://wandb.ai/zsl/huggingface/runs/2kfe4rjw
wandb: Run data is saved locally in /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155507-2kfe4rjw
wandb: Run `wandb offline` to turn off syncing.
  0%|          | 0/225 [00:00<?, ?it/s]/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/225 [00:17<1:06:50, 17.90s/it]  1%|          | 2/225 [00:18<28:07,  7.57s/it]    1%|‚ñè         | 3/225 [00:18<15:26,  4.17s/it]  2%|‚ñè         | 4/225 [00:18<09:33,  2.59s/it]  2%|‚ñè         | 5/225 [00:18<06:28,  1.77s/it]  3%|‚ñé         | 6/225 [00:18<04:25,  1.21s/it]  3%|‚ñé         | 7/225 [00:19<03:07,  1.16it/s]  4%|‚ñé         | 8/225 [00:19<02:30,  1.44it/s]  4%|‚ñç         | 9/225 [00:19<01:52,  1.91it/s]  4%|‚ñç         | 10/225 [00:19<01:26,  2.48it/s]  5%|‚ñç         | 11/225 [00:19<01:13,  2.90it/s]  5%|‚ñå         | 12/225 [00:20<01:10,  3.04it/s]  6%|‚ñå         | 13/225 [00:20<00:56,  3.73it/s]  6%|‚ñå         | 14/225 [00:20<00:55,  3.83it/s]  7%|‚ñã         | 15/225 [00:20<00:46,  4.49it/s]  7%|‚ñã         | 16/225 [00:20<00:41,  5.06it/s]  8%|‚ñä         | 17/225 [00:21<00:37,  5.61it/s]  8%|‚ñä         | 18/225 [00:21<00:34,  6.08it/s]  8%|‚ñä         | 19/225 [00:21<00:31,  6.46it/s]  9%|‚ñâ         | 20/225 [00:21<00:30,  6.69it/s]  9%|‚ñâ         | 21/225 [00:21<00:29,  7.01it/s] 10%|‚ñâ         | 22/225 [00:21<00:28,  7.12it/s] 10%|‚ñà         | 23/225 [00:21<00:27,  7.36it/s] 11%|‚ñà         | 24/225 [00:21<00:26,  7.50it/s] 11%|‚ñà         | 25/225 [00:22<00:34,  5.73it/s] 12%|‚ñà‚ñè        | 26/225 [00:22<00:31,  6.23it/s] 12%|‚ñà‚ñè        | 27/225 [00:22<00:30,  6.57it/s] 12%|‚ñà‚ñè        | 28/225 [00:22<00:28,  6.81it/s] 13%|‚ñà‚ñé        | 29/225 [00:22<00:28,  6.99it/s] 13%|‚ñà‚ñé        | 30/225 [00:22<00:27,  7.12it/s] 14%|‚ñà‚ñç        | 31/225 [00:23<00:26,  7.21it/s] 14%|‚ñà‚ñç        | 32/225 [00:23<00:26,  7.27it/s] 15%|‚ñà‚ñç        | 33/225 [00:23<00:26,  7.25it/s] 15%|‚ñà‚ñå        | 34/225 [00:23<00:26,  7.27it/s] 16%|‚ñà‚ñå        | 35/225 [00:23<00:25,  7.31it/s] 16%|‚ñà‚ñå        | 36/225 [00:23<00:25,  7.33it/s] 16%|‚ñà‚ñã        | 37/225 [00:23<00:25,  7.36it/s] 17%|‚ñà‚ñã        | 38/225 [00:23<00:26,  7.19it/s] 17%|‚ñà‚ñã        | 39/225 [00:24<00:26,  6.96it/s] 18%|‚ñà‚ñä        | 40/225 [00:24<00:27,  6.83it/s] 18%|‚ñà‚ñä        | 41/225 [00:24<00:26,  6.85it/s] 19%|‚ñà‚ñä        | 42/225 [00:24<00:26,  6.81it/s] 19%|‚ñà‚ñâ        | 43/225 [00:24<00:27,  6.72it/s] 20%|‚ñà‚ñâ        | 44/225 [00:24<00:33,  5.36it/s] 20%|‚ñà‚ñà        | 45/225 [00:25<00:34,  5.21it/s] 20%|‚ñà‚ñà        | 46/225 [00:25<00:32,  5.57it/s] 21%|‚ñà‚ñà        | 47/225 [00:25<00:30,  5.82it/s] 21%|‚ñà‚ñà‚ñè       | 48/225 [00:25<00:29,  6.01it/s] 22%|‚ñà‚ñà‚ñè       | 49/225 [00:25<00:28,  6.14it/s] 22%|‚ñà‚ñà‚ñè       | 50/225 [00:25<00:28,  6.14it/s] 23%|‚ñà‚ñà‚ñé       | 51/225 [00:26<00:28,  6.14it/s] 23%|‚ñà‚ñà‚ñé       | 52/225 [00:26<00:29,  5.82it/s] 24%|‚ñà‚ñà‚ñé       | 53/225 [00:26<00:31,  5.39it/s] 24%|‚ñà‚ñà‚ñç       | 54/225 [00:26<00:30,  5.64it/s] 24%|‚ñà‚ñà‚ñç       | 55/225 [00:26<00:28,  5.87it/s] 25%|‚ñà‚ñà‚ñç       | 56/225 [00:27<00:28,  6.01it/s] 25%|‚ñà‚ñà‚ñå       | 57/225 [00:27<00:27,  6.22it/s] 26%|‚ñà‚ñà‚ñå       | 58/225 [00:27<00:26,  6.38it/s] 26%|‚ñà‚ñà‚ñå       | 59/225 [00:27<00:24,  6.69it/s] 27%|‚ñà‚ñà‚ñã       | 60/225 [00:27<00:24,  6.75it/s] 27%|‚ñà‚ñà‚ñã       | 61/225 [00:27<00:30,  5.30it/s] 28%|‚ñà‚ñà‚ñä       | 62/225 [00:28<00:29,  5.52it/s] 28%|‚ñà‚ñà‚ñä       | 63/225 [00:28<00:27,  5.82it/s] 28%|‚ñà‚ñà‚ñä       | 64/225 [00:28<00:30,  5.27it/s] 29%|‚ñà‚ñà‚ñâ       | 65/225 [00:28<00:33,  4.82it/s] 29%|‚ñà‚ñà‚ñâ       | 66/225 [00:28<00:30,  5.23it/s] 30%|‚ñà‚ñà‚ñâ       | 67/225 [00:29<00:30,  5.13it/s] 30%|‚ñà‚ñà‚ñà       | 68/225 [00:29<00:34,  4.60it/s] 31%|‚ñà‚ñà‚ñà       | 69/225 [00:29<00:31,  5.01it/s] 31%|‚ñà‚ñà‚ñà       | 70/225 [00:29<00:28,  5.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/225 [00:29<00:28,  5.43it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 72/225 [00:30<00:32,  4.75it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 73/225 [00:30<00:31,  4.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 74/225 [00:30<00:32,  4.70it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 75/225 [00:30<00:36,  4.12it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 76/225 [00:31<00:44,  3.38it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 77/225 [00:31<00:38,  3.89it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 78/225 [00:31<00:43,  3.41it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 79/225 [00:32<00:51,  2.82it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 80/225 [00:32<00:49,  2.95it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 81/225 [00:32<00:47,  3.01it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 82/225 [00:33<00:51,  2.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/225 [00:33<00:48,  2.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 84/225 [00:33<00:47,  2.95it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/225 [00:34<00:43,  3.23it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 86/225 [00:34<00:42,  3.30it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 87/225 [00:34<00:35,  3.92it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 88/225 [00:34<00:30,  4.49it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/225 [00:35<00:33,  4.10it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 90/225 [00:35<00:29,  4.62it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 91/225 [00:35<00:26,  5.12it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 92/225 [00:35<00:23,  5.61it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/225 [00:35<00:28,  4.70it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/225 [00:35<00:25,  5.20it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/225 [00:36<00:23,  5.65it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/225 [00:36<00:22,  5.76it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/225 [00:36<00:26,  4.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 98/225 [00:36<00:24,  5.24it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/225 [00:36<00:25,  4.90it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 100/225 [00:37<00:29,  4.24it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 101/225 [00:37<00:26,  4.75it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/225 [00:37<00:26,  4.72it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 103/225 [00:37<00:28,  4.27it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 104/225 [00:38<00:25,  4.80it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/225 [00:38<00:23,  5.09it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 106/225 [00:38<00:26,  4.53it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/225 [00:38<00:23,  5.03it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/225 [00:38<00:21,  5.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/225 [00:38<00:22,  5.24it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/225 [00:39<00:24,  4.66it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/225 [00:39<00:21,  5.19it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 112/225 [00:39<00:21,  5.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/225 [00:39<00:19,  5.65it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 114/225 [00:39<00:23,  4.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 115/225 [00:40<00:21,  5.11it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/225 [00:40<00:22,  4.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 117/225 [00:40<00:25,  4.27it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 118/225 [00:40<00:22,  4.75it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/225 [00:41<00:22,  4.68it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 120/225 [00:41<00:25,  4.13it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/225 [00:41<00:23,  4.51it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/225 [00:41<00:21,  4.75it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 123/225 [00:42<00:24,  4.19it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/225 [00:42<00:21,  4.70it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/225 [00:42<00:20,  4.92it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 126/225 [00:42<00:24,  4.08it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/225 [00:42<00:21,  4.61it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 128/225 [00:43<00:20,  4.65it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 129/225 [00:43<00:22,  4.27it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/225 [00:43<00:19,  4.81it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/225 [00:43<00:18,  5.21it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 132/225 [00:43<00:19,  4.69it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/225 [00:44<00:18,  4.95it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 134/225 [00:44<00:16,  5.39it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/225 [00:44<00:15,  5.76it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 136/225 [00:44<00:22,  4.02it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 137/225 [00:45<00:25,  3.45it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/225 [00:45<00:24,  3.52it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 139/225 [00:45<00:29,  2.95it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 140/225 [00:46<00:32,  2.65it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/225 [00:46<00:29,  2.85it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 142/225 [00:47<00:30,  2.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 143/225 [00:47<00:31,  2.59it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/225 [00:47<00:28,  2.86it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 145/225 [00:48<00:26,  2.98it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 146/225 [00:48<00:25,  3.08it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/225 [00:48<00:21,  3.69it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 148/225 [00:48<00:19,  4.01it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 149/225 [00:49<00:20,  3.73it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 150/225 [00:49<00:17,  4.33it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 151/225 [00:49<00:15,  4.92it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/225 [00:49<00:17,  4.24it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 153/225 [00:49<00:15,  4.78it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 154/225 [00:49<00:13,  5.28it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/225 [00:50<00:12,  5.70it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 156/225 [00:50<00:15,  4.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 157/225 [00:50<00:13,  4.93it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/225 [00:50<00:12,  5.36it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 159/225 [00:50<00:12,  5.44it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 160/225 [00:51<00:13,  4.65it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 161/225 [00:51<00:12,  5.07it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 162/225 [00:51<00:11,  5.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 163/225 [00:51<00:11,  5.32it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 164/225 [00:51<00:13,  4.48it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 165/225 [00:52<00:12,  4.98it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/225 [00:52<00:11,  5.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/225 [00:52<00:12,  4.48it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 168/225 [00:52<00:11,  4.98it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/225 [00:52<00:10,  5.35it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 170/225 [00:53<00:11,  4.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 171/225 [00:53<00:12,  4.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/225 [00:53<00:10,  5.02it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 173/225 [00:53<00:09,  5.52it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 174/225 [00:53<00:10,  4.85it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/225 [00:54<00:10,  4.90it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 176/225 [00:54<00:09,  5.36it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 177/225 [00:54<00:09,  5.16it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 178/225 [00:54<00:11,  4.23it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/225 [00:55<00:10,  4.51it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/225 [00:55<00:08,  5.08it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/225 [00:55<00:08,  5.29it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 182/225 [00:55<00:09,  4.51it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/225 [00:55<00:08,  4.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 184/225 [00:55<00:07,  5.39it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 185/225 [00:56<00:08,  4.53it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 186/225 [00:56<00:09,  4.29it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/225 [00:56<00:07,  4.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 188/225 [00:56<00:07,  4.87it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/225 [00:57<00:08,  4.31it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 190/225 [00:57<00:07,  4.85it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 191/225 [00:57<00:07,  4.80it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 192/225 [00:57<00:07,  4.34it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 193/225 [00:57<00:06,  4.68it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 194/225 [00:58<00:06,  4.69it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/225 [00:58<00:07,  4.11it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 196/225 [00:58<00:06,  4.65it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/225 [00:58<00:05,  5.12it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/225 [00:59<00:05,  4.72it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 199/225 [00:59<00:06,  3.94it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/225 [00:59<00:06,  3.59it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 201/225 [01:00<00:07,  3.14it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 202/225 [01:00<00:08,  2.71it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/225 [01:00<00:07,  2.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/225 [01:01<00:07,  2.72it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 205/225 [01:01<00:07,  2.59it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 206/225 [01:02<00:07,  2.71it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/225 [01:02<00:06,  2.84it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 208/225 [01:02<00:06,  2.81it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/225 [01:02<00:04,  3.48it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 210/225 [01:03<00:03,  3.80it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/225 [01:03<00:03,  3.70it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 212/225 [01:03<00:02,  4.34it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 213/225 [01:03<00:02,  4.44it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 214/225 [01:04<00:02,  4.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 215/225 [01:04<00:02,  4.88it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 216/225 [01:04<00:01,  5.06it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/225 [01:04<00:01,  5.20it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 218/225 [01:04<00:01,  5.78it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 219/225 [01:04<00:00,  6.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 220/225 [01:04<00:00,  6.54it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/225 [01:05<00:00,  6.70it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 222/225 [01:05<00:00,  6.87it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/225 [01:05<00:00,  7.02it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 224/225 [01:05<00:00,  7.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:05<00:00,  7.38it/s][INFO|trainer.py:1409] 2021-11-26 15:56:17,178 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:05<00:00,  7.38it/s]{'train_runtime': 71.1814, 'train_samples_per_second': 403.827, 'train_steps_per_second': 3.161, 'train_loss': 7.636416015625, 'epoch': 5.0}100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:05<00:00,  3.42it/s]

[INFO|trainer.py:1995] 2021-11-26 15:56:17,298 >> Saving model checkpoint to ./models/stsb/exit4
[INFO|configuration_utils.py:417] 2021-11-26 15:56:17,305 >> Configuration saved in ./models/stsb/exit4/config.json
[INFO|modeling_utils.py:1058] 2021-11-26 15:56:19,554 >> Model weights saved in ./models/stsb/exit4/pytorch_model.bin
[INFO|tokenization_utils_base.py:2034] 2021-11-26 15:56:19,557 >> tokenizer config file saved in ./models/stsb/exit4/tokenizer_config.json
[INFO|tokenization_utils_base.py:2040] 2021-11-26 15:56:19,559 >> Special tokens file saved in ./models/stsb/exit4/special_tokens_map.json
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     7.6364
  train_runtime            = 0:01:11.18
  train_samples            =       5749
  train_samples_per_second =    403.827
  train_steps_per_second   =      3.161

11/26/2021 15:56:19 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:541] 2021-11-26 15:56:19,695 >> The following columns in the evaluation set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, idx, sentence2.
[INFO|trainer.py:2243] 2021-11-26 15:56:19,702 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2021-11-26 15:56:19,702 >>   Num examples = 1500
[INFO|trainer.py:2248] 2021-11-26 15:56:19,703 >>   Batch size = 32
  0%|          | 0/47 [00:00<?, ?it/s]  6%|‚ñã         | 3/47 [00:00<00:01, 28.92it/s] 13%|‚ñà‚ñé        | 6/47 [00:00<00:01, 21.64it/s] 19%|‚ñà‚ñâ        | 9/47 [00:00<00:01, 20.00it/s] 26%|‚ñà‚ñà‚ñå       | 12/47 [00:00<00:01, 20.12it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 15/47 [00:00<00:01, 19.45it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 17/47 [00:00<00:01, 18.66it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 19/47 [00:00<00:01, 18.58it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 21/47 [00:01<00:01, 18.63it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 23/47 [00:01<00:01, 18.93it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 25/47 [00:01<00:01, 19.01it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 27/47 [00:01<00:01, 19.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 29/47 [00:01<00:00, 18.75it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 31/47 [00:01<00:00, 18.87it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 33/47 [00:01<00:00, 18.65it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 35/47 [00:01<00:00, 18.49it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 37/47 [00:01<00:00, 18.73it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 39/47 [00:02<00:00, 18.88it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 41/47 [00:02<00:00, 18.93it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 43/47 [00:02<00:00, 19.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 45/47 [00:02<00:00, 18.63it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:02<00:00, 18.93it/s]11/26/2021 15:56:22 - INFO - datasets.metric - Removing /home/slzhang/.cache/huggingface/metrics/glue/stsb/default_experiment-1-0.arrow
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:02<00:00, 18.75it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_combined_score     =     0.5246
  eval_loss               =     4.6851
  eval_pearson            =      0.518
  eval_runtime            = 0:00:02.54
  eval_samples            =       1500
  eval_samples_per_second =    588.567
  eval_spearmanr          =     0.5313
  eval_steps_per_second   =     18.442
wandb: Waiting for W&B process to finish, PID 3576723
wandb: Program ended successfully.
wandb: - 0.03MB of 0.03MB uploaded (0.00MB deduped)wandb: \ 0.05MB of 0.05MB uploaded (0.00MB deduped)wandb: | 0.05MB of 0.05MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155507-2kfe4rjw/logs/debug.log
wandb: Find internal logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155507-2kfe4rjw/logs/debug-internal.log
wandb: Run summary:
wandb:              train/train_runtime 71.1814
wandb:   train/train_samples_per_second 403.827
wandb:     train/train_steps_per_second 3.161
wandb:                 train/total_flos 638980874361600.0
wandb:                 train/train_loss 7.63642
wandb:                      train/epoch 5.0
wandb:                train/global_step 225
wandb:                         _runtime 75
wandb:                       _timestamp 1637913382
wandb:                            _step 1
wandb:                        eval/loss 4.68506
wandb:                     eval/pearson 0.518
wandb:                   eval/spearmanr 0.53125
wandb:              eval/combined_score 0.52463
wandb:                     eval/runtime 2.5486
wandb:          eval/samples_per_second 588.567
wandb:            eval/steps_per_second 18.442
wandb: Run history:
wandb:              train/train_runtime ‚ñÅ
wandb:   train/train_samples_per_second ‚ñÅ
wandb:     train/train_steps_per_second ‚ñÅ
wandb:                 train/total_flos ‚ñÅ
wandb:                 train/train_loss ‚ñÅ
wandb:                      train/epoch ‚ñÅ‚ñÅ
wandb:                train/global_step ‚ñÅ‚ñÅ
wandb:                         _runtime ‚ñÅ‚ñà
wandb:                       _timestamp ‚ñÅ‚ñà
wandb:                            _step ‚ñÅ‚ñà
wandb:                        eval/loss ‚ñÅ
wandb:                     eval/pearson ‚ñÅ
wandb:                   eval/spearmanr ‚ñÅ
wandb:              eval/combined_score ‚ñÅ
wandb:                     eval/runtime ‚ñÅ
wandb:          eval/samples_per_second ‚ñÅ
wandb:            eval/steps_per_second ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ./models/stsb/exit4: https://wandb.ai/zsl/huggingface/runs/2kfe4rjw

11/26/2021 15:56:37 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 15:56:37 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit5/runs/Nov26_15-56-37_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit5,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit5,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 15:56:39 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue
11/26/2021 15:56:39 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:56:39 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.py
11/26/2021 15:56:39 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/dataset_infos.json to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/dataset_infos.json
11/26/2021 15:56:39 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.json
11/26/2021 15:56:39 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:56:39 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 15:56:39 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:56:39 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 15:56:39 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 264.05it/s]
[INFO|configuration_utils.py:588] 2021-11-26 15:56:40,490 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:56:40,493 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 15:56:42,139 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:56:42,140 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:56:47,191 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/slzhang/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:56:47,191 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/slzhang/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:56:47,191 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:56:47,191 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:56:47,191 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/slzhang/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:588] 2021-11-26 15:56:48,015 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:56:48,017 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1340] 2021-11-26 15:56:48,890 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/slzhang/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1597] 2021-11-26 15:56:51,045 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertWithSinglehead: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertWithSinglehead from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertWithSinglehead from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1608] 2021-11-26 15:56:51,045 >> Some weights of BertWithSinglehead were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['s1_classifier.bias', 's1_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/26/2021 15:56:52 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecb0af5ac5f5f4cf.arrow
11/26/2021 15:56:52 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f66158b4c3938527.arrow
11/26/2021 15:56:52 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8d605fec10ae3523.arrow
11/26/2021 15:56:52 - INFO - __main__ - Sample 5238 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 5238, 'input_ids': [101, 2966, 2852, 12952, 24373, 1113, 7303, 102, 7661, 112, 188, 1285, 131, 3460, 1159, 1113, 7303, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1.600000023841858, 'sentence1': 'Didier Reynders on Syria', 'sentence2': "Obama's day: Prime time on Syria", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:56:52 - INFO - __main__ - Sample 912 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 912, 'input_ids': [101, 138, 1299, 1110, 9374, 1103, 3751, 119, 102, 138, 1299, 1110, 3759, 170, 1610, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0.4000000059604645, 'sentence1': 'A man is cleaning the windows.', 'sentence2': 'A man is driving a car.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:56:52 - INFO - __main__ - Sample 204 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 204, 'input_ids': [101, 138, 1590, 3486, 170, 24181, 12253, 24886, 119, 102, 138, 1590, 1110, 8184, 1146, 170, 24181, 12253, 24886, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 3.25, 'sentence1': 'A woman holds a kangaroo.', 'sentence2': 'A woman is picking up a kangaroo.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:56:54 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue
11/26/2021 15:56:54 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981
11/26/2021 15:56:54 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.py
11/26/2021 15:56:54 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/dataset_infos.json
11/26/2021 15:56:54 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.json
[INFO|trainer.py:541] 2021-11-26 15:57:01,440 >> The following columns in the training set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, idx, sentence2.
[INFO|trainer.py:1196] 2021-11-26 15:57:01,460 >> ***** Running training *****
[INFO|trainer.py:1197] 2021-11-26 15:57:01,460 >>   Num examples = 5749
[INFO|trainer.py:1198] 2021-11-26 15:57:01,460 >>   Num Epochs = 5
[INFO|trainer.py:1199] 2021-11-26 15:57:01,460 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2021-11-26 15:57:01,460 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:1201] 2021-11-26 15:57:01,460 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2021-11-26 15:57:01,460 >>   Total optimization steps = 225
[INFO|integrations.py:501] 2021-11-26 15:57:01,508 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: zsl (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.22
wandb: Syncing run ./models/stsb/exit5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zsl/huggingface
wandb: üöÄ View run at https://wandb.ai/zsl/huggingface/runs/w39b7sba
wandb: Run data is saved locally in /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155703-w39b7sba
wandb: Run `wandb offline` to turn off syncing.
  0%|          | 0/225 [00:00<?, ?it/s]/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/225 [00:17<1:05:02, 17.42s/it]  1%|          | 2/225 [00:17<27:02,  7.28s/it]    1%|‚ñè         | 3/225 [00:17<14:54,  4.03s/it]  2%|‚ñè         | 4/225 [00:17<09:13,  2.50s/it]  2%|‚ñè         | 5/225 [00:18<06:05,  1.66s/it]  3%|‚ñé         | 6/225 [00:18<04:12,  1.15s/it]  3%|‚ñé         | 7/225 [00:18<03:09,  1.15it/s]  4%|‚ñé         | 8/225 [00:18<02:24,  1.51it/s]  4%|‚ñç         | 9/225 [00:18<01:49,  1.98it/s]  4%|‚ñç         | 10/225 [00:19<01:32,  2.32it/s]  5%|‚ñç         | 11/225 [00:19<01:24,  2.54it/s]  5%|‚ñå         | 12/225 [00:19<01:09,  3.07it/s]  6%|‚ñå         | 13/225 [00:19<01:06,  3.17it/s]  6%|‚ñå         | 14/225 [00:20<01:03,  3.30it/s]  7%|‚ñã         | 15/225 [00:20<00:55,  3.81it/s]  7%|‚ñã         | 16/225 [00:20<01:04,  3.24it/s]  8%|‚ñä         | 17/225 [00:21<00:57,  3.65it/s]  8%|‚ñä         | 18/225 [00:21<00:59,  3.45it/s]  8%|‚ñä         | 19/225 [00:21<00:56,  3.67it/s]  9%|‚ñâ         | 20/225 [00:21<00:56,  3.63it/s]  9%|‚ñâ         | 21/225 [00:22<00:49,  4.11it/s] 10%|‚ñâ         | 22/225 [00:22<00:45,  4.43it/s] 10%|‚ñà         | 23/225 [00:22<00:50,  4.03it/s] 11%|‚ñà         | 24/225 [00:22<00:44,  4.50it/s] 11%|‚ñà         | 25/225 [00:22<00:40,  4.93it/s] 12%|‚ñà‚ñè        | 26/225 [00:23<00:47,  4.23it/s] 12%|‚ñà‚ñè        | 27/225 [00:23<00:42,  4.70it/s] 12%|‚ñà‚ñè        | 28/225 [00:23<00:38,  5.09it/s] 13%|‚ñà‚ñé        | 29/225 [00:23<00:47,  4.15it/s] 13%|‚ñà‚ñé        | 30/225 [00:23<00:43,  4.48it/s] 14%|‚ñà‚ñç        | 31/225 [00:24<00:39,  4.90it/s] 14%|‚ñà‚ñç        | 32/225 [00:24<00:48,  3.98it/s] 15%|‚ñà‚ñç        | 33/225 [00:24<00:59,  3.24it/s] 15%|‚ñà‚ñå        | 34/225 [00:25<00:57,  3.33it/s] 16%|‚ñà‚ñå        | 35/225 [00:25<00:48,  3.89it/s] 16%|‚ñà‚ñå        | 36/225 [00:25<00:53,  3.54it/s] 16%|‚ñà‚ñã        | 37/225 [00:26<00:53,  3.50it/s] 17%|‚ñà‚ñã        | 38/225 [00:26<00:56,  3.31it/s] 17%|‚ñà‚ñã        | 39/225 [00:26<00:56,  3.27it/s] 18%|‚ñà‚ñä        | 40/225 [00:27<00:58,  3.19it/s] 18%|‚ñà‚ñä        | 41/225 [00:27<00:56,  3.27it/s] 19%|‚ñà‚ñä        | 42/225 [00:27<00:48,  3.79it/s] 19%|‚ñà‚ñâ        | 43/225 [00:27<00:42,  4.27it/s] 20%|‚ñà‚ñâ        | 44/225 [00:27<00:38,  4.70it/s] 20%|‚ñà‚ñà        | 45/225 [00:27<00:35,  5.10it/s] 20%|‚ñà‚ñà        | 46/225 [00:28<00:33,  5.38it/s] 21%|‚ñà‚ñà        | 47/225 [00:28<00:31,  5.65it/s] 21%|‚ñà‚ñà‚ñè       | 48/225 [00:28<00:30,  5.83it/s] 22%|‚ñà‚ñà‚ñè       | 49/225 [00:28<00:29,  5.98it/s] 22%|‚ñà‚ñà‚ñè       | 50/225 [00:28<00:29,  6.03it/s] 23%|‚ñà‚ñà‚ñé       | 51/225 [00:28<00:28,  6.04it/s] 23%|‚ñà‚ñà‚ñé       | 52/225 [00:29<00:29,  5.96it/s] 24%|‚ñà‚ñà‚ñé       | 53/225 [00:29<00:29,  5.89it/s] 24%|‚ñà‚ñà‚ñç       | 54/225 [00:29<00:29,  5.79it/s] 24%|‚ñà‚ñà‚ñç       | 55/225 [00:29<00:28,  5.94it/s] 25%|‚ñà‚ñà‚ñç       | 56/225 [00:29<00:27,  6.04it/s] 25%|‚ñà‚ñà‚ñå       | 57/225 [00:29<00:27,  6.13it/s] 26%|‚ñà‚ñà‚ñå       | 58/225 [00:30<00:27,  6.12it/s] 26%|‚ñà‚ñà‚ñå       | 59/225 [00:30<00:27,  6.13it/s] 27%|‚ñà‚ñà‚ñã       | 60/225 [00:30<00:28,  5.88it/s] 27%|‚ñà‚ñà‚ñã       | 61/225 [00:30<00:27,  6.00it/s] 28%|‚ñà‚ñà‚ñä       | 62/225 [00:30<00:26,  6.05it/s] 28%|‚ñà‚ñà‚ñä       | 63/225 [00:30<00:27,  5.98it/s] 28%|‚ñà‚ñà‚ñä       | 64/225 [00:31<00:27,  5.92it/s] 29%|‚ñà‚ñà‚ñâ       | 65/225 [00:31<00:26,  5.94it/s] 29%|‚ñà‚ñà‚ñâ       | 66/225 [00:31<00:27,  5.76it/s] 30%|‚ñà‚ñà‚ñâ       | 67/225 [00:31<00:26,  5.86it/s] 30%|‚ñà‚ñà‚ñà       | 68/225 [00:31<00:26,  5.97it/s] 31%|‚ñà‚ñà‚ñà       | 69/225 [00:31<00:26,  5.96it/s] 31%|‚ñà‚ñà‚ñà       | 70/225 [00:32<00:30,  5.02it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/225 [00:32<00:31,  4.94it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 72/225 [00:32<00:30,  5.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 73/225 [00:32<00:32,  4.61it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 74/225 [00:33<00:35,  4.25it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 75/225 [00:33<00:32,  4.68it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 76/225 [00:33<00:40,  3.64it/s]wandb: Network error (ConnectionError), entering retry loop. See wandb/debug-internal.log for full traceback.
 34%|‚ñà‚ñà‚ñà‚ñç      | 77/225 [00:33<00:36,  4.08it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 78/225 [00:34<00:36,  4.00it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 79/225 [00:34<00:37,  3.87it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 80/225 [00:34<00:33,  4.32it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 81/225 [00:34<00:30,  4.80it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 82/225 [00:35<00:35,  4.03it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/225 [00:35<00:32,  4.32it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 84/225 [00:35<00:30,  4.69it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/225 [00:35<00:35,  3.96it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 86/225 [00:35<00:32,  4.34it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 87/225 [00:36<00:29,  4.75it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 88/225 [00:36<00:33,  4.08it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/225 [00:36<00:32,  4.21it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 90/225 [00:36<00:29,  4.62it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 91/225 [00:37<00:30,  4.37it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 92/225 [00:37<00:34,  3.81it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/225 [00:37<00:30,  4.26it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/225 [00:37<00:33,  3.85it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/225 [00:38<00:34,  3.79it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/225 [00:38<00:30,  4.25it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/225 [00:38<00:33,  3.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 98/225 [00:38<00:32,  3.95it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/225 [00:39<00:28,  4.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 100/225 [00:39<00:30,  4.09it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 101/225 [00:39<00:37,  3.27it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/225 [00:40<00:38,  3.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 103/225 [00:40<00:38,  3.17it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 104/225 [00:40<00:42,  2.86it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/225 [00:41<00:45,  2.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 106/225 [00:41<00:42,  2.81it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/225 [00:42<00:50,  2.35it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/225 [00:42<00:51,  2.28it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/225 [00:42<00:41,  2.82it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/225 [00:43<00:36,  3.12it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/225 [00:43<00:35,  3.17it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 112/225 [00:43<00:30,  3.73it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/225 [00:43<00:32,  3.40it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 114/225 [00:44<00:29,  3.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 115/225 [00:44<00:26,  4.19it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/225 [00:44<00:31,  3.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 117/225 [00:44<00:28,  3.80it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 118/225 [00:45<00:28,  3.72it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/225 [00:45<00:28,  3.73it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 120/225 [00:45<00:25,  4.12it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/225 [00:45<00:26,  3.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/225 [00:46<00:25,  4.07it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 123/225 [00:46<00:22,  4.51it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/225 [00:46<00:24,  4.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/225 [00:46<00:25,  3.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 126/225 [00:47<00:22,  4.34it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/225 [00:47<00:26,  3.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 128/225 [00:47<00:23,  4.06it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 129/225 [00:47<00:21,  4.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/225 [00:48<00:24,  3.92it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/225 [00:48<00:24,  3.82it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 132/225 [00:48<00:21,  4.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/225 [00:48<00:22,  4.07it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 134/225 [00:49<00:23,  3.81it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/225 [00:49<00:20,  4.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 136/225 [00:49<00:19,  4.64it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 137/225 [00:49<00:20,  4.22it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/225 [00:50<00:21,  4.02it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 139/225 [00:50<00:19,  4.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 140/225 [00:50<00:19,  4.31it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/225 [00:50<00:21,  3.94it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 142/225 [00:50<00:19,  4.34it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 143/225 [00:51<00:20,  3.95it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/225 [00:51<00:20,  3.99it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 145/225 [00:51<00:18,  4.39it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 146/225 [00:52<00:20,  3.77it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/225 [00:52<00:18,  4.13it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 148/225 [00:52<00:16,  4.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 149/225 [00:52<00:17,  4.39it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 150/225 [00:52<00:19,  3.90it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 151/225 [00:53<00:16,  4.37it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/225 [00:53<00:17,  4.22it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 153/225 [00:53<00:18,  3.85it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 154/225 [00:53<00:16,  4.34it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/225 [00:54<00:16,  4.21it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 156/225 [00:54<00:22,  3.06it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 157/225 [00:54<00:21,  3.11it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/225 [00:55<00:23,  2.79it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 159/225 [00:55<00:27,  2.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 160/225 [00:56<00:26,  2.46it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 161/225 [00:56<00:24,  2.59it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 162/225 [00:57<00:25,  2.44it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 163/225 [00:57<00:23,  2.66it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 164/225 [00:57<00:20,  3.01it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 165/225 [00:57<00:17,  3.50it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/225 [00:58<00:17,  3.40it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/225 [00:58<00:14,  3.93it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 168/225 [00:58<00:12,  4.45it/s]wandb: Network error resolved after 0:00:43.265234, resuming normal operation.
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/225 [00:58<00:14,  3.76it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 170/225 [00:59<00:13,  4.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 171/225 [00:59<00:11,  4.56it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/225 [00:59<00:13,  3.91it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 173/225 [00:59<00:12,  4.08it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 174/225 [00:59<00:11,  4.51it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/225 [01:00<00:12,  4.02it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 176/225 [01:00<00:12,  3.84it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 177/225 [01:00<00:11,  4.26it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 178/225 [01:01<00:13,  3.41it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/225 [01:01<00:11,  3.92it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/225 [01:01<00:10,  4.47it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/225 [01:01<00:10,  4.24it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 182/225 [01:02<00:10,  3.96it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/225 [01:02<00:09,  4.44it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 184/225 [01:02<00:09,  4.41it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 185/225 [01:02<00:09,  4.03it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 186/225 [01:02<00:08,  4.42it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/225 [01:03<00:09,  4.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 188/225 [01:03<00:09,  3.85it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/225 [01:03<00:08,  4.33it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 190/225 [01:03<00:07,  4.39it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 191/225 [01:04<00:08,  3.97it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 192/225 [01:04<00:07,  4.37it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 193/225 [01:04<00:08,  3.99it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 194/225 [01:04<00:08,  3.87it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/225 [01:05<00:07,  4.21it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 196/225 [01:05<00:07,  3.78it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/225 [01:05<00:06,  4.17it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/225 [01:05<00:05,  4.68it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 199/225 [01:05<00:05,  4.72it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/225 [01:06<00:06,  4.11it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 201/225 [01:06<00:05,  4.63it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 202/225 [01:06<00:06,  3.76it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/225 [01:07<00:05,  3.97it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/225 [01:07<00:04,  4.54it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 205/225 [01:07<00:05,  3.86it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 206/225 [01:07<00:04,  4.14it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/225 [01:07<00:04,  4.47it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 208/225 [01:08<00:04,  3.98it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/225 [01:08<00:03,  4.38it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 210/225 [01:08<00:03,  4.19it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/225 [01:09<00:04,  3.35it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 212/225 [01:09<00:04,  3.14it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 213/225 [01:09<00:03,  3.10it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 214/225 [01:10<00:03,  3.17it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 215/225 [01:10<00:03,  3.23it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 216/225 [01:10<00:02,  3.21it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/225 [01:11<00:02,  3.08it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 218/225 [01:11<00:02,  3.15it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 219/225 [01:11<00:01,  3.69it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 220/225 [01:11<00:01,  4.25it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/225 [01:11<00:00,  4.71it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 222/225 [01:12<00:00,  5.06it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/225 [01:12<00:00,  5.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 224/225 [01:12<00:00,  5.40it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:12<00:00,  5.67it/s][INFO|trainer.py:1409] 2021-11-26 15:58:19,407 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 77.9459, 'train_samples_per_second': 368.781, 'train_steps_per_second': 2.887, 'train_loss': 7.265616319444445, 'epoch': 5.0}100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:12<00:00,  5.67it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:12<00:00,  3.10it/s]

[INFO|trainer.py:1995] 2021-11-26 15:58:19,522 >> Saving model checkpoint to ./models/stsb/exit5
[INFO|configuration_utils.py:417] 2021-11-26 15:58:19,526 >> Configuration saved in ./models/stsb/exit5/config.json
[INFO|modeling_utils.py:1058] 2021-11-26 15:58:22,096 >> Model weights saved in ./models/stsb/exit5/pytorch_model.bin
[INFO|tokenization_utils_base.py:2034] 2021-11-26 15:58:22,104 >> tokenizer config file saved in ./models/stsb/exit5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2040] 2021-11-26 15:58:22,107 >> Special tokens file saved in ./models/stsb/exit5/special_tokens_map.json
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     7.2656
  train_runtime            = 0:01:17.94
  train_samples            =       5749
  train_samples_per_second =    368.781
  train_steps_per_second   =      2.887

11/26/2021 15:58:22 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:541] 2021-11-26 15:58:22,302 >> The following columns in the evaluation set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, idx, sentence2.
[INFO|trainer.py:2243] 2021-11-26 15:58:22,308 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2021-11-26 15:58:22,308 >>   Num examples = 1500
[INFO|trainer.py:2248] 2021-11-26 15:58:22,308 >>   Batch size = 32
  0%|          | 0/47 [00:00<?, ?it/s]  6%|‚ñã         | 3/47 [00:00<00:01, 25.43it/s] 13%|‚ñà‚ñé        | 6/47 [00:00<00:02, 17.22it/s] 17%|‚ñà‚ñã        | 8/47 [00:00<00:02, 15.71it/s] 21%|‚ñà‚ñà‚ñè       | 10/47 [00:00<00:02, 15.23it/s] 26%|‚ñà‚ñà‚ñå       | 12/47 [00:00<00:02, 14.39it/s] 30%|‚ñà‚ñà‚ñâ       | 14/47 [00:00<00:02, 13.99it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 16/47 [00:01<00:02, 13.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 18/47 [00:01<00:02, 13.04it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 20/47 [00:01<00:02, 12.20it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 22/47 [00:01<00:01, 12.68it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 24/47 [00:01<00:01, 13.39it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 26/47 [00:01<00:01, 13.93it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 28/47 [00:01<00:01, 14.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 30/47 [00:02<00:01, 15.04it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 32/47 [00:02<00:01, 13.79it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 34/47 [00:02<00:01, 11.30it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 36/47 [00:02<00:00, 11.96it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 38/47 [00:02<00:00, 13.13it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 40/47 [00:03<00:00,  9.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 42/47 [00:03<00:00, 10.82it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 44/47 [00:03<00:00, 12.21it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 46/47 [00:03<00:00, 12.86it/s]11/26/2021 15:58:26 - INFO - datasets.metric - Removing /home/slzhang/.cache/huggingface/metrics/glue/stsb/default_experiment-1-0.arrow
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:03<00:00, 12.69it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_combined_score     =     0.5092
  eval_loss               =     4.4283
  eval_pearson            =      0.503
  eval_runtime            = 0:00:03.75
  eval_samples            =       1500
  eval_samples_per_second =    399.978
  eval_spearmanr          =     0.5153
  eval_steps_per_second   =     12.533
wandb: Waiting for W&B process to finish, PID 3579891
wandb: Program ended successfully.
wandb: - 0.03MB of 0.03MB uploaded (0.00MB deduped)wandb: \ 0.06MB of 0.06MB uploaded (0.00MB deduped)wandb: | 0.06MB of 0.06MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155703-w39b7sba/logs/debug.log
wandb: Find internal logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155703-w39b7sba/logs/debug-internal.log
wandb: Run summary:
wandb:              train/train_runtime 77.9459
wandb:   train/train_samples_per_second 368.781
wandb:     train/train_steps_per_second 2.887
wandb:                 train/total_flos 795453870693120.0
wandb:                 train/train_loss 7.26562
wandb:                      train/epoch 5.0
wandb:                train/global_step 225
wandb:                         _runtime 83
wandb:                       _timestamp 1637913506
wandb:                            _step 1
wandb:                        eval/loss 4.42832
wandb:                     eval/pearson 0.50298
wandb:                   eval/spearmanr 0.51533
wandb:              eval/combined_score 0.50915
wandb:                     eval/runtime 3.7502
wandb:          eval/samples_per_second 399.978
wandb:            eval/steps_per_second 12.533
wandb: Run history:
wandb:              train/train_runtime ‚ñÅ
wandb:   train/train_samples_per_second ‚ñÅ
wandb:     train/train_steps_per_second ‚ñÅ
wandb:                 train/total_flos ‚ñÅ
wandb:                 train/train_loss ‚ñÅ
wandb:                      train/epoch ‚ñÅ‚ñÅ
wandb:                train/global_step ‚ñÅ‚ñÅ
wandb:                         _runtime ‚ñÅ‚ñà
wandb:                       _timestamp ‚ñÅ‚ñà
wandb:                            _step ‚ñÅ‚ñà
wandb:                        eval/loss ‚ñÅ
wandb:                     eval/pearson ‚ñÅ
wandb:                   eval/spearmanr ‚ñÅ
wandb:              eval/combined_score ‚ñÅ
wandb:                     eval/runtime ‚ñÅ
wandb:          eval/samples_per_second ‚ñÅ
wandb:            eval/steps_per_second ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ./models/stsb/exit5: https://wandb.ai/zsl/huggingface/runs/w39b7sba

11/26/2021 15:58:41 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 15:58:41 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit6/runs/Nov26_15-58-40_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit6,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit6,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 15:58:42 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue
11/26/2021 15:58:42 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:58:42 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.py
11/26/2021 15:58:42 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/dataset_infos.json to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/dataset_infos.json
11/26/2021 15:58:42 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.json
11/26/2021 15:58:43 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:58:43 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 15:58:43 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 15:58:43 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 15:58:43 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 300.34it/s]
[INFO|configuration_utils.py:588] 2021-11-26 15:58:43,827 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:58:43,828 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 15:58:45,601 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:58:45,603 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:58:50,510 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/slzhang/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:58:50,510 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/slzhang/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:58:50,511 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:58:50,511 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 15:58:50,511 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/slzhang/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:588] 2021-11-26 15:58:51,315 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 15:58:51,317 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1340] 2021-11-26 15:58:52,160 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/slzhang/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1597] 2021-11-26 15:58:54,426 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertWithSinglehead: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertWithSinglehead from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertWithSinglehead from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1608] 2021-11-26 15:58:54,426 >> Some weights of BertWithSinglehead were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['s1_classifier.bias', 's1_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/26/2021 15:58:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecb0af5ac5f5f4cf.arrow
11/26/2021 15:58:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f66158b4c3938527.arrow
11/26/2021 15:58:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8d605fec10ae3523.arrow
11/26/2021 15:58:55 - INFO - __main__ - Sample 5238 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 5238, 'input_ids': [101, 2966, 2852, 12952, 24373, 1113, 7303, 102, 7661, 112, 188, 1285, 131, 3460, 1159, 1113, 7303, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1.600000023841858, 'sentence1': 'Didier Reynders on Syria', 'sentence2': "Obama's day: Prime time on Syria", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:58:55 - INFO - __main__ - Sample 912 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 912, 'input_ids': [101, 138, 1299, 1110, 9374, 1103, 3751, 119, 102, 138, 1299, 1110, 3759, 170, 1610, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0.4000000059604645, 'sentence1': 'A man is cleaning the windows.', 'sentence2': 'A man is driving a car.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:58:55 - INFO - __main__ - Sample 204 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 204, 'input_ids': [101, 138, 1590, 3486, 170, 24181, 12253, 24886, 119, 102, 138, 1590, 1110, 8184, 1146, 170, 24181, 12253, 24886, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 3.25, 'sentence1': 'A woman holds a kangaroo.', 'sentence2': 'A woman is picking up a kangaroo.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 15:58:58 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue
11/26/2021 15:58:58 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981
11/26/2021 15:58:58 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.py
11/26/2021 15:58:58 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/dataset_infos.json
11/26/2021 15:58:58 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.json
[INFO|trainer.py:541] 2021-11-26 15:59:05,161 >> The following columns in the training set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, sentence2, idx.
[INFO|trainer.py:1196] 2021-11-26 15:59:05,183 >> ***** Running training *****
[INFO|trainer.py:1197] 2021-11-26 15:59:05,183 >>   Num examples = 5749
[INFO|trainer.py:1198] 2021-11-26 15:59:05,183 >>   Num Epochs = 5
[INFO|trainer.py:1199] 2021-11-26 15:59:05,183 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2021-11-26 15:59:05,183 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:1201] 2021-11-26 15:59:05,185 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2021-11-26 15:59:05,185 >>   Total optimization steps = 225
[INFO|integrations.py:501] 2021-11-26 15:59:05,216 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: W&B API key is configured (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.10.22
wandb: Syncing run ./models/stsb/exit6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zsl/huggingface
wandb: üöÄ View run at https://wandb.ai/zsl/huggingface/runs/2icp3wr6
wandb: Run data is saved locally in /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155911-2icp3wr6
wandb: Run `wandb offline` to turn off syncing.
  0%|          | 0/225 [00:00<?, ?it/s]/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/225 [00:15<56:53, 15.24s/it]  1%|          | 2/225 [00:15<23:44,  6.39s/it]  1%|‚ñè         | 3/225 [00:15<13:08,  3.55s/it]  2%|‚ñè         | 4/225 [00:15<08:10,  2.22s/it]  2%|‚ñè         | 5/225 [00:15<05:26,  1.49s/it]  3%|‚ñé         | 6/225 [00:16<03:48,  1.04s/it]  3%|‚ñé         | 7/225 [00:16<02:46,  1.31it/s]  4%|‚ñé         | 8/225 [00:16<02:05,  1.74it/s]  4%|‚ñç         | 9/225 [00:16<01:39,  2.18it/s]  4%|‚ñç         | 10/225 [00:16<01:24,  2.55it/s]  5%|‚ñç         | 11/225 [00:17<01:10,  3.04it/s]  5%|‚ñå         | 12/225 [00:17<01:06,  3.19it/s]  6%|‚ñå         | 13/225 [00:17<01:05,  3.25it/s]  6%|‚ñå         | 14/225 [00:17<00:56,  3.74it/s]  7%|‚ñã         | 15/225 [00:18<01:03,  3.30it/s]  7%|‚ñã         | 16/225 [00:18<00:56,  3.68it/s]  8%|‚ñä         | 17/225 [00:18<00:51,  4.07it/s]  8%|‚ñä         | 18/225 [00:19<01:13,  2.80it/s]  8%|‚ñä         | 19/225 [00:19<01:17,  2.65it/s]  9%|‚ñâ         | 20/225 [00:20<01:15,  2.71it/s]  9%|‚ñâ         | 21/225 [00:20<01:31,  2.24it/s] 10%|‚ñâ         | 22/225 [00:21<01:35,  2.12it/s] 10%|‚ñà         | 23/225 [00:21<01:34,  2.15it/s] 11%|‚ñà         | 24/225 [00:22<01:40,  2.01it/s] 11%|‚ñà         | 25/225 [00:22<01:22,  2.42it/s] 12%|‚ñà‚ñè        | 26/225 [00:22<01:09,  2.88it/s] 12%|‚ñà‚ñè        | 27/225 [00:23<01:14,  2.66it/s] 12%|‚ñà‚ñè        | 28/225 [00:23<01:05,  3.01it/s] 13%|‚ñà‚ñé        | 29/225 [00:23<00:56,  3.46it/s] 13%|‚ñà‚ñé        | 30/225 [00:23<01:00,  3.21it/s] 14%|‚ñà‚ñç        | 31/225 [00:24<00:55,  3.48it/s] 14%|‚ñà‚ñç        | 32/225 [00:24<00:48,  3.96it/s] 15%|‚ñà‚ñç        | 33/225 [00:24<00:50,  3.83it/s] 15%|‚ñà‚ñå        | 34/225 [00:24<00:50,  3.78it/s] 16%|‚ñà‚ñå        | 35/225 [00:25<00:46,  4.09it/s] 16%|‚ñà‚ñå        | 36/225 [00:25<00:55,  3.39it/s] 16%|‚ñà‚ñã        | 37/225 [00:25<00:49,  3.82it/s] 17%|‚ñà‚ñã        | 38/225 [00:25<00:45,  4.14it/s] 17%|‚ñà‚ñã        | 39/225 [00:26<00:52,  3.54it/s] 18%|‚ñà‚ñä        | 40/225 [00:26<00:46,  3.94it/s] 18%|‚ñà‚ñä        | 41/225 [00:26<00:44,  4.15it/s] 19%|‚ñà‚ñä        | 42/225 [00:26<00:46,  3.90it/s] 19%|‚ñà‚ñâ        | 43/225 [00:27<00:48,  3.77it/s] 20%|‚ñà‚ñâ        | 44/225 [00:27<00:43,  4.18it/s] 20%|‚ñà‚ñà        | 45/225 [00:27<00:47,  3.83it/s] 20%|‚ñà‚ñà        | 46/225 [00:27<00:48,  3.70it/s] 21%|‚ñà‚ñà        | 47/225 [00:28<00:43,  4.11it/s] 21%|‚ñà‚ñà‚ñè       | 48/225 [00:28<00:54,  3.27it/s] 22%|‚ñà‚ñà‚ñè       | 49/225 [00:28<00:47,  3.69it/s] 22%|‚ñà‚ñà‚ñè       | 50/225 [00:28<00:44,  3.90it/s] 23%|‚ñà‚ñà‚ñé       | 51/225 [00:29<00:49,  3.55it/s] 23%|‚ñà‚ñà‚ñé       | 52/225 [00:29<00:44,  3.86it/s] 24%|‚ñà‚ñà‚ñé       | 53/225 [00:29<00:51,  3.37it/s] 24%|‚ñà‚ñà‚ñç       | 54/225 [00:30<00:45,  3.76it/s] 24%|‚ñà‚ñà‚ñç       | 55/225 [00:30<00:40,  4.16it/s] 25%|‚ñà‚ñà‚ñç       | 56/225 [00:30<00:48,  3.46it/s] 25%|‚ñà‚ñà‚ñå       | 57/225 [00:30<00:46,  3.60it/s] 26%|‚ñà‚ñà‚ñå       | 58/225 [00:31<00:41,  4.02it/s] 26%|‚ñà‚ñà‚ñå       | 59/225 [00:31<00:47,  3.51it/s] 27%|‚ñà‚ñà‚ñã       | 60/225 [00:31<00:43,  3.83it/s] 27%|‚ñà‚ñà‚ñã       | 61/225 [00:31<00:38,  4.23it/s] 28%|‚ñà‚ñà‚ñä       | 62/225 [00:32<00:44,  3.65it/s] 28%|‚ñà‚ñà‚ñä       | 63/225 [00:32<00:42,  3.80it/s] 28%|‚ñà‚ñà‚ñä       | 64/225 [00:32<00:38,  4.21it/s] 29%|‚ñà‚ñà‚ñâ       | 65/225 [00:33<00:44,  3.63it/s] 29%|‚ñà‚ñà‚ñâ       | 66/225 [00:33<00:40,  3.96it/s] 30%|‚ñà‚ñà‚ñâ       | 67/225 [00:33<00:36,  4.32it/s] 30%|‚ñà‚ñà‚ñà       | 68/225 [00:33<00:46,  3.35it/s] 31%|‚ñà‚ñà‚ñà       | 69/225 [00:34<00:53,  2.91it/s] 31%|‚ñà‚ñà‚ñà       | 70/225 [00:34<00:59,  2.62it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/225 [00:35<01:09,  2.22it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 72/225 [00:35<01:08,  2.22it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 73/225 [00:36<01:15,  2.01it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 74/225 [00:36<01:09,  2.18it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 75/225 [00:37<01:16,  1.95it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 76/225 [00:37<01:00,  2.45it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 77/225 [00:37<00:54,  2.71it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 78/225 [00:38<00:50,  2.89it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 79/225 [00:38<00:43,  3.36it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 80/225 [00:38<00:39,  3.67it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 81/225 [00:38<00:44,  3.26it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 82/225 [00:39<00:38,  3.68it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/225 [00:39<00:42,  3.37it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 84/225 [00:39<00:38,  3.67it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/225 [00:39<00:33,  4.13it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 86/225 [00:40<00:39,  3.56it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 87/225 [00:40<00:37,  3.69it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 88/225 [00:40<00:34,  4.01it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/225 [00:41<00:40,  3.36it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 90/225 [00:41<00:35,  3.84it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 91/225 [00:41<00:35,  3.82it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 92/225 [00:41<00:36,  3.69it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/225 [00:42<00:32,  4.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/225 [00:42<00:36,  3.63it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/225 [00:42<00:34,  3.76it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/225 [00:42<00:30,  4.17it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/225 [00:43<00:33,  3.83it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 98/225 [00:43<00:34,  3.63it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/225 [00:43<00:31,  4.02it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 100/225 [00:44<00:36,  3.46it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 101/225 [00:44<00:32,  3.82it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/225 [00:44<00:29,  4.18it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 103/225 [00:44<00:36,  3.35it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 104/225 [00:45<00:32,  3.70it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/225 [00:45<00:29,  4.13it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 106/225 [00:45<00:27,  4.30it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/225 [00:45<00:32,  3.62it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/225 [00:45<00:29,  4.01it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/225 [00:46<00:30,  3.80it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/225 [00:46<00:31,  3.60it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/225 [00:46<00:28,  3.99it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 112/225 [00:47<00:32,  3.47it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/225 [00:47<00:29,  3.77it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 114/225 [00:47<00:32,  3.43it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 115/225 [00:47<00:30,  3.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/225 [00:48<00:26,  4.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 117/225 [00:48<00:33,  3.25it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 118/225 [00:48<00:30,  3.54it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/225 [00:49<00:27,  3.92it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 120/225 [00:49<00:37,  2.83it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/225 [00:50<00:38,  2.67it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/225 [00:50<00:43,  2.36it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 123/225 [00:51<00:47,  2.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/225 [00:51<00:44,  2.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/225 [00:52<00:49,  2.02it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 126/225 [00:52<00:46,  2.12it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/225 [00:52<00:43,  2.25it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 128/225 [00:53<00:38,  2.50it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 129/225 [00:53<00:32,  2.98it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/225 [00:53<00:28,  3.31it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/225 [00:53<00:29,  3.16it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 132/225 [00:54<00:25,  3.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/225 [00:54<00:29,  3.12it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 134/225 [00:54<00:25,  3.59it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/225 [00:55<00:26,  3.35it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 136/225 [00:55<00:24,  3.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 137/225 [00:55<00:21,  4.16it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/225 [00:55<00:24,  3.59it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 139/225 [00:56<00:21,  4.01it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 140/225 [00:56<00:19,  4.43it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/225 [00:56<00:20,  4.20it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 142/225 [00:56<00:18,  4.57it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 143/225 [00:56<00:16,  4.85it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/225 [00:57<00:16,  5.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 145/225 [00:57<00:15,  5.29it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 146/225 [00:57<00:14,  5.44it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/225 [00:57<00:13,  5.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 148/225 [00:57<00:13,  5.64it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 149/225 [00:57<00:13,  5.68it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 150/225 [00:58<00:12,  5.78it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 151/225 [00:58<00:12,  5.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/225 [00:58<00:12,  5.86it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 153/225 [00:58<00:12,  5.91it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 154/225 [00:58<00:12,  5.85it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/225 [00:58<00:12,  5.83it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 156/225 [00:59<00:11,  5.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 157/225 [00:59<00:11,  5.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/225 [00:59<00:11,  5.82it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 159/225 [00:59<00:11,  5.83it/s]wandb: Network error (ConnectionError), entering retry loop. See wandb/debug-internal.log for full traceback.
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 160/225 [00:59<00:11,  5.70it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 161/225 [00:59<00:11,  5.67it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 162/225 [01:00<00:11,  5.66it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 163/225 [01:00<00:11,  5.60it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 164/225 [01:00<00:11,  5.50it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 165/225 [01:00<00:11,  5.01it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/225 [01:01<00:13,  4.40it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/225 [01:01<00:13,  4.40it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 168/225 [01:01<00:12,  4.64it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/225 [01:01<00:12,  4.62it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 170/225 [01:01<00:12,  4.48it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 171/225 [01:02<00:11,  4.65it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/225 [01:02<00:10,  4.89it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 173/225 [01:02<00:10,  5.04it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 174/225 [01:02<00:11,  4.32it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/225 [01:03<00:13,  3.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 176/225 [01:03<00:14,  3.43it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 177/225 [01:03<00:14,  3.22it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 178/225 [01:04<00:18,  2.50it/s]wandb: Network error resolved after 0:00:33.389929, resuming normal operation.
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/225 [01:04<00:17,  2.62it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/225 [01:05<00:18,  2.48it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/225 [01:05<00:19,  2.21it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 182/225 [01:05<00:16,  2.69it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/225 [01:06<00:14,  2.96it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 184/225 [01:06<00:14,  2.90it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 185/225 [01:06<00:11,  3.34it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 186/225 [01:07<00:13,  2.97it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/225 [01:07<00:11,  3.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 188/225 [01:07<00:09,  3.80it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/225 [01:07<00:11,  3.25it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 190/225 [01:08<00:09,  3.71it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 191/225 [01:08<00:09,  3.75it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 192/225 [01:08<00:09,  3.50it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 193/225 [01:08<00:08,  3.89it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 194/225 [01:09<00:09,  3.41it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/225 [01:09<00:08,  3.66it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 196/225 [01:09<00:07,  3.97it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/225 [01:10<00:08,  3.27it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/225 [01:10<00:07,  3.70it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 199/225 [01:10<00:07,  3.44it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/225 [01:10<00:06,  3.69it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 201/225 [01:11<00:05,  4.08it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 202/225 [01:11<00:06,  3.38it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/225 [01:11<00:05,  3.67it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/225 [01:11<00:05,  4.05it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 205/225 [01:12<00:04,  4.08it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 206/225 [01:12<00:05,  3.76it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/225 [01:12<00:04,  4.06it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 208/225 [01:12<00:04,  4.14it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/225 [01:13<00:04,  3.46it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 210/225 [01:13<00:03,  3.86it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/225 [01:13<00:04,  3.43it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 212/225 [01:14<00:03,  3.65it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 213/225 [01:14<00:02,  4.12it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 214/225 [01:14<00:03,  3.51it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 215/225 [01:14<00:02,  3.80it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 216/225 [01:15<00:02,  4.22it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/225 [01:15<00:02,  3.75it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 218/225 [01:15<00:01,  3.91it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 219/225 [01:15<00:01,  4.26it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 220/225 [01:16<00:01,  3.60it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/225 [01:16<00:01,  3.98it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 222/225 [01:16<00:00,  4.32it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/225 [01:17<00:00,  3.39it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 224/225 [01:17<00:00,  3.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:17<00:00,  3.91it/s][INFO|trainer.py:1409] 2021-11-26 16:00:38,104 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 92.9192, 'train_samples_per_second': 309.355, 'train_steps_per_second': 2.421, 'train_loss': 6.364436306423611, 'epoch': 5.0}100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:17<00:00,  3.91it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:17<00:00,  2.90it/s]
[INFO|trainer.py:1995] 2021-11-26 16:00:38,229 >> Saving model checkpoint to ./models/stsb/exit6
[INFO|configuration_utils.py:417] 2021-11-26 16:00:38,233 >> Configuration saved in ./models/stsb/exit6/config.json
[INFO|modeling_utils.py:1058] 2021-11-26 16:00:41,400 >> Model weights saved in ./models/stsb/exit6/pytorch_model.bin
[INFO|tokenization_utils_base.py:2034] 2021-11-26 16:00:41,405 >> tokenizer config file saved in ./models/stsb/exit6/tokenizer_config.json
[INFO|tokenization_utils_base.py:2040] 2021-11-26 16:00:41,407 >> Special tokens file saved in ./models/stsb/exit6/special_tokens_map.json
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     6.3644
  train_runtime            = 0:01:32.91
  train_samples            =       5749
  train_samples_per_second =    309.355
  train_steps_per_second   =      2.421

11/26/2021 16:00:41 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:541] 2021-11-26 16:00:41,634 >> The following columns in the evaluation set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, sentence2, idx.
[INFO|trainer.py:2243] 2021-11-26 16:00:41,644 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2021-11-26 16:00:41,644 >>   Num examples = 1500
[INFO|trainer.py:2248] 2021-11-26 16:00:41,645 >>   Batch size = 32
  0%|          | 0/47 [00:00<?, ?it/s]  4%|‚ñç         | 2/47 [00:00<00:03, 11.64it/s]  9%|‚ñä         | 4/47 [00:00<00:03, 12.77it/s] 13%|‚ñà‚ñé        | 6/47 [00:00<00:04, 10.07it/s] 17%|‚ñà‚ñã        | 8/47 [00:00<00:04,  8.58it/s] 21%|‚ñà‚ñà‚ñè       | 10/47 [00:00<00:03, 10.09it/s] 26%|‚ñà‚ñà‚ñå       | 12/47 [00:01<00:03,  9.49it/s] 30%|‚ñà‚ñà‚ñâ       | 14/47 [00:01<00:03,  8.64it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 15/47 [00:01<00:04,  7.53it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 16/47 [00:01<00:04,  7.42it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 17/47 [00:02<00:04,  6.53it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 19/47 [00:02<00:03,  8.47it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 21/47 [00:02<00:02, 10.20it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 23/47 [00:02<00:02,  9.51it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 25/47 [00:02<00:02,  8.45it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 27/47 [00:02<00:02,  9.70it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 29/47 [00:03<00:02,  8.67it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 30/47 [00:03<00:01,  8.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 32/47 [00:03<00:01,  9.91it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 34/47 [00:03<00:01,  8.85it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 35/47 [00:04<00:01,  7.68it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 37/47 [00:04<00:01,  9.28it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 39/47 [00:04<00:00, 10.35it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 41/47 [00:04<00:00,  8.35it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 43/47 [00:04<00:00,  9.67it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 45/47 [00:04<00:00, 10.87it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:05<00:00, 11.53it/s]11/26/2021 16:00:46 - INFO - datasets.metric - Removing /home/slzhang/.cache/huggingface/metrics/glue/stsb/default_experiment-1-0.arrow
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:05<00:00,  9.20it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_combined_score     =     0.6786
  eval_loss               =     3.7469
  eval_pearson            =     0.6779
  eval_runtime            = 0:00:05.24
  eval_samples            =       1500
  eval_samples_per_second =    285.873
  eval_spearmanr          =     0.6793
  eval_steps_per_second   =      8.957
wandb: Waiting for W&B process to finish, PID 3583157
wandb: Program ended successfully.
wandb: - 0.04MB of 0.04MB uploaded (0.00MB deduped)wandb: \ 0.04MB of 0.06MB uploaded (0.00MB deduped)wandb: | 0.06MB of 0.06MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155911-2icp3wr6/logs/debug.log
wandb: Find internal logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_155911-2icp3wr6/logs/debug-internal.log
wandb: Run summary:
wandb:              train/train_runtime 92.9192
wandb:   train/train_samples_per_second 309.355
wandb:     train/train_steps_per_second 2.421
wandb:                 train/total_flos 951926867024640.0
wandb:                 train/train_loss 6.36444
wandb:                      train/epoch 5.0
wandb:                train/global_step 225
wandb:                         _runtime 95
wandb:                       _timestamp 1637913646
wandb:                            _step 1
wandb:                        eval/loss 3.74693
wandb:                     eval/pearson 0.6779
wandb:                   eval/spearmanr 0.67927
wandb:              eval/combined_score 0.67858
wandb:                     eval/runtime 5.2471
wandb:          eval/samples_per_second 285.873
wandb:            eval/steps_per_second 8.957
wandb: Run history:
wandb:              train/train_runtime ‚ñÅ
wandb:   train/train_samples_per_second ‚ñÅ
wandb:     train/train_steps_per_second ‚ñÅ
wandb:                 train/total_flos ‚ñÅ
wandb:                 train/train_loss ‚ñÅ
wandb:                      train/epoch ‚ñÅ‚ñÅ
wandb:                train/global_step ‚ñÅ‚ñÅ
wandb:                         _runtime ‚ñÅ‚ñà
wandb:                       _timestamp ‚ñÅ‚ñà
wandb:                            _step ‚ñÅ‚ñà
wandb:                        eval/loss ‚ñÅ
wandb:                     eval/pearson ‚ñÅ
wandb:                   eval/spearmanr ‚ñÅ
wandb:              eval/combined_score ‚ñÅ
wandb:                     eval/runtime ‚ñÅ
wandb:          eval/samples_per_second ‚ñÅ
wandb:            eval/steps_per_second ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ./models/stsb/exit6: https://wandb.ai/zsl/huggingface/runs/2icp3wr6

11/26/2021 16:01:01 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 16:01:01 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit7/runs/Nov26_16-01-01_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit7,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit7,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 16:01:03 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue
11/26/2021 16:01:03 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:01:03 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.py
11/26/2021 16:01:03 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/dataset_infos.json to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/dataset_infos.json
11/26/2021 16:01:03 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.json
11/26/2021 16:01:03 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:01:03 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 16:01:03 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:01:03 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 16:01:03 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 253.02it/s]
[INFO|configuration_utils.py:588] 2021-11-26 16:01:04,591 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:01:04,592 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 16:01:06,420 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:01:06,421 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:01:11,449 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/slzhang/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:01:11,449 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/slzhang/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:01:11,449 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:01:11,449 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:01:11,449 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/slzhang/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:588] 2021-11-26 16:01:12,280 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:01:12,281 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1340] 2021-11-26 16:01:13,151 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/slzhang/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1597] 2021-11-26 16:01:15,364 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertWithSinglehead: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertWithSinglehead from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertWithSinglehead from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1608] 2021-11-26 16:01:15,364 >> Some weights of BertWithSinglehead were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['s1_classifier.bias', 's1_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/26/2021 16:01:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecb0af5ac5f5f4cf.arrow
11/26/2021 16:01:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f66158b4c3938527.arrow
11/26/2021 16:01:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8d605fec10ae3523.arrow
11/26/2021 16:01:17 - INFO - __main__ - Sample 5238 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 5238, 'input_ids': [101, 2966, 2852, 12952, 24373, 1113, 7303, 102, 7661, 112, 188, 1285, 131, 3460, 1159, 1113, 7303, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1.600000023841858, 'sentence1': 'Didier Reynders on Syria', 'sentence2': "Obama's day: Prime time on Syria", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:01:17 - INFO - __main__ - Sample 912 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 912, 'input_ids': [101, 138, 1299, 1110, 9374, 1103, 3751, 119, 102, 138, 1299, 1110, 3759, 170, 1610, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0.4000000059604645, 'sentence1': 'A man is cleaning the windows.', 'sentence2': 'A man is driving a car.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:01:17 - INFO - __main__ - Sample 204 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 204, 'input_ids': [101, 138, 1590, 3486, 170, 24181, 12253, 24886, 119, 102, 138, 1590, 1110, 8184, 1146, 170, 24181, 12253, 24886, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 3.25, 'sentence1': 'A woman holds a kangaroo.', 'sentence2': 'A woman is picking up a kangaroo.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:01:19 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue
11/26/2021 16:01:19 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981
11/26/2021 16:01:19 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.py
11/26/2021 16:01:19 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/dataset_infos.json
11/26/2021 16:01:19 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.json
[INFO|trainer.py:541] 2021-11-26 16:01:26,927 >> The following columns in the training set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, idx, sentence2.
[INFO|trainer.py:1196] 2021-11-26 16:01:26,951 >> ***** Running training *****
[INFO|trainer.py:1197] 2021-11-26 16:01:26,951 >>   Num examples = 5749
[INFO|trainer.py:1198] 2021-11-26 16:01:26,952 >>   Num Epochs = 5
[INFO|trainer.py:1199] 2021-11-26 16:01:26,952 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2021-11-26 16:01:26,952 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:1201] 2021-11-26 16:01:26,952 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2021-11-26 16:01:26,952 >>   Total optimization steps = 225
[INFO|integrations.py:501] 2021-11-26 16:01:26,990 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: zsl (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.22
wandb: Syncing run ./models/stsb/exit7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zsl/huggingface
wandb: üöÄ View run at https://wandb.ai/zsl/huggingface/runs/25f0b3k4
wandb: Run data is saved locally in /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_160128-25f0b3k4
wandb: Run `wandb offline` to turn off syncing.
  0%|          | 0/225 [00:00<?, ?it/s]/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/225 [00:14<54:47, 14.68s/it]  1%|          | 2/225 [00:15<23:50,  6.41s/it]  1%|‚ñè         | 3/225 [00:15<13:52,  3.75s/it]  2%|‚ñè         | 4/225 [00:16<09:14,  2.51s/it]  2%|‚ñè         | 5/225 [00:16<06:22,  1.74s/it]  3%|‚ñé         | 6/225 [00:17<04:56,  1.35s/it]  3%|‚ñé         | 7/225 [00:17<03:49,  1.05s/it]  4%|‚ñé         | 8/225 [00:18<02:54,  1.24it/s]  4%|‚ñç         | 9/225 [00:18<02:24,  1.50it/s]  4%|‚ñç         | 10/225 [00:18<01:54,  1.88it/s]  5%|‚ñç         | 11/225 [00:19<01:47,  2.00it/s]  5%|‚ñå         | 12/225 [00:19<01:27,  2.44it/s]  6%|‚ñå         | 13/225 [00:19<01:19,  2.68it/s]  6%|‚ñå         | 14/225 [00:20<01:17,  2.74it/s]  7%|‚ñã         | 15/225 [00:20<01:26,  2.43it/s]  7%|‚ñã         | 16/225 [00:20<01:16,  2.74it/s]  8%|‚ñä         | 17/225 [00:21<01:06,  3.13it/s]  8%|‚ñä         | 18/225 [00:21<01:11,  2.90it/s]  8%|‚ñä         | 19/225 [00:21<01:01,  3.33it/s]  9%|‚ñâ         | 20/225 [00:22<01:06,  3.06it/s]  9%|‚ñâ         | 21/225 [00:22<01:02,  3.24it/s] 10%|‚ñâ         | 22/225 [00:22<00:55,  3.64it/s] 10%|‚ñà         | 23/225 [00:22<00:51,  3.92it/s] 11%|‚ñà         | 24/225 [00:23<00:59,  3.36it/s] 11%|‚ñà         | 25/225 [00:23<00:54,  3.67it/s] 12%|‚ñà‚ñè        | 26/225 [00:23<01:03,  3.12it/s] 12%|‚ñà‚ñè        | 27/225 [00:23<00:59,  3.34it/s] 12%|‚ñà‚ñè        | 28/225 [00:24<00:52,  3.73it/s] 13%|‚ñà‚ñé        | 29/225 [00:24<00:57,  3.39it/s] 13%|‚ñà‚ñé        | 30/225 [00:24<00:52,  3.74it/s] 14%|‚ñà‚ñç        | 31/225 [00:24<00:47,  4.05it/s] 14%|‚ñà‚ñç        | 32/225 [00:25<00:58,  3.32it/s] 15%|‚ñà‚ñç        | 33/225 [00:25<00:51,  3.70it/s] 15%|‚ñà‚ñå        | 34/225 [00:25<00:59,  3.21it/s] 16%|‚ñà‚ñå        | 35/225 [00:26<00:53,  3.54it/s] 16%|‚ñà‚ñå        | 36/225 [00:26<00:48,  3.90it/s] 16%|‚ñà‚ñã        | 37/225 [00:26<00:52,  3.55it/s] 17%|‚ñà‚ñã        | 38/225 [00:26<00:51,  3.64it/s] 17%|‚ñà‚ñã        | 39/225 [00:27<00:46,  4.00it/s] 18%|‚ñà‚ñä        | 40/225 [00:27<00:52,  3.50it/s] 18%|‚ñà‚ñä        | 41/225 [00:27<00:48,  3.78it/s] 19%|‚ñà‚ñä        | 42/225 [00:28<00:48,  3.79it/s] 19%|‚ñà‚ñâ        | 43/225 [00:28<00:53,  3.38it/s] 20%|‚ñà‚ñâ        | 44/225 [00:28<00:48,  3.73it/s] 20%|‚ñà‚ñà        | 45/225 [00:28<00:53,  3.38it/s] 20%|‚ñà‚ñà        | 46/225 [00:29<00:49,  3.65it/s] 21%|‚ñà‚ñà        | 47/225 [00:29<00:45,  3.93it/s] 21%|‚ñà‚ñà‚ñè       | 48/225 [00:29<00:46,  3.79it/s] 22%|‚ñà‚ñà‚ñè       | 49/225 [00:29<00:47,  3.72it/s] 22%|‚ñà‚ñà‚ñè       | 50/225 [00:30<00:44,  3.92it/s] 23%|‚ñà‚ñà‚ñé       | 51/225 [00:30<01:03,  2.75it/s] 23%|‚ñà‚ñà‚ñé       | 52/225 [00:31<01:04,  2.69it/s] 24%|‚ñà‚ñà‚ñé       | 53/225 [00:31<01:16,  2.25it/s] 24%|‚ñà‚ñà‚ñç       | 54/225 [00:32<01:23,  2.06it/s] 24%|‚ñà‚ñà‚ñç       | 55/225 [00:32<01:19,  2.15it/s] 25%|‚ñà‚ñà‚ñç       | 56/225 [00:33<01:28,  1.91it/s] 25%|‚ñà‚ñà‚ñå       | 57/225 [00:33<01:18,  2.14it/s] 26%|‚ñà‚ñà‚ñå       | 58/225 [00:33<01:04,  2.58it/s] 26%|‚ñà‚ñà‚ñå       | 59/225 [00:34<01:02,  2.64it/s] 27%|‚ñà‚ñà‚ñã       | 60/225 [00:34<00:53,  3.11it/s] 27%|‚ñà‚ñà‚ñã       | 61/225 [00:34<00:57,  2.85it/s] 28%|‚ñà‚ñà‚ñä       | 62/225 [00:35<00:50,  3.24it/s] 28%|‚ñà‚ñà‚ñä       | 63/225 [00:35<00:56,  2.86it/s] 28%|‚ñà‚ñà‚ñä       | 64/225 [00:35<00:51,  3.11it/s] 29%|‚ñà‚ñà‚ñâ       | 65/225 [00:36<00:45,  3.53it/s] 29%|‚ñà‚ñà‚ñâ       | 66/225 [00:36<00:51,  3.08it/s] 30%|‚ñà‚ñà‚ñâ       | 67/225 [00:36<00:45,  3.49it/s] 30%|‚ñà‚ñà‚ñà       | 68/225 [00:37<00:49,  3.15it/s] 31%|‚ñà‚ñà‚ñà       | 69/225 [00:37<00:47,  3.29it/s] 31%|‚ñà‚ñà‚ñà       | 70/225 [00:37<00:42,  3.66it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/225 [00:37<00:49,  3.11it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 72/225 [00:38<00:43,  3.52it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 73/225 [00:38<00:49,  3.10it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 74/225 [00:38<00:44,  3.39it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 75/225 [00:39<00:40,  3.69it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 76/225 [00:39<00:42,  3.55it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 77/225 [00:39<00:45,  3.28it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 78/225 [00:40<00:49,  2.98it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 79/225 [00:40<00:45,  3.24it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 80/225 [00:40<00:39,  3.65it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 81/225 [00:40<00:44,  3.24it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 82/225 [00:41<00:39,  3.64it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/225 [00:41<00:35,  4.03it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 84/225 [00:41<00:43,  3.25it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/225 [00:41<00:37,  3.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 86/225 [00:42<00:42,  3.30it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 87/225 [00:42<00:37,  3.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 88/225 [00:42<00:33,  4.11it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/225 [00:43<00:39,  3.46it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 90/225 [00:43<00:34,  3.86it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 91/225 [00:43<00:43,  3.11it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 92/225 [00:43<00:38,  3.49it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/225 [00:44<00:45,  2.91it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/225 [00:44<00:39,  3.35it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/225 [00:45<00:44,  2.93it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/225 [00:45<00:38,  3.35it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/225 [00:45<00:36,  3.52it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 98/225 [00:45<00:32,  3.89it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/225 [00:45<00:33,  3.81it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 100/225 [00:46<00:36,  3.43it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 101/225 [00:46<00:38,  3.20it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/225 [00:47<00:40,  3.02it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 103/225 [00:47<00:42,  2.86it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 104/225 [00:47<00:45,  2.68it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/225 [00:48<00:47,  2.51it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 106/225 [00:48<00:47,  2.52it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/225 [00:48<00:39,  2.96it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/225 [00:49<00:34,  3.39it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/225 [00:49<00:30,  3.80it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/225 [00:49<00:27,  4.12it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/225 [00:49<00:26,  4.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 112/225 [00:49<00:25,  4.51it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/225 [00:50<00:23,  4.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 114/225 [00:50<00:23,  4.81it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 115/225 [00:50<00:22,  4.86it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/225 [00:50<00:21,  4.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 117/225 [00:50<00:21,  4.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 118/225 [00:51<00:21,  4.93it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/225 [00:51<00:22,  4.73it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 120/225 [00:51<00:28,  3.66it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/225 [00:52<00:27,  3.82it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/225 [00:52<00:29,  3.52it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 123/225 [00:52<00:27,  3.64it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/225 [00:52<00:25,  3.98it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/225 [00:53<00:28,  3.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 126/225 [00:53<00:27,  3.66it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/225 [00:53<00:24,  3.93it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 128/225 [00:53<00:26,  3.70it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 129/225 [00:54<00:25,  3.72it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/225 [00:54<00:23,  4.00it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/225 [00:54<00:22,  4.10it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 132/225 [00:55<00:28,  3.27it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/225 [00:55<00:25,  3.60it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 134/225 [00:55<00:29,  3.09it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/225 [00:55<00:25,  3.52it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 136/225 [00:56<00:26,  3.31it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 137/225 [00:56<00:26,  3.34it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/225 [00:56<00:23,  3.66it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 139/225 [00:57<00:24,  3.47it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 140/225 [00:57<00:24,  3.51it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/225 [00:57<00:21,  3.89it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 142/225 [00:58<00:27,  3.02it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 143/225 [00:58<00:24,  3.33it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/225 [00:58<00:27,  2.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 145/225 [00:58<00:24,  3.31it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 146/225 [00:59<00:27,  2.92it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/225 [00:59<00:23,  3.32it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 148/225 [00:59<00:20,  3.69it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 149/225 [01:00<00:23,  3.27it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 150/225 [01:00<00:20,  3.61it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 151/225 [01:00<00:18,  3.93it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/225 [01:01<00:23,  3.17it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 153/225 [01:01<00:20,  3.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 154/225 [01:01<00:22,  3.19it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/225 [01:01<00:19,  3.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 156/225 [01:02<00:17,  3.84it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 157/225 [01:02<00:26,  2.61it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/225 [01:03<00:26,  2.56it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 159/225 [01:03<00:26,  2.51it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 160/225 [01:04<00:30,  2.13it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 161/225 [01:04<00:28,  2.26it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 162/225 [01:05<00:28,  2.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 163/225 [01:05<00:28,  2.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 164/225 [01:05<00:25,  2.43it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 165/225 [01:06<00:20,  2.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/225 [01:06<00:21,  2.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/225 [01:06<00:17,  3.23it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 168/225 [01:06<00:18,  3.02it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/225 [01:07<00:16,  3.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 170/225 [01:07<00:14,  3.72it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 171/225 [01:07<00:16,  3.32it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/225 [01:07<00:14,  3.72it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 173/225 [01:08<00:15,  3.35it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 174/225 [01:08<00:13,  3.65it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/225 [01:08<00:12,  4.02it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 176/225 [01:09<00:15,  3.13it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 177/225 [01:09<00:13,  3.48it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 178/225 [01:09<00:13,  3.37it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/225 [01:10<00:13,  3.52it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/225 [01:10<00:11,  3.80it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/225 [01:10<00:14,  3.13it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 182/225 [01:10<00:12,  3.48it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/225 [01:11<00:10,  3.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 184/225 [01:11<00:12,  3.22it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 185/225 [01:11<00:11,  3.52it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 186/225 [01:11<00:10,  3.80it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/225 [01:12<00:11,  3.27it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 188/225 [01:12<00:10,  3.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/225 [01:13<00:11,  3.02it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 190/225 [01:13<00:10,  3.43it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 191/225 [01:13<00:11,  2.88it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 192/225 [01:13<00:10,  3.24it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 193/225 [01:14<00:08,  3.60it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 194/225 [01:14<00:09,  3.24it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/225 [01:14<00:08,  3.61it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 196/225 [01:15<00:08,  3.33it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/225 [01:15<00:08,  3.26it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/225 [01:15<00:07,  3.66it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 199/225 [01:15<00:07,  3.38it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/225 [01:16<00:07,  3.49it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 201/225 [01:16<00:06,  3.79it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 202/225 [01:16<00:07,  3.16it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/225 [01:17<00:07,  2.92it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/225 [01:17<00:09,  2.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 205/225 [01:18<00:08,  2.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 206/225 [01:18<00:08,  2.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/225 [01:19<00:08,  2.00it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 208/225 [01:20<00:08,  1.90it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/225 [01:20<00:08,  1.93it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 210/225 [01:20<00:06,  2.39it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/225 [01:21<00:05,  2.48it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 212/225 [01:21<00:04,  2.89it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 213/225 [01:21<00:03,  3.31it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 214/225 [01:21<00:03,  3.34it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 215/225 [01:22<00:03,  3.30it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 216/225 [01:22<00:02,  3.70it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/225 [01:22<00:02,  3.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 218/225 [01:22<00:01,  3.66it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 219/225 [01:23<00:01,  3.67it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 220/225 [01:23<00:01,  3.22it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/225 [01:23<00:01,  3.57it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 222/225 [01:24<00:01,  2.92it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/225 [01:24<00:00,  3.35it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 224/225 [01:24<00:00,  3.75it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:24<00:00,  3.44it/s][INFO|trainer.py:1409] 2021-11-26 16:02:57,602 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 90.6502, 'train_samples_per_second': 317.098, 'train_steps_per_second': 2.482, 'train_loss': 4.981413302951389, 'epoch': 5.0}100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:25<00:00,  3.44it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:25<00:00,  2.64it/s]
[INFO|trainer.py:1995] 2021-11-26 16:02:57,724 >> Saving model checkpoint to ./models/stsb/exit7
[INFO|configuration_utils.py:417] 2021-11-26 16:02:57,729 >> Configuration saved in ./models/stsb/exit7/config.json
[INFO|modeling_utils.py:1058] 2021-11-26 16:03:00,592 >> Model weights saved in ./models/stsb/exit7/pytorch_model.bin
[INFO|tokenization_utils_base.py:2034] 2021-11-26 16:03:00,598 >> tokenizer config file saved in ./models/stsb/exit7/tokenizer_config.json
[INFO|tokenization_utils_base.py:2040] 2021-11-26 16:03:00,601 >> Special tokens file saved in ./models/stsb/exit7/special_tokens_map.json
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     4.9814
  train_runtime            = 0:01:30.65
  train_samples            =       5749
  train_samples_per_second =    317.098
  train_steps_per_second   =      2.482

11/26/2021 16:03:00 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:541] 2021-11-26 16:03:00,717 >> The following columns in the evaluation set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, idx, sentence2.
[INFO|trainer.py:2243] 2021-11-26 16:03:00,724 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2021-11-26 16:03:00,724 >>   Num examples = 1500
[INFO|trainer.py:2248] 2021-11-26 16:03:00,724 >>   Batch size = 32
  0%|          | 0/47 [00:00<?, ?it/s]  6%|‚ñã         | 3/47 [00:00<00:02, 21.44it/s] 13%|‚ñà‚ñé        | 6/47 [00:00<00:02, 16.56it/s] 17%|‚ñà‚ñã        | 8/47 [00:00<00:02, 15.22it/s] 21%|‚ñà‚ñà‚ñè       | 10/47 [00:00<00:02, 14.99it/s] 26%|‚ñà‚ñà‚ñå       | 12/47 [00:00<00:02, 14.73it/s] 30%|‚ñà‚ñà‚ñâ       | 14/47 [00:00<00:02, 14.46it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 16/47 [00:01<00:02, 14.42it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 18/47 [00:01<00:02, 14.48it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 20/47 [00:01<00:01, 14.54it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 22/47 [00:01<00:01, 14.60it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 24/47 [00:01<00:01, 14.63it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 26/47 [00:01<00:01, 14.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 28/47 [00:01<00:01, 14.69it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 30/47 [00:02<00:01, 14.58it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 32/47 [00:02<00:01, 14.82it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 34/47 [00:02<00:00, 14.96it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 36/47 [00:02<00:00, 14.88it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 38/47 [00:02<00:00, 14.84it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 40/47 [00:02<00:00, 14.44it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 42/47 [00:02<00:00, 14.35it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 44/47 [00:02<00:00, 13.76it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 46/47 [00:03<00:00, 13.88it/s]11/26/2021 16:03:04 - INFO - datasets.metric - Removing /home/slzhang/.cache/huggingface/metrics/glue/stsb/default_experiment-1-0.arrow
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:03<00:00, 13.71it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_combined_score     =     0.6541
  eval_loss               =     2.9458
  eval_pearson            =     0.6604
  eval_runtime            = 0:00:03.48
  eval_samples            =       1500
  eval_samples_per_second =    430.085
  eval_spearmanr          =     0.6478
  eval_steps_per_second   =     13.476
wandb: Waiting for W&B process to finish, PID 3586451
wandb: Program ended successfully.
wandb: - 0.04MB of 0.04MB uploaded (0.00MB deduped)wandb: \ 0.04MB of 0.07MB uploaded (0.00MB deduped)wandb: | 0.07MB of 0.07MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_160128-25f0b3k4/logs/debug.log
wandb: Find internal logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_160128-25f0b3k4/logs/debug-internal.log
wandb: Run summary:
wandb:              train/train_runtime 90.6502
wandb:   train/train_samples_per_second 317.098
wandb:     train/train_steps_per_second 2.482
wandb:                 train/total_flos 1108399863356160.0
wandb:                 train/train_loss 4.98141
wandb:                      train/epoch 5.0
wandb:                train/global_step 225
wandb:                         _runtime 96
wandb:                       _timestamp 1637913784
wandb:                            _step 1
wandb:                        eval/loss 2.94579
wandb:                     eval/pearson 0.66043
wandb:                   eval/spearmanr 0.64778
wandb:              eval/combined_score 0.6541
wandb:                     eval/runtime 3.4877
wandb:          eval/samples_per_second 430.085
wandb:            eval/steps_per_second 13.476
wandb: Run history:
wandb:              train/train_runtime ‚ñÅ
wandb:   train/train_samples_per_second ‚ñÅ
wandb:     train/train_steps_per_second ‚ñÅ
wandb:                 train/total_flos ‚ñÅ
wandb:                 train/train_loss ‚ñÅ
wandb:                      train/epoch ‚ñÅ‚ñÅ
wandb:                train/global_step ‚ñÅ‚ñÅ
wandb:                         _runtime ‚ñÅ‚ñà
wandb:                       _timestamp ‚ñÅ‚ñà
wandb:                            _step ‚ñÅ‚ñà
wandb:                        eval/loss ‚ñÅ
wandb:                     eval/pearson ‚ñÅ
wandb:                   eval/spearmanr ‚ñÅ
wandb:              eval/combined_score ‚ñÅ
wandb:                     eval/runtime ‚ñÅ
wandb:          eval/samples_per_second ‚ñÅ
wandb:            eval/steps_per_second ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ./models/stsb/exit7: https://wandb.ai/zsl/huggingface/runs/25f0b3k4

11/26/2021 16:03:27 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 16:03:27 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit8/runs/Nov26_16-03-26_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit8,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit8,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 16:03:32 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue
11/26/2021 16:03:32 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:03:32 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.py
11/26/2021 16:03:32 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/dataset_infos.json to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/dataset_infos.json
11/26/2021 16:03:32 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.json
11/26/2021 16:03:32 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:03:32 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 16:03:32 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:03:32 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 16:03:32 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 275.21it/s]
[INFO|configuration_utils.py:588] 2021-11-26 16:03:33,153 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:03:33,155 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 16:03:34,796 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:03:34,798 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:03:41,032 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/slzhang/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:03:41,033 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/slzhang/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:03:41,033 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:03:41,033 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:03:41,033 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/slzhang/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:588] 2021-11-26 16:03:41,835 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:03:41,836 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1340] 2021-11-26 16:03:42,716 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/slzhang/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1597] 2021-11-26 16:03:44,885 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertWithSinglehead: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertWithSinglehead from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertWithSinglehead from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1608] 2021-11-26 16:03:44,886 >> Some weights of BertWithSinglehead were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['s1_classifier.weight', 's1_classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/26/2021 16:03:46 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecb0af5ac5f5f4cf.arrow
11/26/2021 16:03:46 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f66158b4c3938527.arrow
11/26/2021 16:03:46 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8d605fec10ae3523.arrow
11/26/2021 16:03:46 - INFO - __main__ - Sample 5238 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 5238, 'input_ids': [101, 2966, 2852, 12952, 24373, 1113, 7303, 102, 7661, 112, 188, 1285, 131, 3460, 1159, 1113, 7303, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1.600000023841858, 'sentence1': 'Didier Reynders on Syria', 'sentence2': "Obama's day: Prime time on Syria", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:03:46 - INFO - __main__ - Sample 912 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 912, 'input_ids': [101, 138, 1299, 1110, 9374, 1103, 3751, 119, 102, 138, 1299, 1110, 3759, 170, 1610, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0.4000000059604645, 'sentence1': 'A man is cleaning the windows.', 'sentence2': 'A man is driving a car.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:03:46 - INFO - __main__ - Sample 204 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 204, 'input_ids': [101, 138, 1590, 3486, 170, 24181, 12253, 24886, 119, 102, 138, 1590, 1110, 8184, 1146, 170, 24181, 12253, 24886, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 3.25, 'sentence1': 'A woman holds a kangaroo.', 'sentence2': 'A woman is picking up a kangaroo.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:03:51 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue
11/26/2021 16:03:51 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981
11/26/2021 16:03:51 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.py
11/26/2021 16:03:51 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/dataset_infos.json
11/26/2021 16:03:51 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.json
[INFO|trainer.py:541] 2021-11-26 16:03:58,660 >> The following columns in the training set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: idx, sentence2, sentence1.
[INFO|trainer.py:1196] 2021-11-26 16:03:58,689 >> ***** Running training *****
[INFO|trainer.py:1197] 2021-11-26 16:03:58,689 >>   Num examples = 5749
[INFO|trainer.py:1198] 2021-11-26 16:03:58,689 >>   Num Epochs = 5
[INFO|trainer.py:1199] 2021-11-26 16:03:58,689 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2021-11-26 16:03:58,689 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:1201] 2021-11-26 16:03:58,689 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2021-11-26 16:03:58,690 >>   Total optimization steps = 225
[INFO|integrations.py:501] 2021-11-26 16:03:58,732 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: zsl (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.22
wandb: Syncing run ./models/stsb/exit8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zsl/huggingface
wandb: üöÄ View run at https://wandb.ai/zsl/huggingface/runs/28e14ofj
wandb: Run data is saved locally in /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_160400-28e14ofj
wandb: Run `wandb offline` to turn off syncing.
  0%|          | 0/225 [00:00<?, ?it/s]/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/225 [00:14<55:46, 14.94s/it]  1%|          | 2/225 [00:15<23:21,  6.29s/it]  1%|‚ñè         | 3/225 [00:15<13:06,  3.54s/it]  2%|‚ñè         | 4/225 [00:15<08:16,  2.24s/it]  2%|‚ñè         | 5/225 [00:15<05:37,  1.53s/it]  3%|‚ñé         | 6/225 [00:16<03:58,  1.09s/it]  3%|‚ñé         | 7/225 [00:16<02:56,  1.23it/s]  4%|‚ñé         | 8/225 [00:16<02:15,  1.61it/s]  4%|‚ñç         | 9/225 [00:17<01:55,  1.87it/s]  4%|‚ñç         | 10/225 [00:17<01:40,  2.14it/s]  5%|‚ñç         | 11/225 [00:17<01:23,  2.56it/s]  5%|‚ñå         | 12/225 [00:17<01:13,  2.91it/s]  6%|‚ñå         | 13/225 [00:17<01:05,  3.25it/s]  6%|‚ñå         | 14/225 [00:18<01:12,  2.90it/s]  7%|‚ñã         | 15/225 [00:18<01:04,  3.25it/s]  7%|‚ñã         | 16/225 [00:19<01:19,  2.63it/s]  8%|‚ñä         | 17/225 [00:19<01:08,  3.02it/s]  8%|‚ñä         | 18/225 [00:19<01:08,  3.02it/s]  8%|‚ñä         | 19/225 [00:20<01:08,  3.02it/s]  9%|‚ñâ         | 20/225 [00:20<01:01,  3.36it/s]  9%|‚ñâ         | 21/225 [00:20<01:07,  3.01it/s] 10%|‚ñâ         | 22/225 [00:20<01:00,  3.33it/s] 10%|‚ñà         | 23/225 [00:21<01:08,  2.93it/s] 11%|‚ñà         | 24/225 [00:21<01:01,  3.29it/s] 11%|‚ñà         | 25/225 [00:21<01:01,  3.23it/s] 12%|‚ñà‚ñè        | 26/225 [00:22<00:59,  3.34it/s] 12%|‚ñà‚ñè        | 27/225 [00:22<00:56,  3.51it/s] 12%|‚ñà‚ñè        | 28/225 [00:22<01:04,  3.06it/s] 13%|‚ñà‚ñé        | 29/225 [00:23<00:57,  3.41it/s] 13%|‚ñà‚ñé        | 30/225 [00:23<01:04,  3.01it/s] 14%|‚ñà‚ñç        | 31/225 [00:23<00:59,  3.28it/s] 14%|‚ñà‚ñç        | 32/225 [00:24<01:07,  2.84it/s] 15%|‚ñà‚ñç        | 33/225 [00:24<01:00,  3.18it/s] 15%|‚ñà‚ñå        | 34/225 [00:25<01:23,  2.28it/s] 16%|‚ñà‚ñå        | 35/225 [00:25<01:25,  2.21it/s] 16%|‚ñà‚ñå        | 36/225 [00:26<01:28,  2.13it/s] 16%|‚ñà‚ñã        | 37/225 [00:26<01:35,  1.97it/s] 17%|‚ñà‚ñã        | 38/225 [00:27<01:38,  1.90it/s] 17%|‚ñà‚ñã        | 39/225 [00:28<01:48,  1.71it/s] 18%|‚ñà‚ñä        | 40/225 [00:28<01:37,  1.89it/s] 18%|‚ñà‚ñä        | 41/225 [00:28<01:28,  2.08it/s] 19%|‚ñà‚ñä        | 42/225 [00:29<01:13,  2.49it/s] 19%|‚ñà‚ñâ        | 43/225 [00:29<01:15,  2.42it/s] 20%|‚ñà‚ñâ        | 44/225 [00:29<01:03,  2.84it/s] 20%|‚ñà‚ñà        | 45/225 [00:30<01:10,  2.55it/s] 20%|‚ñà‚ñà        | 46/225 [00:30<01:01,  2.93it/s] 21%|‚ñà‚ñà        | 47/225 [00:30<01:00,  2.96it/s] 21%|‚ñà‚ñà‚ñè       | 48/225 [00:31<00:57,  3.05it/s] 22%|‚ñà‚ñà‚ñè       | 49/225 [00:31<00:52,  3.37it/s] 22%|‚ñà‚ñà‚ñè       | 50/225 [00:31<01:00,  2.88it/s] 23%|‚ñà‚ñà‚ñé       | 51/225 [00:31<00:53,  3.25it/s] 23%|‚ñà‚ñà‚ñé       | 52/225 [00:32<00:59,  2.89it/s] 24%|‚ñà‚ñà‚ñé       | 53/225 [00:32<00:56,  3.05it/s] 24%|‚ñà‚ñà‚ñç       | 54/225 [00:32<00:54,  3.11it/s] 24%|‚ñà‚ñà‚ñç       | 55/225 [00:33<00:54,  3.09it/s] 25%|‚ñà‚ñà‚ñç       | 56/225 [00:33<00:52,  3.24it/s] 25%|‚ñà‚ñà‚ñå       | 57/225 [00:33<00:57,  2.91it/s] 26%|‚ñà‚ñà‚ñå       | 58/225 [00:34<00:51,  3.23it/s] 26%|‚ñà‚ñà‚ñå       | 59/225 [00:34<00:48,  3.42it/s] 27%|‚ñà‚ñà‚ñã       | 60/225 [00:34<00:51,  3.19it/s] 27%|‚ñà‚ñà‚ñã       | 61/225 [00:35<00:47,  3.48it/s] 28%|‚ñà‚ñà‚ñä       | 62/225 [00:35<00:53,  3.06it/s] 28%|‚ñà‚ñà‚ñä       | 63/225 [00:35<00:47,  3.39it/s] 28%|‚ñà‚ñà‚ñä       | 64/225 [00:36<00:52,  3.04it/s] 29%|‚ñà‚ñà‚ñâ       | 65/225 [00:36<00:48,  3.30it/s] 29%|‚ñà‚ñà‚ñâ       | 66/225 [00:36<00:43,  3.63it/s] 30%|‚ñà‚ñà‚ñâ       | 67/225 [00:36<00:51,  3.06it/s] 30%|‚ñà‚ñà‚ñà       | 68/225 [00:37<00:46,  3.38it/s] 31%|‚ñà‚ñà‚ñà       | 69/225 [00:37<00:55,  2.81it/s] 31%|‚ñà‚ñà‚ñà       | 70/225 [00:37<00:48,  3.17it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/225 [00:38<00:54,  2.85it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 72/225 [00:38<00:47,  3.23it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 73/225 [00:39<00:57,  2.64it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 74/225 [00:39<00:50,  2.97it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 75/225 [00:39<00:54,  2.76it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 76/225 [00:40<00:54,  2.73it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 77/225 [00:40<01:10,  2.11it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 78/225 [00:41<01:12,  2.04it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 79/225 [00:42<01:25,  1.70it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 80/225 [00:42<01:18,  1.84it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 81/225 [00:43<01:24,  1.71it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 82/225 [00:43<01:14,  1.92it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/225 [00:43<01:00,  2.35it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 84/225 [00:44<00:53,  2.62it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/225 [00:44<00:51,  2.71it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 86/225 [00:44<00:46,  2.97it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 87/225 [00:45<00:49,  2.76it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 88/225 [00:45<00:43,  3.14it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/225 [00:45<00:49,  2.76it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 90/225 [00:46<00:42,  3.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 91/225 [00:46<00:45,  2.93it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 92/225 [00:46<00:40,  3.28it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/225 [00:47<00:41,  3.17it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/225 [00:47<00:43,  2.98it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/225 [00:47<00:40,  3.22it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/225 [00:48<00:45,  2.86it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/225 [00:48<00:39,  3.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 98/225 [00:48<00:45,  2.82it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/225 [00:49<00:39,  3.16it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 100/225 [00:49<00:44,  2.81it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 101/225 [00:49<00:38,  3.19it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/225 [00:49<00:36,  3.37it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 103/225 [00:50<00:40,  3.03it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 104/225 [00:50<00:35,  3.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/225 [00:50<00:39,  3.05it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 106/225 [00:51<00:34,  3.46it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/225 [00:51<00:43,  2.71it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/225 [00:51<00:37,  3.13it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/225 [00:52<00:38,  3.00it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/225 [00:52<00:36,  3.19it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/225 [00:52<00:32,  3.56it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 112/225 [00:53<00:38,  2.95it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/225 [00:53<00:33,  3.34it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 114/225 [00:53<00:37,  2.92it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 115/225 [00:54<00:33,  3.32it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/225 [00:54<00:31,  3.46it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 117/225 [00:54<00:30,  3.56it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 118/225 [00:55<00:38,  2.79it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/225 [00:55<00:42,  2.51it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 120/225 [00:56<00:44,  2.33it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/225 [00:56<00:47,  2.20it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/225 [00:57<00:44,  2.30it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 123/225 [00:57<00:44,  2.29it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/225 [00:57<00:37,  2.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/225 [00:57<00:32,  3.11it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 126/225 [00:58<00:28,  3.47it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/225 [00:58<00:26,  3.69it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 128/225 [00:58<00:24,  3.93it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 129/225 [00:58<00:26,  3.64it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/225 [00:59<00:24,  3.87it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/225 [00:59<00:23,  4.06it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 132/225 [00:59<00:22,  4.20it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/225 [00:59<00:21,  4.34it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 134/225 [01:00<00:20,  4.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/225 [01:00<00:19,  4.53it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 136/225 [01:00<00:19,  4.59it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 137/225 [01:00<00:19,  4.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/225 [01:01<00:26,  3.29it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 139/225 [01:01<00:30,  2.86it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 140/225 [01:01<00:28,  3.02it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/225 [01:02<00:25,  3.34it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 142/225 [01:02<00:23,  3.56it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 143/225 [01:02<00:21,  3.81it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/225 [01:02<00:23,  3.49it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 145/225 [01:03<00:25,  3.09it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 146/225 [01:03<00:23,  3.37it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/225 [01:04<00:26,  2.90it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 148/225 [01:04<00:24,  3.18it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 149/225 [01:04<00:26,  2.83it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 150/225 [01:04<00:23,  3.18it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 151/225 [01:05<00:27,  2.70it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/225 [01:05<00:23,  3.04it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 153/225 [01:06<00:27,  2.65it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 154/225 [01:06<00:23,  3.00it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/225 [01:06<00:25,  2.73it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 156/225 [01:07<00:22,  3.09it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 157/225 [01:07<00:25,  2.62it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/225 [01:07<00:22,  2.95it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 159/225 [01:08<00:25,  2.59it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 160/225 [01:08<00:21,  2.99it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 161/225 [01:09<00:24,  2.62it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 162/225 [01:09<00:21,  2.99it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 163/225 [01:09<00:24,  2.52it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 164/225 [01:10<00:27,  2.25it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 165/225 [01:10<00:28,  2.08it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/225 [01:11<00:31,  1.87it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/225 [01:12<00:31,  1.86it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 168/225 [01:12<00:33,  1.68it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/225 [01:13<00:30,  1.86it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 170/225 [01:13<00:27,  2.01it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 171/225 [01:13<00:22,  2.41it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/225 [01:14<00:18,  2.85it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 173/225 [01:14<00:20,  2.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 174/225 [01:14<00:17,  2.94it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/225 [01:15<00:18,  2.70it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 176/225 [01:15<00:16,  3.02it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 177/225 [01:15<00:18,  2.63it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 178/225 [01:16<00:15,  2.99it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/225 [01:16<00:17,  2.66it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/225 [01:16<00:14,  3.01it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/225 [01:17<00:16,  2.67it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 182/225 [01:17<00:15,  2.80it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/225 [01:18<00:15,  2.77it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 184/225 [01:18<00:13,  3.10it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 185/225 [01:18<00:13,  3.01it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 186/225 [01:18<00:12,  3.08it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/225 [01:19<00:11,  3.41it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 188/225 [01:19<00:12,  2.96it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/225 [01:19<00:11,  3.16it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 190/225 [01:20<00:10,  3.48it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 191/225 [01:20<00:10,  3.12it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 192/225 [01:20<00:09,  3.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 193/225 [01:21<00:10,  3.02it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 194/225 [01:21<00:09,  3.35it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/225 [01:21<00:11,  2.67it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 196/225 [01:22<00:09,  3.06it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/225 [01:22<00:10,  2.62it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/225 [01:22<00:09,  2.96it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 199/225 [01:23<00:10,  2.54it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/225 [01:23<00:08,  2.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 201/225 [01:23<00:07,  3.26it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 202/225 [01:24<00:07,  2.88it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/225 [01:24<00:06,  3.23it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/225 [01:25<00:08,  2.52it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 205/225 [01:25<00:08,  2.28it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 206/225 [01:26<00:09,  2.00it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/225 [01:26<00:10,  1.77it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 208/225 [01:27<00:10,  1.67it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/225 [01:28<00:09,  1.61it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 210/225 [01:28<00:09,  1.66it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/225 [01:29<00:07,  1.93it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 212/225 [01:29<00:05,  2.34it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 213/225 [01:29<00:05,  2.32it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 214/225 [01:30<00:04,  2.73it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 215/225 [01:30<00:03,  2.64it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 216/225 [01:30<00:02,  3.01it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/225 [01:31<00:03,  2.59it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 218/225 [01:31<00:02,  2.99it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 219/225 [01:31<00:02,  2.64it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 220/225 [01:32<00:01,  3.04it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/225 [01:32<00:01,  2.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 222/225 [01:32<00:00,  3.18it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/225 [01:33<00:00,  3.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 224/225 [01:33<00:00,  3.12it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:33<00:00,  3.15it/s][INFO|trainer.py:1409] 2021-11-26 16:05:38,159 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 99.4697, 'train_samples_per_second': 288.983, 'train_steps_per_second': 2.262, 'train_loss': 4.6753097873263885, 'epoch': 5.0}100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:33<00:00,  3.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:33<00:00,  2.40it/s]

[INFO|trainer.py:1995] 2021-11-26 16:05:38,276 >> Saving model checkpoint to ./models/stsb/exit8
[INFO|configuration_utils.py:417] 2021-11-26 16:05:38,280 >> Configuration saved in ./models/stsb/exit8/config.json
[INFO|modeling_utils.py:1058] 2021-11-26 16:05:41,399 >> Model weights saved in ./models/stsb/exit8/pytorch_model.bin
[INFO|tokenization_utils_base.py:2034] 2021-11-26 16:05:41,404 >> tokenizer config file saved in ./models/stsb/exit8/tokenizer_config.json
[INFO|tokenization_utils_base.py:2040] 2021-11-26 16:05:41,406 >> Special tokens file saved in ./models/stsb/exit8/special_tokens_map.json
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     4.6753
  train_runtime            = 0:01:39.46
  train_samples            =       5749
  train_samples_per_second =    288.983
  train_steps_per_second   =      2.262

11/26/2021 16:05:41 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:541] 2021-11-26 16:05:41,557 >> The following columns in the evaluation set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: idx, sentence2, sentence1.
[INFO|trainer.py:2243] 2021-11-26 16:05:41,563 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2021-11-26 16:05:41,564 >>   Num examples = 1500
[INFO|trainer.py:2248] 2021-11-26 16:05:41,564 >>   Batch size = 32
  0%|          | 0/47 [00:00<?, ?it/s]  6%|‚ñã         | 3/47 [00:00<00:02, 20.19it/s] 13%|‚ñà‚ñé        | 6/47 [00:00<00:03, 13.03it/s] 17%|‚ñà‚ñã        | 8/47 [00:00<00:02, 13.30it/s] 21%|‚ñà‚ñà‚ñè       | 10/47 [00:00<00:02, 13.47it/s] 26%|‚ñà‚ñà‚ñå       | 12/47 [00:00<00:02, 13.53it/s] 30%|‚ñà‚ñà‚ñâ       | 14/47 [00:01<00:02, 13.60it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 16/47 [00:01<00:02, 13.57it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 18/47 [00:01<00:02, 13.47it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 20/47 [00:01<00:01, 13.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 22/47 [00:01<00:01, 13.73it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 24/47 [00:01<00:01, 13.57it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 26/47 [00:01<00:01, 13.65it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 28/47 [00:02<00:01, 13.68it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 30/47 [00:02<00:01, 13.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 32/47 [00:02<00:01, 11.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 34/47 [00:02<00:01, 11.99it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 36/47 [00:02<00:00, 12.47it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 38/47 [00:02<00:00, 12.80it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 40/47 [00:03<00:00, 13.08it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 42/47 [00:03<00:00, 13.33it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 44/47 [00:03<00:00, 13.43it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 46/47 [00:03<00:00, 13.24it/s]11/26/2021 16:05:45 - INFO - datasets.metric - Removing /home/slzhang/.cache/huggingface/metrics/glue/stsb/default_experiment-1-0.arrow
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:03<00:00, 13.06it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_combined_score     =     0.6516
  eval_loss               =     2.8212
  eval_pearson            =     0.6592
  eval_runtime            = 0:00:03.77
  eval_samples            =       1500
  eval_samples_per_second =    397.675
  eval_spearmanr          =      0.644
  eval_steps_per_second   =      12.46
wandb: Waiting for W&B process to finish, PID 3590226
wandb: Program ended successfully.
wandb: - 0.05MB of 0.05MB uploaded (0.00MB deduped)wandb: \ 0.07MB of 0.07MB uploaded (0.00MB deduped)wandb: | 0.07MB of 0.07MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_160400-28e14ofj/logs/debug.log
wandb: Find internal logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_160400-28e14ofj/logs/debug-internal.log
wandb: Run summary:
wandb:              train/train_runtime 99.4697
wandb:   train/train_samples_per_second 288.983
wandb:     train/train_steps_per_second 2.262
wandb:                 train/total_flos 1264872859687680.0
wandb:                 train/train_loss 4.67531
wandb:                      train/epoch 5.0
wandb:                train/global_step 225
wandb:                         _runtime 105
wandb:                       _timestamp 1637913945
wandb:                            _step 1
wandb:                        eval/loss 2.82118
wandb:                     eval/pearson 0.65923
wandb:                   eval/spearmanr 0.644
wandb:              eval/combined_score 0.65161
wandb:                     eval/runtime 3.7719
wandb:          eval/samples_per_second 397.675
wandb:            eval/steps_per_second 12.46
wandb: Run history:
wandb:              train/train_runtime ‚ñÅ
wandb:   train/train_samples_per_second ‚ñÅ
wandb:     train/train_steps_per_second ‚ñÅ
wandb:                 train/total_flos ‚ñÅ
wandb:                 train/train_loss ‚ñÅ
wandb:                      train/epoch ‚ñÅ‚ñÅ
wandb:                train/global_step ‚ñÅ‚ñÅ
wandb:                         _runtime ‚ñÅ‚ñà
wandb:                       _timestamp ‚ñÅ‚ñà
wandb:                            _step ‚ñÅ‚ñà
wandb:                        eval/loss ‚ñÅ
wandb:                     eval/pearson ‚ñÅ
wandb:                   eval/spearmanr ‚ñÅ
wandb:              eval/combined_score ‚ñÅ
wandb:                     eval/runtime ‚ñÅ
wandb:          eval/samples_per_second ‚ñÅ
wandb:            eval/steps_per_second ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ./models/stsb/exit8: https://wandb.ai/zsl/huggingface/runs/28e14ofj

11/26/2021 16:06:07 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 16:06:07 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit9/runs/Nov26_16-06-07_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit9,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit9,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 16:06:12 - INFO - datasets.utils.file_utils - HEAD request to https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/glue/glue.py timed out, retrying... [1.0]
11/26/2021 16:06:32 - WARNING - datasets.load - Using the latest cached version of the module from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad (last modified on Mon Oct 18 16:41:08 2021) since it couldn't be found locally at /home/slzhang/projects/ETBA/Train/bert_train/glue/glue.py, or remotely (ConnectionError).
11/26/2021 16:06:32 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:06:32 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 16:06:32 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:06:32 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 16:06:32 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 289.36it/s]
[INFO|configuration_utils.py:588] 2021-11-26 16:06:42,305 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:06:42,307 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 16:06:44,038 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:06:44,039 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:06:49,107 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/slzhang/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:06:49,108 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/slzhang/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:06:49,108 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:06:49,108 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:06:49,108 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/slzhang/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:588] 2021-11-26 16:06:49,934 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:06:49,936 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1340] 2021-11-26 16:06:50,810 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/slzhang/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1597] 2021-11-26 16:06:53,267 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertWithSinglehead: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertWithSinglehead from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertWithSinglehead from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1608] 2021-11-26 16:06:53,268 >> Some weights of BertWithSinglehead were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['s1_classifier.weight', 's1_classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/26/2021 16:06:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecb0af5ac5f5f4cf.arrow
11/26/2021 16:06:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f66158b4c3938527.arrow
11/26/2021 16:06:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8d605fec10ae3523.arrow
11/26/2021 16:06:55 - INFO - __main__ - Sample 5238 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 5238, 'input_ids': [101, 2966, 2852, 12952, 24373, 1113, 7303, 102, 7661, 112, 188, 1285, 131, 3460, 1159, 1113, 7303, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1.600000023841858, 'sentence1': 'Didier Reynders on Syria', 'sentence2': "Obama's day: Prime time on Syria", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:06:55 - INFO - __main__ - Sample 912 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 912, 'input_ids': [101, 138, 1299, 1110, 9374, 1103, 3751, 119, 102, 138, 1299, 1110, 3759, 170, 1610, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0.4000000059604645, 'sentence1': 'A man is cleaning the windows.', 'sentence2': 'A man is driving a car.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:06:55 - INFO - __main__ - Sample 204 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 204, 'input_ids': [101, 138, 1590, 3486, 170, 24181, 12253, 24886, 119, 102, 138, 1590, 1110, 8184, 1146, 170, 24181, 12253, 24886, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 3.25, 'sentence1': 'A woman holds a kangaroo.', 'sentence2': 'A woman is picking up a kangaroo.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:06:57 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue
11/26/2021 16:06:57 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981
11/26/2021 16:06:57 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.py
11/26/2021 16:06:57 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/dataset_infos.json
11/26/2021 16:06:57 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.json
[INFO|trainer.py:541] 2021-11-26 16:07:04,165 >> The following columns in the training set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, idx, sentence2.
[INFO|trainer.py:1196] 2021-11-26 16:07:04,197 >> ***** Running training *****
[INFO|trainer.py:1197] 2021-11-26 16:07:04,197 >>   Num examples = 5749
[INFO|trainer.py:1198] 2021-11-26 16:07:04,197 >>   Num Epochs = 5
[INFO|trainer.py:1199] 2021-11-26 16:07:04,197 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2021-11-26 16:07:04,197 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:1201] 2021-11-26 16:07:04,197 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2021-11-26 16:07:04,198 >>   Total optimization steps = 225
[INFO|integrations.py:501] 2021-11-26 16:07:04,237 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: zsl (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.22
wandb: Syncing run ./models/stsb/exit9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zsl/huggingface
wandb: üöÄ View run at https://wandb.ai/zsl/huggingface/runs/192sx7lg
wandb: Run data is saved locally in /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_160705-192sx7lg
wandb: Run `wandb offline` to turn off syncing.
  0%|          | 0/225 [00:00<?, ?it/s]/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/225 [00:16<1:02:56, 16.86s/it]  1%|          | 2/225 [00:17<26:24,  7.11s/it]    1%|‚ñè         | 3/225 [00:17<14:58,  4.05s/it]  2%|‚ñè         | 4/225 [00:17<09:33,  2.59s/it]  2%|‚ñè         | 5/225 [00:18<07:07,  1.94s/it]  3%|‚ñé         | 6/225 [00:19<05:15,  1.44s/it]  3%|‚ñé         | 7/225 [00:19<04:20,  1.19s/it]  4%|‚ñé         | 8/225 [00:20<03:35,  1.01it/s]  4%|‚ñç         | 9/225 [00:21<03:08,  1.15it/s]  4%|‚ñç         | 10/225 [00:21<02:35,  1.38it/s]  5%|‚ñç         | 11/225 [00:21<02:09,  1.66it/s]  5%|‚ñå         | 12/225 [00:22<01:55,  1.85it/s]  6%|‚ñå         | 13/225 [00:22<01:38,  2.14it/s]  6%|‚ñå         | 14/225 [00:22<01:35,  2.21it/s]  7%|‚ñã         | 15/225 [00:23<01:23,  2.50it/s]  7%|‚ñã         | 16/225 [00:23<01:24,  2.47it/s]  8%|‚ñä         | 17/225 [00:23<01:17,  2.68it/s]  8%|‚ñä         | 18/225 [00:24<01:18,  2.65it/s]  8%|‚ñä         | 19/225 [00:24<01:12,  2.84it/s]  9%|‚ñâ         | 20/225 [00:24<01:13,  2.77it/s]  9%|‚ñâ         | 21/225 [00:25<01:06,  3.09it/s] 10%|‚ñâ         | 22/225 [00:25<01:13,  2.78it/s] 10%|‚ñà         | 23/225 [00:25<01:09,  2.90it/s] 11%|‚ñà         | 24/225 [00:26<01:12,  2.77it/s] 11%|‚ñà         | 25/225 [00:26<01:04,  3.10it/s] 12%|‚ñà‚ñè        | 26/225 [00:26<01:02,  3.21it/s] 12%|‚ñà‚ñè        | 27/225 [00:27<00:56,  3.51it/s] 12%|‚ñà‚ñè        | 28/225 [00:27<00:52,  3.77it/s] 13%|‚ñà‚ñé        | 29/225 [00:27<00:49,  3.98it/s] 13%|‚ñà‚ñé        | 30/225 [00:27<00:47,  4.14it/s] 14%|‚ñà‚ñç        | 31/225 [00:27<00:45,  4.26it/s] 14%|‚ñà‚ñç        | 32/225 [00:28<00:44,  4.31it/s] 15%|‚ñà‚ñç        | 33/225 [00:28<00:44,  4.34it/s] 15%|‚ñà‚ñå        | 34/225 [00:28<00:43,  4.38it/s] 16%|‚ñà‚ñå        | 35/225 [00:28<00:42,  4.44it/s] 16%|‚ñà‚ñå        | 36/225 [00:29<00:42,  4.48it/s] 16%|‚ñà‚ñã        | 37/225 [00:29<00:41,  4.48it/s] 17%|‚ñà‚ñã        | 38/225 [00:29<00:41,  4.52it/s] 17%|‚ñà‚ñã        | 39/225 [00:29<00:41,  4.51it/s] 18%|‚ñà‚ñä        | 40/225 [00:29<00:41,  4.50it/s] 18%|‚ñà‚ñä        | 41/225 [00:30<00:41,  4.47it/s] 19%|‚ñà‚ñä        | 42/225 [00:30<00:41,  4.38it/s] 19%|‚ñà‚ñâ        | 43/225 [00:30<00:42,  4.30it/s] 20%|‚ñà‚ñâ        | 44/225 [00:30<00:43,  4.16it/s] 20%|‚ñà‚ñà        | 45/225 [00:31<00:41,  4.34it/s] 20%|‚ñà‚ñà        | 46/225 [00:31<00:42,  4.25it/s] 21%|‚ñà‚ñà        | 47/225 [00:31<00:41,  4.28it/s] 21%|‚ñà‚ñà‚ñè       | 48/225 [00:31<00:41,  4.23it/s] 22%|‚ñà‚ñà‚ñè       | 49/225 [00:32<00:41,  4.25it/s] 22%|‚ñà‚ñà‚ñè       | 50/225 [00:32<00:42,  4.16it/s] 23%|‚ñà‚ñà‚ñé       | 51/225 [00:32<00:50,  3.45it/s] 23%|‚ñà‚ñà‚ñé       | 52/225 [00:33<00:55,  3.12it/s] 24%|‚ñà‚ñà‚ñé       | 53/225 [00:33<00:52,  3.29it/s] 24%|‚ñà‚ñà‚ñç       | 54/225 [00:33<01:02,  2.75it/s] 24%|‚ñà‚ñà‚ñç       | 55/225 [00:34<01:26,  1.96it/s] 25%|‚ñà‚ñà‚ñç       | 56/225 [00:35<01:27,  1.93it/s] 25%|‚ñà‚ñà‚ñå       | 57/225 [00:36<01:43,  1.63it/s] 26%|‚ñà‚ñà‚ñå       | 58/225 [00:36<01:41,  1.64it/s] 26%|‚ñà‚ñà‚ñå       | 59/225 [00:37<01:40,  1.65it/s] 27%|‚ñà‚ñà‚ñã       | 60/225 [00:37<01:25,  1.94it/s] 27%|‚ñà‚ñà‚ñã       | 61/225 [00:37<01:12,  2.26it/s] 28%|‚ñà‚ñà‚ñä       | 62/225 [00:38<01:11,  2.28it/s] 28%|‚ñà‚ñà‚ñä       | 63/225 [00:38<01:01,  2.64it/s] 28%|‚ñà‚ñà‚ñä       | 64/225 [00:38<01:04,  2.48it/s] 29%|‚ñà‚ñà‚ñâ       | 65/225 [00:39<00:56,  2.84it/s] 29%|‚ñà‚ñà‚ñâ       | 66/225 [00:39<01:03,  2.50it/s] 30%|‚ñà‚ñà‚ñâ       | 67/225 [00:39<00:55,  2.86it/s] 30%|‚ñà‚ñà‚ñà       | 68/225 [00:40<00:58,  2.66it/s] 31%|‚ñà‚ñà‚ñà       | 69/225 [00:40<00:52,  2.99it/s] 31%|‚ñà‚ñà‚ñà       | 70/225 [00:41<00:58,  2.67it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/225 [00:41<00:50,  3.03it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 72/225 [00:41<00:58,  2.63it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 73/225 [00:42<00:51,  2.96it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 74/225 [00:42<00:56,  2.67it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 75/225 [00:42<00:50,  3.00it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 76/225 [00:43<00:59,  2.49it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 77/225 [00:43<00:52,  2.84it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 78/225 [00:43<00:53,  2.72it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 79/225 [00:44<00:50,  2.88it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 80/225 [00:44<00:45,  3.15it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 81/225 [00:44<00:51,  2.80it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 82/225 [00:45<00:45,  3.11it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/225 [00:45<00:42,  3.38it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 84/225 [00:45<00:47,  2.99it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/225 [00:46<00:42,  3.29it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 86/225 [00:46<00:49,  2.83it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 87/225 [00:46<00:43,  3.15it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 88/225 [00:47<00:49,  2.78it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/225 [00:47<00:43,  3.09it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 90/225 [00:47<00:46,  2.88it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 91/225 [00:48<00:42,  3.17it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 92/225 [00:48<00:53,  2.47it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/225 [00:49<00:55,  2.40it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/225 [00:49<01:05,  2.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/225 [00:50<01:11,  1.82it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/225 [00:51<01:16,  1.69it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/225 [00:51<01:17,  1.64it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 98/225 [00:52<01:04,  1.96it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/225 [00:52<01:00,  2.09it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 100/225 [00:52<00:52,  2.36it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 101/225 [00:53<00:51,  2.41it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/225 [00:53<00:44,  2.76it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 103/225 [00:53<00:47,  2.60it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 104/225 [00:54<00:40,  2.95it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/225 [00:54<00:45,  2.63it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 106/225 [00:54<00:39,  3.00it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/225 [00:55<00:38,  3.10it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/225 [00:55<00:40,  2.86it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/225 [00:55<00:37,  3.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/225 [00:56<00:42,  2.73it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/225 [00:56<00:37,  3.06it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 112/225 [00:57<00:42,  2.64it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/225 [00:57<00:38,  2.89it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 114/225 [00:57<00:41,  2.65it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 115/225 [00:58<00:38,  2.88it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/225 [00:58<00:39,  2.74it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 117/225 [00:58<00:35,  3.04it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 118/225 [00:59<00:41,  2.60it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/225 [00:59<00:36,  2.94it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 120/225 [00:59<00:41,  2.52it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/225 [01:00<00:36,  2.87it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/225 [01:00<00:39,  2.59it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 123/225 [01:00<00:34,  2.97it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/225 [01:01<00:39,  2.55it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/225 [01:01<00:34,  2.90it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 126/225 [01:02<00:37,  2.67it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/225 [01:02<00:32,  2.98it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 128/225 [01:02<00:33,  2.88it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 129/225 [01:03<00:33,  2.89it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/225 [01:03<00:29,  3.20it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/225 [01:03<00:32,  2.89it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 132/225 [01:03<00:29,  3.19it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/225 [01:04<00:44,  2.06it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 134/225 [01:05<00:50,  1.81it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/225 [01:06<00:53,  1.68it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 136/225 [01:06<00:55,  1.60it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 137/225 [01:07<00:57,  1.53it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/225 [01:08<00:52,  1.67it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 139/225 [01:08<00:44,  1.93it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 140/225 [01:08<00:37,  2.28it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/225 [01:09<00:36,  2.30it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 142/225 [01:09<00:38,  2.14it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 143/225 [01:09<00:33,  2.44it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/225 [01:10<00:29,  2.70it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 145/225 [01:10<00:30,  2.58it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 146/225 [01:10<00:27,  2.89it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/225 [01:11<00:27,  2.79it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 148/225 [01:11<00:25,  3.06it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 149/225 [01:11<00:26,  2.84it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 150/225 [01:12<00:24,  3.09it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 151/225 [01:12<00:26,  2.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/225 [01:12<00:23,  3.13it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 153/225 [01:13<00:22,  3.20it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 154/225 [01:13<00:20,  3.51it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/225 [01:13<00:18,  3.73it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 156/225 [01:13<00:17,  3.93it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 157/225 [01:14<00:16,  4.04it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/225 [01:14<00:16,  4.16it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 159/225 [01:14<00:15,  4.28it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 160/225 [01:14<00:14,  4.41it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 161/225 [01:14<00:14,  4.51it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 162/225 [01:15<00:13,  4.57it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 163/225 [01:15<00:13,  4.56it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 164/225 [01:15<00:13,  4.53it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 165/225 [01:15<00:13,  4.46it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/225 [01:16<00:13,  4.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/225 [01:16<00:13,  4.28it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 168/225 [01:16<00:13,  4.20it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/225 [01:16<00:13,  4.15it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 170/225 [01:17<00:13,  4.21it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 171/225 [01:17<00:12,  4.20it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/225 [01:17<00:13,  4.02it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 173/225 [01:17<00:14,  3.65it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 174/225 [01:18<00:13,  3.77it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/225 [01:18<00:12,  3.87it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 176/225 [01:18<00:12,  3.96it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 177/225 [01:19<00:15,  3.18it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 178/225 [01:19<00:20,  2.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/225 [01:20<00:23,  1.94it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/225 [01:21<00:25,  1.78it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/225 [01:21<00:26,  1.69it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 182/225 [01:22<00:25,  1.66it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/225 [01:22<00:21,  1.96it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 184/225 [01:23<00:19,  2.10it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 185/225 [01:23<00:16,  2.48it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 186/225 [01:23<00:16,  2.35it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/225 [01:24<00:14,  2.69it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 188/225 [01:24<00:14,  2.48it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/225 [01:24<00:12,  2.81it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 190/225 [01:25<00:13,  2.58it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 191/225 [01:25<00:11,  2.93it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 192/225 [01:26<00:12,  2.58it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 193/225 [01:26<00:11,  2.89it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 194/225 [01:26<00:12,  2.56it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/225 [01:27<00:10,  2.89it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 196/225 [01:27<00:12,  2.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/225 [01:27<00:10,  2.75it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/225 [01:28<00:10,  2.52it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 199/225 [01:28<00:09,  2.87it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/225 [01:29<00:09,  2.55it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 201/225 [01:29<00:08,  2.82it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 202/225 [01:29<00:07,  3.10it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/225 [01:29<00:06,  3.38it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/225 [01:30<00:06,  3.01it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 205/225 [01:30<00:06,  3.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 206/225 [01:30<00:07,  2.70it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/225 [01:31<00:06,  2.99it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 208/225 [01:31<00:06,  2.66it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/225 [01:31<00:05,  2.92it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 210/225 [01:32<00:05,  2.74it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/225 [01:32<00:04,  3.06it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 212/225 [01:33<00:04,  2.70it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 213/225 [01:33<00:03,  3.01it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 214/225 [01:33<00:04,  2.69it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 215/225 [01:34<00:03,  3.03it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 216/225 [01:34<00:03,  2.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/225 [01:34<00:02,  2.93it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 218/225 [01:35<00:02,  2.64it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 219/225 [01:35<00:02,  2.19it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 220/225 [01:36<00:02,  1.76it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/225 [01:37<00:02,  1.78it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 222/225 [01:38<00:01,  1.58it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/225 [01:38<00:01,  1.62it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 224/225 [01:38<00:00,  1.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:39<00:00,  2.09it/s][INFO|trainer.py:1409] 2021-11-26 16:08:49,675 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 105.477, 'train_samples_per_second': 272.524, 'train_steps_per_second': 2.133, 'train_loss': 4.787140842013889, 'epoch': 5.0}
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:39<00:00,  2.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:39<00:00,  2.26it/s]
[INFO|trainer.py:1995] 2021-11-26 16:08:49,792 >> Saving model checkpoint to ./models/stsb/exit9
[INFO|configuration_utils.py:417] 2021-11-26 16:08:49,799 >> Configuration saved in ./models/stsb/exit9/config.json
[INFO|modeling_utils.py:1058] 2021-11-26 16:08:53,611 >> Model weights saved in ./models/stsb/exit9/pytorch_model.bin
[INFO|tokenization_utils_base.py:2034] 2021-11-26 16:08:53,616 >> tokenizer config file saved in ./models/stsb/exit9/tokenizer_config.json
[INFO|tokenization_utils_base.py:2040] 2021-11-26 16:08:53,618 >> Special tokens file saved in ./models/stsb/exit9/special_tokens_map.json
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     4.7871
  train_runtime            = 0:01:45.47
  train_samples            =       5749
  train_samples_per_second =    272.524
  train_steps_per_second   =      2.133

11/26/2021 16:08:53 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:541] 2021-11-26 16:08:53,776 >> The following columns in the evaluation set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence1, idx, sentence2.
[INFO|trainer.py:2243] 2021-11-26 16:08:53,782 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2021-11-26 16:08:53,782 >>   Num examples = 1500
[INFO|trainer.py:2248] 2021-11-26 16:08:53,782 >>   Batch size = 32
  0%|          | 0/47 [00:00<?, ?it/s]  6%|‚ñã         | 3/47 [00:00<00:02, 16.60it/s] 11%|‚ñà         | 5/47 [00:00<00:03, 13.70it/s] 15%|‚ñà‚ñç        | 7/47 [00:00<00:03, 12.41it/s] 19%|‚ñà‚ñâ        | 9/47 [00:00<00:03, 11.62it/s] 23%|‚ñà‚ñà‚ñé       | 11/47 [00:01<00:04,  7.78it/s] 28%|‚ñà‚ñà‚ñä       | 13/47 [00:01<00:04,  8.30it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 15/47 [00:01<00:03,  8.70it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 17/47 [00:01<00:04,  7.17it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 19/47 [00:02<00:03,  7.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 21/47 [00:02<00:03,  7.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 22/47 [00:02<00:03,  6.99it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 24/47 [00:02<00:02,  8.06it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 26/47 [00:03<00:03,  6.53it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 27/47 [00:03<00:02,  6.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 29/47 [00:03<00:02,  7.77it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 31/47 [00:03<00:01,  8.64it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 32/47 [00:04<00:02,  6.49it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 33/47 [00:04<00:02,  6.60it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 35/47 [00:04<00:01,  7.93it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 37/47 [00:04<00:01,  7.06it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 38/47 [00:04<00:01,  7.03it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 40/47 [00:05<00:00,  8.12it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 41/47 [00:05<00:00,  8.25it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 42/47 [00:05<00:00,  6.54it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 44/47 [00:05<00:00,  7.78it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 46/47 [00:05<00:00,  7.25it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:06<00:00,  7.01it/s]11/26/2021 16:08:59 - INFO - datasets.metric - Removing /home/slzhang/.cache/huggingface/metrics/glue/stsb/default_experiment-1-0.arrow
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:06<00:00,  7.70it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_combined_score     =      0.616
  eval_loss               =     2.9942
  eval_pearson            =     0.6289
  eval_runtime            = 0:00:06.18
  eval_samples            =       1500
  eval_samples_per_second =    242.453
  eval_spearmanr          =      0.603
  eval_steps_per_second   =      7.597
wandb: Waiting for W&B process to finish, PID 3594505
wandb: Program ended successfully.
wandb: - 0.05MB of 0.05MB uploaded (0.00MB deduped)wandb: \ 0.08MB of 0.08MB uploaded (0.00MB deduped)wandb: | 0.08MB of 0.08MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_160705-192sx7lg/logs/debug.log
wandb: Find internal logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_160705-192sx7lg/logs/debug-internal.log
wandb: Run summary:
wandb:              train/train_runtime 105.477
wandb:   train/train_samples_per_second 272.524
wandb:     train/train_steps_per_second 2.133
wandb:                 train/total_flos 1421345856019200.0
wandb:                 train/train_loss 4.78714
wandb:                      train/epoch 5.0
wandb:                train/global_step 225
wandb:                         _runtime 113
wandb:                       _timestamp 1637914139
wandb:                            _step 1
wandb:                        eval/loss 2.99415
wandb:                     eval/pearson 0.62892
wandb:                   eval/spearmanr 0.60303
wandb:              eval/combined_score 0.61598
wandb:                     eval/runtime 6.1868
wandb:          eval/samples_per_second 242.453
wandb:            eval/steps_per_second 7.597
wandb: Run history:
wandb:              train/train_runtime ‚ñÅ
wandb:   train/train_samples_per_second ‚ñÅ
wandb:     train/train_steps_per_second ‚ñÅ
wandb:                 train/total_flos ‚ñÅ
wandb:                 train/train_loss ‚ñÅ
wandb:                      train/epoch ‚ñÅ‚ñÅ
wandb:                train/global_step ‚ñÅ‚ñÅ
wandb:                         _runtime ‚ñÅ‚ñà
wandb:                       _timestamp ‚ñÅ‚ñà
wandb:                            _step ‚ñÅ‚ñà
wandb:                        eval/loss ‚ñÅ
wandb:                     eval/pearson ‚ñÅ
wandb:                   eval/spearmanr ‚ñÅ
wandb:              eval/combined_score ‚ñÅ
wandb:                     eval/runtime ‚ñÅ
wandb:          eval/samples_per_second ‚ñÅ
wandb:            eval/steps_per_second ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ./models/stsb/exit9: https://wandb.ai/zsl/huggingface/runs/192sx7lg

11/26/2021 16:09:14 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 16:09:14 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit10/runs/Nov26_16-09-14_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit10,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit10,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 16:09:17 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue
11/26/2021 16:09:17 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:09:17 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.py
11/26/2021 16:09:17 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/dataset_infos.json to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/dataset_infos.json
11/26/2021 16:09:17 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.json
11/26/2021 16:09:17 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:09:17 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 16:09:17 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:09:17 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 16:09:17 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 268.38it/s]
[INFO|configuration_utils.py:588] 2021-11-26 16:09:17,942 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:09:17,944 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 16:09:19,618 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:09:19,619 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

Traceback (most recent call last):
  File "run_glue.py", line 583, in <module>
    main()
  File "run_glue.py", line 330, in main
    use_auth_token=True if model_args.use_auth_token else None,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py", line 498, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/transformers/tokenization_utils_base.py", line 1700, in from_pretrained
    user_agent=user_agent,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/transformers/file_utils.py", line 1499, in cached_path
    local_files_only=local_files_only,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/transformers/file_utils.py", line 1716, in get_from_cache
    "Connection error, and we cannot find the requested files in the cached path."
ValueError: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.
11/26/2021 16:09:32 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 16:09:32 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit11/runs/Nov26_16-09-32_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit11,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit11,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 16:09:34 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue
11/26/2021 16:09:34 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:09:34 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.py
11/26/2021 16:09:34 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/dataset_infos.json to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/dataset_infos.json
11/26/2021 16:09:34 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.json
11/26/2021 16:09:34 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:09:34 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 16:09:34 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:09:34 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 16:09:34 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 428.69it/s]
[INFO|configuration_utils.py:588] 2021-11-26 16:09:35,675 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:09:35,678 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 16:09:38,350 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:09:38,357 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:09:44,724 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/slzhang/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:09:44,725 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/slzhang/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:09:44,725 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:09:44,725 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:09:44,725 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/slzhang/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:588] 2021-11-26 16:09:45,536 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:09:45,539 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1340] 2021-11-26 16:09:46,367 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/slzhang/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1597] 2021-11-26 16:09:48,957 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertWithSinglehead: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertWithSinglehead from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertWithSinglehead from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1608] 2021-11-26 16:09:48,957 >> Some weights of BertWithSinglehead were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['s1_classifier.weight', 's1_classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/26/2021 16:09:51 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecb0af5ac5f5f4cf.arrow
11/26/2021 16:09:51 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f66158b4c3938527.arrow
11/26/2021 16:09:51 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8d605fec10ae3523.arrow
11/26/2021 16:09:51 - INFO - __main__ - Sample 5238 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 5238, 'input_ids': [101, 2966, 2852, 12952, 24373, 1113, 7303, 102, 7661, 112, 188, 1285, 131, 3460, 1159, 1113, 7303, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1.600000023841858, 'sentence1': 'Didier Reynders on Syria', 'sentence2': "Obama's day: Prime time on Syria", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:09:51 - INFO - __main__ - Sample 912 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 912, 'input_ids': [101, 138, 1299, 1110, 9374, 1103, 3751, 119, 102, 138, 1299, 1110, 3759, 170, 1610, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0.4000000059604645, 'sentence1': 'A man is cleaning the windows.', 'sentence2': 'A man is driving a car.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:09:51 - INFO - __main__ - Sample 204 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 204, 'input_ids': [101, 138, 1590, 3486, 170, 24181, 12253, 24886, 119, 102, 138, 1590, 1110, 8184, 1146, 170, 24181, 12253, 24886, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 3.25, 'sentence1': 'A woman holds a kangaroo.', 'sentence2': 'A woman is picking up a kangaroo.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:09:53 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue
11/26/2021 16:09:53 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981
11/26/2021 16:09:53 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.py
11/26/2021 16:09:53 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/dataset_infos.json
11/26/2021 16:09:53 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.json
[INFO|trainer.py:541] 2021-11-26 16:10:02,423 >> The following columns in the training set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: idx, sentence1, sentence2.
[INFO|trainer.py:1196] 2021-11-26 16:10:02,443 >> ***** Running training *****
[INFO|trainer.py:1197] 2021-11-26 16:10:02,443 >>   Num examples = 5749
[INFO|trainer.py:1198] 2021-11-26 16:10:02,443 >>   Num Epochs = 5
[INFO|trainer.py:1199] 2021-11-26 16:10:02,443 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2021-11-26 16:10:02,443 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:1201] 2021-11-26 16:10:02,443 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2021-11-26 16:10:02,443 >>   Total optimization steps = 225
[INFO|integrations.py:501] 2021-11-26 16:10:02,474 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: W&B API key is configured (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.10.22
wandb: Syncing run ./models/stsb/exit11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zsl/huggingface
wandb: üöÄ View run at https://wandb.ai/zsl/huggingface/runs/3hdx0agb
wandb: Run data is saved locally in /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_161008-3hdx0agb
wandb: Run `wandb offline` to turn off syncing.
  0%|          | 0/225 [00:00<?, ?it/s]/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/225 [00:14<54:38, 14.63s/it]  1%|          | 2/225 [00:15<23:22,  6.29s/it]  1%|‚ñè         | 3/225 [00:15<13:09,  3.56s/it]  2%|‚ñè         | 4/225 [00:15<08:45,  2.38s/it]  2%|‚ñè         | 5/225 [00:16<06:48,  1.86s/it]  3%|‚ñé         | 6/225 [00:17<05:03,  1.38s/it]  3%|‚ñé         | 7/225 [00:18<04:24,  1.21s/it]  4%|‚ñé         | 8/225 [00:18<03:37,  1.00s/it]  4%|‚ñç         | 9/225 [00:19<02:52,  1.25it/s]  4%|‚ñç         | 10/225 [00:19<02:27,  1.46it/s]  5%|‚ñç         | 11/225 [00:20<02:19,  1.54it/s]  5%|‚ñå         | 12/225 [00:20<01:57,  1.82it/s]  6%|‚ñå         | 13/225 [00:20<01:51,  1.90it/s]  6%|‚ñå         | 14/225 [00:21<01:37,  2.17it/s]  7%|‚ñã         | 15/225 [00:21<01:34,  2.22it/s]  7%|‚ñã         | 16/225 [00:21<01:22,  2.52it/s]  8%|‚ñä         | 17/225 [00:22<01:29,  2.33it/s]  8%|‚ñä         | 18/225 [00:22<01:23,  2.49it/s]  8%|‚ñä         | 19/225 [00:23<01:24,  2.45it/s]  9%|‚ñâ         | 20/225 [00:23<01:21,  2.52it/s]  9%|‚ñâ         | 21/225 [00:23<01:22,  2.48it/s] 10%|‚ñâ         | 22/225 [00:24<01:21,  2.48it/s] 10%|‚ñà         | 23/225 [00:24<01:21,  2.46it/s] 11%|‚ñà         | 24/225 [00:25<01:17,  2.58it/s] 11%|‚ñà         | 25/225 [00:25<01:20,  2.49it/s] 12%|‚ñà‚ñè        | 26/225 [00:26<01:21,  2.44it/s] 12%|‚ñà‚ñè        | 27/225 [00:26<01:21,  2.42it/s] 12%|‚ñà‚ñè        | 28/225 [00:26<01:19,  2.47it/s] 13%|‚ñà‚ñé        | 29/225 [00:27<01:22,  2.37it/s] 13%|‚ñà‚ñé        | 30/225 [00:27<01:21,  2.39it/s] 14%|‚ñà‚ñç        | 31/225 [00:28<01:18,  2.48it/s] 14%|‚ñà‚ñç        | 32/225 [00:28<01:11,  2.69it/s] 15%|‚ñà‚ñç        | 33/225 [00:28<01:17,  2.49it/s] 15%|‚ñà‚ñå        | 34/225 [00:29<01:14,  2.57it/s] 16%|‚ñà‚ñå        | 35/225 [00:29<01:15,  2.51it/s] 16%|‚ñà‚ñå        | 36/225 [00:29<01:10,  2.67it/s] 16%|‚ñà‚ñã        | 37/225 [00:30<01:14,  2.54it/s] 17%|‚ñà‚ñã        | 38/225 [00:30<01:09,  2.70it/s] 17%|‚ñà‚ñã        | 39/225 [00:31<01:12,  2.55it/s] 18%|‚ñà‚ñä        | 40/225 [00:31<01:09,  2.67it/s] 18%|‚ñà‚ñä        | 41/225 [00:32<01:27,  2.11it/s] 19%|‚ñà‚ñä        | 42/225 [00:32<01:26,  2.13it/s] 19%|‚ñà‚ñâ        | 43/225 [00:33<01:46,  1.71it/s] 20%|‚ñà‚ñâ        | 44/225 [00:34<02:01,  1.49it/s] 20%|‚ñà‚ñà        | 45/225 [00:34<01:54,  1.57it/s] 20%|‚ñà‚ñà        | 46/225 [00:35<01:52,  1.60it/s] 21%|‚ñà‚ñà        | 47/225 [00:35<01:33,  1.91it/s] 21%|‚ñà‚ñà‚ñè       | 48/225 [00:36<01:19,  2.22it/s] 22%|‚ñà‚ñà‚ñè       | 49/225 [00:36<01:22,  2.14it/s] 22%|‚ñà‚ñà‚ñè       | 50/225 [00:36<01:14,  2.35it/s] 23%|‚ñà‚ñà‚ñé       | 51/225 [00:37<01:16,  2.28it/s] 23%|‚ñà‚ñà‚ñé       | 52/225 [00:37<01:06,  2.60it/s] 24%|‚ñà‚ñà‚ñé       | 53/225 [00:38<01:11,  2.39it/s] 24%|‚ñà‚ñà‚ñç       | 54/225 [00:38<01:07,  2.55it/s] 24%|‚ñà‚ñà‚ñç       | 55/225 [00:38<01:08,  2.47it/s] 25%|‚ñà‚ñà‚ñç       | 56/225 [00:39<01:03,  2.67it/s] 25%|‚ñà‚ñà‚ñå       | 57/225 [00:39<01:06,  2.53it/s] 26%|‚ñà‚ñà‚ñå       | 58/225 [00:40<01:17,  2.15it/s] 26%|‚ñà‚ñà‚ñå       | 59/225 [00:40<01:13,  2.26it/s] 27%|‚ñà‚ñà‚ñã       | 60/225 [00:41<01:13,  2.25it/s] 27%|‚ñà‚ñà‚ñã       | 61/225 [00:41<01:11,  2.28it/s] 28%|‚ñà‚ñà‚ñä       | 62/225 [00:41<01:11,  2.30it/s] 28%|‚ñà‚ñà‚ñä       | 63/225 [00:42<01:09,  2.33it/s] 28%|‚ñà‚ñà‚ñä       | 64/225 [00:42<01:07,  2.40it/s] 29%|‚ñà‚ñà‚ñâ       | 65/225 [00:43<01:03,  2.54it/s] 29%|‚ñà‚ñà‚ñâ       | 66/225 [00:43<01:06,  2.40it/s] 30%|‚ñà‚ñà‚ñâ       | 67/225 [00:44<01:07,  2.34it/s] 30%|‚ñà‚ñà‚ñà       | 68/225 [00:44<01:04,  2.42it/s] 31%|‚ñà‚ñà‚ñà       | 69/225 [00:44<01:00,  2.57it/s] 31%|‚ñà‚ñà‚ñà       | 70/225 [00:45<01:02,  2.49it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/225 [00:45<01:01,  2.49it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 72/225 [00:45<01:01,  2.50it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 73/225 [00:46<00:57,  2.62it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 74/225 [00:46<00:59,  2.55it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 75/225 [00:47<00:56,  2.65it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 76/225 [00:47<00:56,  2.64it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 77/225 [00:47<01:03,  2.33it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 78/225 [00:48<01:17,  1.89it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 79/225 [00:49<01:20,  1.82it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 80/225 [00:49<01:17,  1.86it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 81/225 [00:50<01:22,  1.75it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 82/225 [00:51<01:24,  1.68it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/225 [00:51<01:10,  2.01it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 84/225 [00:51<00:59,  2.37it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/225 [00:52<00:56,  2.50it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 86/225 [00:52<00:49,  2.79it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 87/225 [00:52<00:45,  3.05it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 88/225 [00:52<00:42,  3.25it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/225 [00:53<00:40,  3.34it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 90/225 [00:53<00:38,  3.48it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 91/225 [00:53<00:38,  3.51it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 92/225 [00:53<00:37,  3.58it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/225 [00:54<00:37,  3.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/225 [00:54<00:37,  3.54it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/225 [00:54<00:36,  3.58it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/225 [00:55<00:35,  3.61it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/225 [00:55<00:35,  3.57it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 98/225 [00:55<00:43,  2.94it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/225 [00:56<00:40,  3.09it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 100/225 [00:56<00:42,  2.97it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 101/225 [00:56<00:46,  2.68it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/225 [00:57<00:47,  2.59it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 103/225 [00:57<00:48,  2.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 104/225 [00:57<00:43,  2.78it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/225 [00:58<00:48,  2.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 106/225 [00:58<00:47,  2.49it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/225 [00:59<00:47,  2.48it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/225 [00:59<00:42,  2.72it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/225 [01:00<00:46,  2.51it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/225 [01:00<00:44,  2.59it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/225 [01:00<00:45,  2.51it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 112/225 [01:01<00:40,  2.80it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/225 [01:01<00:40,  2.78it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 114/225 [01:01<00:39,  2.84it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 115/225 [01:02<00:38,  2.88it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/225 [01:02<00:41,  2.62it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 117/225 [01:02<00:38,  2.78it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 118/225 [01:03<00:41,  2.58it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/225 [01:04<00:54,  1.93it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 120/225 [01:04<01:01,  1.71it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/225 [01:05<01:11,  1.46it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/225 [01:06<01:05,  1.57it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 123/225 [01:07<01:10,  1.44it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/225 [01:07<00:58,  1.72it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/225 [01:07<00:54,  1.85it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 126/225 [01:08<00:48,  2.04it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/225 [01:08<00:46,  2.09it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 128/225 [01:09<00:40,  2.39it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 129/225 [01:09<00:42,  2.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/225 [01:09<00:38,  2.47it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/225 [01:10<00:37,  2.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 132/225 [01:10<00:34,  2.69it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/225 [01:10<00:32,  2.85it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 134/225 [01:11<00:34,  2.63it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/225 [01:11<00:33,  2.71it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 136/225 [01:12<00:33,  2.67it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 137/225 [01:12<00:33,  2.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/225 [01:12<00:34,  2.53it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 139/225 [01:13<00:32,  2.66it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 140/225 [01:13<00:34,  2.48it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/225 [01:14<00:33,  2.47it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 142/225 [01:14<00:34,  2.43it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 143/225 [01:14<00:30,  2.72it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/225 [01:15<00:32,  2.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 145/225 [01:15<00:30,  2.65it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 146/225 [01:16<00:31,  2.54it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/225 [01:16<00:31,  2.45it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 148/225 [01:16<00:29,  2.62it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 149/225 [01:17<00:28,  2.62it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 150/225 [01:17<00:29,  2.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 151/225 [01:17<00:27,  2.69it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/225 [01:18<00:28,  2.55it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 153/225 [01:18<00:26,  2.75it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 154/225 [01:19<00:25,  2.74it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/225 [01:19<00:27,  2.58it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 156/225 [01:20<00:38,  1.81it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 157/225 [01:20<00:37,  1.82it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/225 [01:21<00:35,  1.90it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 159/225 [01:22<00:41,  1.59it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 160/225 [01:23<00:43,  1.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 161/225 [01:23<00:36,  1.75it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 162/225 [01:23<00:32,  1.94it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 163/225 [01:24<00:29,  2.12it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 164/225 [01:24<00:27,  2.18it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 165/225 [01:24<00:27,  2.22it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/225 [01:25<00:24,  2.44it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/225 [01:25<00:24,  2.33it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 168/225 [01:26<00:23,  2.47it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/225 [01:26<00:22,  2.45it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 170/225 [01:26<00:21,  2.55it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 171/225 [01:27<00:21,  2.49it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/225 [01:27<00:20,  2.58it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 173/225 [01:28<00:22,  2.35it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 174/225 [01:28<00:20,  2.49it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/225 [01:28<00:20,  2.40it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 176/225 [01:29<00:20,  2.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 177/225 [01:29<00:19,  2.41it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 178/225 [01:30<00:20,  2.34it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/225 [01:30<00:18,  2.42it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/225 [01:31<00:20,  2.17it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/225 [01:31<00:18,  2.37it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 182/225 [01:31<00:18,  2.35it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/225 [01:32<00:16,  2.50it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 184/225 [01:32<00:16,  2.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 185/225 [01:33<00:16,  2.48it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 186/225 [01:33<00:14,  2.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/225 [01:33<00:13,  2.77it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 188/225 [01:34<00:13,  2.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/225 [01:34<00:13,  2.57it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 190/225 [01:35<00:13,  2.53it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 191/225 [01:35<00:13,  2.50it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 192/225 [01:35<00:13,  2.52it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 193/225 [01:36<00:14,  2.20it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 194/225 [01:37<00:15,  1.96it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/225 [01:37<00:16,  1.82it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 196/225 [01:38<00:16,  1.75it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/225 [01:38<00:14,  1.97it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/225 [01:38<00:11,  2.31it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 199/225 [01:39<00:10,  2.53it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/225 [01:39<00:09,  2.60it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 201/225 [01:40<00:10,  2.23it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 202/225 [01:40<00:09,  2.35it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/225 [01:40<00:08,  2.57it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/225 [01:41<00:07,  2.77it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 205/225 [01:41<00:06,  2.99it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 206/225 [01:41<00:05,  3.18it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/225 [01:41<00:05,  3.30it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 208/225 [01:42<00:05,  2.83it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/225 [01:42<00:05,  2.90it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 210/225 [01:43<00:04,  3.02it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/225 [01:43<00:05,  2.61it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 212/225 [01:43<00:04,  2.84it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 213/225 [01:44<00:04,  2.56it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 214/225 [01:44<00:03,  2.82it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 215/225 [01:44<00:03,  2.96it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 216/225 [01:45<00:03,  2.63it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/225 [01:45<00:02,  2.77it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 218/225 [01:46<00:02,  2.50it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 219/225 [01:46<00:02,  2.68it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 220/225 [01:46<00:01,  2.51it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/225 [01:47<00:01,  2.80it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 222/225 [01:47<00:01,  2.51it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/225 [01:47<00:00,  2.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 224/225 [01:48<00:00,  2.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:48<00:00,  2.71it/s][INFO|trainer.py:1409] 2021-11-26 16:12:03,612 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 121.1683, 'train_samples_per_second': 237.232, 'train_steps_per_second': 1.857, 'train_loss': 3.5355186631944444, 'epoch': 5.0}100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:48<00:00,  2.71it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:48<00:00,  2.07it/s]
[INFO|trainer.py:1995] 2021-11-26 16:12:03,733 >> Saving model checkpoint to ./models/stsb/exit11
[INFO|configuration_utils.py:417] 2021-11-26 16:12:03,737 >> Configuration saved in ./models/stsb/exit11/config.json
[INFO|modeling_utils.py:1058] 2021-11-26 16:12:11,329 >> Model weights saved in ./models/stsb/exit11/pytorch_model.bin
[INFO|tokenization_utils_base.py:2034] 2021-11-26 16:12:11,334 >> tokenizer config file saved in ./models/stsb/exit11/tokenizer_config.json
[INFO|tokenization_utils_base.py:2040] 2021-11-26 16:12:11,336 >> Special tokens file saved in ./models/stsb/exit11/special_tokens_map.json
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     3.5355
  train_runtime            = 0:02:01.16
  train_samples            =       5749
  train_samples_per_second =    237.232
  train_steps_per_second   =      1.857

11/26/2021 16:12:11 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:541] 2021-11-26 16:12:11,504 >> The following columns in the evaluation set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: idx, sentence1, sentence2.
[INFO|trainer.py:2243] 2021-11-26 16:12:11,512 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2021-11-26 16:12:11,512 >>   Num examples = 1500
[INFO|trainer.py:2248] 2021-11-26 16:12:11,512 >>   Batch size = 32
  0%|          | 0/47 [00:00<?, ?it/s]  4%|‚ñç         | 2/47 [00:00<00:06,  7.11it/s]  9%|‚ñä         | 4/47 [00:00<00:04,  8.72it/s] 13%|‚ñà‚ñé        | 6/47 [00:00<00:04,  9.50it/s] 17%|‚ñà‚ñã        | 8/47 [00:00<00:03,  9.94it/s] 21%|‚ñà‚ñà‚ñè       | 10/47 [00:01<00:03, 10.11it/s] 26%|‚ñà‚ñà‚ñå       | 12/47 [00:01<00:03, 10.13it/s] 30%|‚ñà‚ñà‚ñâ       | 14/47 [00:01<00:03, 10.31it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 16/47 [00:01<00:02, 10.40it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 18/47 [00:01<00:02,  9.72it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 19/47 [00:02<00:04,  6.99it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 20/47 [00:02<00:03,  6.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 22/47 [00:02<00:03,  7.75it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 23/47 [00:02<00:03,  7.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 24/47 [00:02<00:03,  6.04it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 25/47 [00:03<00:03,  6.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 27/47 [00:03<00:03,  5.90it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 28/47 [00:03<00:03,  6.04it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 29/47 [00:03<00:02,  6.54it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 30/47 [00:03<00:02,  7.15it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 31/47 [00:04<00:02,  6.36it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 32/47 [00:04<00:02,  5.79it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 33/47 [00:04<00:02,  6.56it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 35/47 [00:04<00:01,  6.37it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 36/47 [00:04<00:01,  6.21it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 37/47 [00:05<00:01,  5.56it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 38/47 [00:05<00:01,  4.77it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 39/47 [00:05<00:01,  5.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 41/47 [00:05<00:00,  6.50it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 43/47 [00:06<00:00,  6.04it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 44/47 [00:06<00:00,  6.46it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 45/47 [00:06<00:00,  7.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 46/47 [00:06<00:00,  7.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:06<00:00,  8.03it/s]11/26/2021 16:12:18 - INFO - datasets.metric - Removing /home/slzhang/.cache/huggingface/metrics/glue/stsb/default_experiment-1-0.arrow
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:06<00:00,  7.15it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_combined_score     =     0.6087
  eval_loss               =      1.981
  eval_pearson            =     0.6108
  eval_runtime            = 0:00:06.82
  eval_samples            =       1500
  eval_samples_per_second =    219.801
  eval_spearmanr          =     0.6067
  eval_steps_per_second   =      6.887
Traceback (most recent call last):
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 706, in urlopen
    chunked=chunked,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connection.py", line 421, in connect
    tls_in_tls=tls_in_tls,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 450, in ssl_wrap_socket
    sock, context, tls_in_tls, server_hostname=server_hostname
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 423, in wrap_socket
    session=session
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 870, in _create
    self.do_handshake()
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 1139, in do_handshake
    self._sslobj.do_handshake()
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/adapters.py", line 449, in send
    timeout=timeout
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 756, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/util/retry.py", line 532, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/packages/six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 706, in urlopen
    chunked=chunked,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 382, in _make_request
    self._validate_conn(conn)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connectionpool.py", line 1010, in _validate_conn
    conn.connect()
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/connection.py", line 421, in connect
    tls_in_tls=tls_in_tls,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 450, in ssl_wrap_socket
    sock, context, tls_in_tls, server_hostname=server_hostname
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 423, in wrap_socket
    session=session
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 870, in _create
    self.do_handshake()
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/ssl.py", line 1139, in do_handshake
    self._sslobj.do_handshake()
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run_glue.py", line 583, in <module>
    main()
  File "run_glue.py", line 574, in main
    trainer.create_model_card(**kwargs)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/transformers/trainer.py", line 2603, in create_model_card
    dataset_args=dataset_args,
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/transformers/modelcard.py", line 604, in from_trainer
    hyperparameters=hyperparameters,
  File "<string>", line 14, in __init__
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/transformers/modelcard.py", line 390, in __post_init__
    model_info = HfApi().model_info(self.finetuned_from)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/huggingface_hub/hf_api.py", line 516, in model_info
    r = requests.get(path, headers=headers, timeout=timeout)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/api.py", line 76, in get
    return request('get', url, params=params, **kwargs)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/requests/adapters.py", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
wandb: Waiting for W&B process to finish, PID 3598585
wandb: Program failed with code 1.  Press ctrl-c to abort syncing.
wandb: - 0.06MB of 0.06MB uploaded (0.00MB deduped)wandb: \ 0.09MB of 0.10MB uploaded (0.00MB deduped)wandb: | 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_161008-3hdx0agb/logs/debug.log
wandb: Find internal logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_161008-3hdx0agb/logs/debug-internal.log
wandb: Run summary:
wandb:              train/train_runtime 121.1683
wandb:   train/train_samples_per_second 237.232
wandb:     train/train_steps_per_second 1.857
wandb:                 train/total_flos 1734291848682240.0
wandb:                 train/train_loss 3.53552
wandb:                      train/epoch 5.0
wandb:                train/global_step 225
wandb:                         _runtime 130
wandb:                       _timestamp 1637914338
wandb:                            _step 1
wandb:                        eval/loss 1.98096
wandb:                     eval/pearson 0.61083
wandb:                   eval/spearmanr 0.60666
wandb:              eval/combined_score 0.60875
wandb:                     eval/runtime 6.8244
wandb:          eval/samples_per_second 219.801
wandb:            eval/steps_per_second 6.887
wandb: Run history:
wandb:              train/train_runtime ‚ñÅ
wandb:   train/train_samples_per_second ‚ñÅ
wandb:     train/train_steps_per_second ‚ñÅ
wandb:                 train/total_flos ‚ñÅ
wandb:                 train/train_loss ‚ñÅ
wandb:                      train/epoch ‚ñÅ‚ñÅ
wandb:                train/global_step ‚ñÅ‚ñÅ
wandb:                         _runtime ‚ñÅ‚ñà
wandb:                       _timestamp ‚ñÅ‚ñà
wandb:                            _step ‚ñÅ‚ñà
wandb:                        eval/loss ‚ñÅ
wandb:                     eval/pearson ‚ñÅ
wandb:                   eval/spearmanr ‚ñÅ
wandb:              eval/combined_score ‚ñÅ
wandb:                     eval/runtime ‚ñÅ
wandb:          eval/samples_per_second ‚ñÅ
wandb:            eval/steps_per_second ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ./models/stsb/exit11: https://wandb.ai/zsl/huggingface/runs/3hdx0agb

11/26/2021 16:12:37 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 4distributed training: False, 16-bits training: False
11/26/2021 16:12:37 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=4,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=./models/stsb/exit12/runs/Nov26_16-12-37_p100-02,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=5.0,
output_dir=./models/stsb/exit12,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
resume_from_checkpoint=None,
run_name=./models/stsb/exit12,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
11/26/2021 16:12:39 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue
11/26/2021 16:12:39 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:12:39 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.py
11/26/2021 16:12:39 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/dataset_infos.json to /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/dataset_infos.json
11/26/2021 16:12:39 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.11.0/datasets/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/glue.json
11/26/2021 16:12:39 - INFO - datasets.info - Loading Dataset Infos from /home/slzhang/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:12:39 - INFO - datasets.builder - Overwrite dataset info from restored data version.
11/26/2021 16:12:39 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/26/2021 16:12:39 - WARNING - datasets.builder - Reusing dataset glue (/home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/26/2021 16:12:39 - INFO - datasets.info - Loading Dataset info from /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
  0%|          | 0/3 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 296.26it/s]
[INFO|configuration_utils.py:588] 2021-11-26 16:12:40,242 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:12:40,244 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "stsb",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|configuration_utils.py:588] 2021-11-26 16:12:41,874 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:12:41,875 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:12:48,412 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/slzhang/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:12:48,413 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/slzhang/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:12:48,413 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:12:48,413 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1742] 2021-11-26 16:12:48,413 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/slzhang/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f
[INFO|configuration_utils.py:588] 2021-11-26 16:12:49,369 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/slzhang/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307
[INFO|configuration_utils.py:625] 2021-11-26 16:12:49,371 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.12.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 28996
}

[INFO|modeling_utils.py:1340] 2021-11-26 16:12:50,249 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /home/slzhang/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda
[WARNING|modeling_utils.py:1597] 2021-11-26 16:12:52,581 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertWithSinglehead: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertWithSinglehead from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertWithSinglehead from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1608] 2021-11-26 16:12:52,581 >> Some weights of BertWithSinglehead were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['s1_classifier.weight', 's1_classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
11/26/2021 16:12:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-ecb0af5ac5f5f4cf.arrow
11/26/2021 16:12:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f66158b4c3938527.arrow
11/26/2021 16:12:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/slzhang/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8d605fec10ae3523.arrow
11/26/2021 16:12:55 - INFO - __main__ - Sample 5238 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 5238, 'input_ids': [101, 2966, 2852, 12952, 24373, 1113, 7303, 102, 7661, 112, 188, 1285, 131, 3460, 1159, 1113, 7303, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 1.600000023841858, 'sentence1': 'Didier Reynders on Syria', 'sentence2': "Obama's day: Prime time on Syria", 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:12:55 - INFO - __main__ - Sample 912 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 912, 'input_ids': [101, 138, 1299, 1110, 9374, 1103, 3751, 119, 102, 138, 1299, 1110, 3759, 170, 1610, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 0.4000000059604645, 'sentence1': 'A man is cleaning the windows.', 'sentence2': 'A man is driving a car.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:12:55 - INFO - __main__ - Sample 204 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'idx': 204, 'input_ids': [101, 138, 1590, 3486, 170, 24181, 12253, 24886, 119, 102, 138, 1590, 1110, 8184, 1146, 170, 24181, 12253, 24886, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'label': 3.25, 'sentence1': 'A woman holds a kangaroo.', 'sentence2': 'A woman is picking up a kangaroo.', 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
11/26/2021 16:13:00 - INFO - datasets.utils.file_utils - HEAD request to https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics/glue/glue.py timed out, retrying... [1.0]
11/26/2021 16:13:05 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue
11/26/2021 16:13:05 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981
11/26/2021 16:13:05 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py to /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.py
11/26/2021 16:13:05 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/dataset_infos.json
11/26/2021 16:13:05 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/glue/glue.py at /home/slzhang/.cache/huggingface/modules/datasets_modules/metrics/glue/479ff3f18b7b4e5a529ea7117f3ce02d081a7219ee662384b5633d830a11b981/glue.json
[INFO|trainer.py:541] 2021-11-26 16:13:13,323 >> The following columns in the training set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence2, idx, sentence1.
[INFO|trainer.py:1196] 2021-11-26 16:13:13,342 >> ***** Running training *****
[INFO|trainer.py:1197] 2021-11-26 16:13:13,342 >>   Num examples = 5749
[INFO|trainer.py:1198] 2021-11-26 16:13:13,342 >>   Num Epochs = 5
[INFO|trainer.py:1199] 2021-11-26 16:13:13,342 >>   Instantaneous batch size per device = 32
[INFO|trainer.py:1200] 2021-11-26 16:13:13,342 >>   Total train batch size (w. parallel, distributed & accumulation) = 128
[INFO|trainer.py:1201] 2021-11-26 16:13:13,342 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2021-11-26 16:13:13,342 >>   Total optimization steps = 225
[INFO|integrations.py:501] 2021-11-26 16:13:13,382 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: W&B API key is configured (use `wandb login --relogin` to force relogin)
wandb: Tracking run with wandb version 0.10.22
wandb: Syncing run ./models/stsb/exit12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zsl/huggingface
wandb: üöÄ View run at https://wandb.ai/zsl/huggingface/runs/10icjd38
wandb: Run data is saved locally in /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_161319-10icjd38
wandb: Run `wandb offline` to turn off syncing.
  0%|          | 0/225 [00:00<?, ?it/s]/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 1/225 [00:17<1:06:30, 17.81s/it]  1%|          | 2/225 [00:18<28:00,  7.54s/it]    1%|‚ñè         | 3/225 [00:18<15:59,  4.32s/it]  2%|‚ñè         | 4/225 [00:18<10:02,  2.73s/it]  2%|‚ñè         | 5/225 [00:19<07:13,  1.97s/it]  3%|‚ñé         | 6/225 [00:19<05:14,  1.44s/it]  3%|‚ñé         | 7/225 [00:20<04:02,  1.11s/it]  4%|‚ñé         | 8/225 [00:20<03:08,  1.15it/s]  4%|‚ñç         | 9/225 [00:21<02:43,  1.32it/s]  4%|‚ñç         | 10/225 [00:21<02:23,  1.49it/s]  5%|‚ñç         | 11/225 [00:22<02:09,  1.65it/s]  5%|‚ñå         | 12/225 [00:22<01:53,  1.87it/s]  6%|‚ñå         | 13/225 [00:22<01:41,  2.08it/s]  6%|‚ñå         | 14/225 [00:23<01:27,  2.40it/s]  7%|‚ñã         | 15/225 [00:23<01:17,  2.70it/s]  7%|‚ñã         | 16/225 [00:23<01:11,  2.94it/s]  8%|‚ñä         | 17/225 [00:23<01:06,  3.14it/s]  8%|‚ñä         | 18/225 [00:24<01:03,  3.28it/s]  8%|‚ñä         | 19/225 [00:24<01:01,  3.37it/s]  9%|‚ñâ         | 20/225 [00:24<00:59,  3.45it/s]  9%|‚ñâ         | 21/225 [00:25<00:58,  3.49it/s] 10%|‚ñâ         | 22/225 [00:25<00:58,  3.48it/s] 10%|‚ñà         | 23/225 [00:25<00:57,  3.49it/s] 11%|‚ñà         | 24/225 [00:25<00:56,  3.55it/s] 11%|‚ñà         | 25/225 [00:26<00:56,  3.57it/s] 12%|‚ñà‚ñè        | 26/225 [00:26<00:56,  3.50it/s] 12%|‚ñà‚ñè        | 27/225 [00:26<00:56,  3.47it/s] 12%|‚ñà‚ñè        | 28/225 [00:27<00:56,  3.47it/s] 13%|‚ñà‚ñé        | 29/225 [00:27<00:56,  3.45it/s] 13%|‚ñà‚ñé        | 30/225 [00:27<01:08,  2.83it/s] 14%|‚ñà‚ñç        | 31/225 [00:28<01:29,  2.17it/s] 14%|‚ñà‚ñç        | 32/225 [00:29<01:40,  1.92it/s] 15%|‚ñà‚ñç        | 33/225 [00:30<01:52,  1.71it/s] 15%|‚ñà‚ñå        | 34/225 [00:30<02:05,  1.52it/s] 16%|‚ñà‚ñå        | 35/225 [00:31<01:47,  1.77it/s] 16%|‚ñà‚ñå        | 36/225 [00:31<01:41,  1.87it/s] 16%|‚ñà‚ñã        | 37/225 [00:32<01:30,  2.07it/s] 17%|‚ñà‚ñã        | 38/225 [00:32<01:28,  2.11it/s] 17%|‚ñà‚ñã        | 39/225 [00:32<01:17,  2.40it/s] 18%|‚ñà‚ñä        | 40/225 [00:33<01:23,  2.22it/s] 18%|‚ñà‚ñä        | 41/225 [00:33<01:37,  1.89it/s] 19%|‚ñà‚ñä        | 42/225 [00:34<01:23,  2.20it/s] 19%|‚ñà‚ñâ        | 43/225 [00:34<01:24,  2.14it/s] 20%|‚ñà‚ñâ        | 44/225 [00:35<01:18,  2.29it/s] 20%|‚ñà‚ñà        | 45/225 [00:35<01:17,  2.31it/s] 20%|‚ñà‚ñà        | 46/225 [00:35<01:16,  2.35it/s] 21%|‚ñà‚ñà        | 47/225 [00:36<01:19,  2.23it/s] 21%|‚ñà‚ñà‚ñè       | 48/225 [00:36<01:16,  2.32it/s] 22%|‚ñà‚ñà‚ñè       | 49/225 [00:37<01:17,  2.28it/s] 22%|‚ñà‚ñà‚ñè       | 50/225 [00:37<01:18,  2.23it/s] 23%|‚ñà‚ñà‚ñé       | 51/225 [00:38<01:15,  2.31it/s] 23%|‚ñà‚ñà‚ñé       | 52/225 [00:38<01:14,  2.33it/s] 24%|‚ñà‚ñà‚ñé       | 53/225 [00:38<01:11,  2.41it/s] 24%|‚ñà‚ñà‚ñç       | 54/225 [00:39<01:09,  2.45it/s] 24%|‚ñà‚ñà‚ñç       | 55/225 [00:39<01:08,  2.49it/s] 25%|‚ñà‚ñà‚ñç       | 56/225 [00:40<01:09,  2.42it/s] 25%|‚ñà‚ñà‚ñå       | 57/225 [00:40<01:08,  2.45it/s] 26%|‚ñà‚ñà‚ñå       | 58/225 [00:41<01:09,  2.41it/s] 26%|‚ñà‚ñà‚ñå       | 59/225 [00:41<01:05,  2.54it/s] 27%|‚ñà‚ñà‚ñã       | 60/225 [00:41<01:07,  2.46it/s] 27%|‚ñà‚ñà‚ñã       | 61/225 [00:42<01:08,  2.39it/s] 28%|‚ñà‚ñà‚ñä       | 62/225 [00:42<01:09,  2.36it/s] 28%|‚ñà‚ñà‚ñä       | 63/225 [00:43<01:08,  2.35it/s] 28%|‚ñà‚ñà‚ñä       | 64/225 [00:43<01:24,  1.90it/s] 29%|‚ñà‚ñà‚ñâ       | 65/225 [00:44<01:38,  1.63it/s] 29%|‚ñà‚ñà‚ñâ       | 66/225 [00:45<01:53,  1.40it/s] 30%|‚ñà‚ñà‚ñâ       | 67/225 [00:46<01:58,  1.34it/s] 30%|‚ñà‚ñà‚ñà       | 68/225 [00:47<01:54,  1.37it/s] 31%|‚ñà‚ñà‚ñà       | 69/225 [00:47<01:39,  1.56it/s] 31%|‚ñà‚ñà‚ñà       | 70/225 [00:48<01:29,  1.72it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 71/225 [00:48<01:22,  1.87it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 72/225 [00:48<01:16,  2.01it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 73/225 [00:49<01:25,  1.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 74/225 [00:50<01:20,  1.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 75/225 [00:50<01:15,  2.00it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 76/225 [00:50<01:15,  1.99it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 77/225 [00:51<01:08,  2.16it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 78/225 [00:51<01:04,  2.28it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 79/225 [00:52<01:02,  2.35it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 80/225 [00:52<00:55,  2.59it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 81/225 [00:52<01:00,  2.39it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 82/225 [00:53<01:01,  2.34it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 83/225 [00:53<01:00,  2.33it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 84/225 [00:54<00:58,  2.41it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 85/225 [00:54<01:03,  2.22it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 86/225 [00:55<00:59,  2.33it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 87/225 [00:55<01:01,  2.23it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 88/225 [00:56<01:00,  2.26it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 89/225 [00:56<00:58,  2.34it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 90/225 [00:56<00:52,  2.56it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 91/225 [00:57<00:56,  2.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 92/225 [00:57<00:52,  2.52it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 93/225 [00:57<00:54,  2.41it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 94/225 [00:58<00:53,  2.46it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 95/225 [00:58<00:52,  2.48it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 96/225 [00:59<00:50,  2.54it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 97/225 [00:59<00:50,  2.53it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 98/225 [00:59<00:49,  2.58it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 99/225 [01:00<01:00,  2.09it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 100/225 [01:01<01:11,  1.75it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 101/225 [01:02<01:16,  1.61it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 102/225 [01:03<01:30,  1.37it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 103/225 [01:03<01:22,  1.48it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 104/225 [01:04<01:16,  1.59it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 105/225 [01:04<01:17,  1.56it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 106/225 [01:05<01:04,  1.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 107/225 [01:05<01:00,  1.94it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 108/225 [01:06<00:56,  2.08it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 109/225 [01:06<00:51,  2.25it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 110/225 [01:06<00:48,  2.39it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 111/225 [01:07<00:47,  2.39it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 112/225 [01:07<00:45,  2.47it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 113/225 [01:07<00:45,  2.49it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 114/225 [01:08<00:45,  2.43it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 115/225 [01:08<00:42,  2.59it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 116/225 [01:09<00:45,  2.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 117/225 [01:09<00:42,  2.57it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 118/225 [01:09<00:40,  2.65it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 119/225 [01:10<00:42,  2.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 120/225 [01:10<00:40,  2.58it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 121/225 [01:10<00:36,  2.83it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 122/225 [01:11<00:34,  3.00it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 123/225 [01:11<00:32,  3.17it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 124/225 [01:11<00:30,  3.31it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 125/225 [01:12<00:29,  3.39it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 126/225 [01:12<00:28,  3.44it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 127/225 [01:12<00:27,  3.54it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 128/225 [01:12<00:27,  3.56it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 129/225 [01:13<00:26,  3.60it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 130/225 [01:13<00:26,  3.65it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 131/225 [01:13<00:25,  3.63it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 132/225 [01:13<00:25,  3.60it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 133/225 [01:14<00:26,  3.51it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 134/225 [01:14<00:26,  3.40it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 135/225 [01:14<00:26,  3.45it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 136/225 [01:15<00:25,  3.43it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 137/225 [01:15<00:29,  3.02it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 138/225 [01:15<00:27,  3.13it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 139/225 [01:16<00:30,  2.81it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 140/225 [01:17<00:44,  1.93it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 141/225 [01:18<00:52,  1.61it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 142/225 [01:19<01:00,  1.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 143/225 [01:19<00:57,  1.42it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 144/225 [01:20<00:49,  1.65it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 145/225 [01:20<00:44,  1.82it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 146/225 [01:20<00:38,  2.03it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 147/225 [01:21<00:37,  2.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 148/225 [01:21<00:36,  2.09it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 149/225 [01:22<00:34,  2.23it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 150/225 [01:22<00:29,  2.52it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 151/225 [01:23<00:33,  2.22it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 152/225 [01:23<00:30,  2.43it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 153/225 [01:23<00:30,  2.35it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 154/225 [01:24<00:29,  2.42it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 155/225 [01:24<00:29,  2.35it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 156/225 [01:24<00:28,  2.46it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 157/225 [01:25<00:29,  2.34it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 158/225 [01:25<00:25,  2.59it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 159/225 [01:26<00:28,  2.34it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 160/225 [01:26<00:27,  2.38it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 161/225 [01:27<00:27,  2.35it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 162/225 [01:27<00:24,  2.55it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 163/225 [01:27<00:26,  2.35it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 164/225 [01:28<00:23,  2.60it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 165/225 [01:28<00:25,  2.39it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 166/225 [01:29<00:23,  2.56it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 167/225 [01:29<00:24,  2.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 168/225 [01:29<00:24,  2.33it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 169/225 [01:30<00:24,  2.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 170/225 [01:30<00:25,  2.13it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 171/225 [01:31<00:23,  2.29it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 172/225 [01:31<00:23,  2.23it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 173/225 [01:32<00:22,  2.28it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 174/225 [01:32<00:26,  1.91it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 175/225 [01:33<00:30,  1.62it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 176/225 [01:34<00:28,  1.70it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 177/225 [01:35<00:34,  1.39it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 178/225 [01:36<00:33,  1.41it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 179/225 [01:36<00:29,  1.56it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 180/225 [01:36<00:24,  1.84it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 181/225 [01:37<00:23,  1.91it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 182/225 [01:37<00:20,  2.13it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 183/225 [01:38<00:20,  2.04it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 184/225 [01:38<00:17,  2.33it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 185/225 [01:39<00:19,  2.10it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 186/225 [01:39<00:17,  2.20it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 187/225 [01:39<00:17,  2.22it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 188/225 [01:40<00:16,  2.19it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 189/225 [01:40<00:15,  2.27it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 190/225 [01:41<00:14,  2.43it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 191/225 [01:41<00:14,  2.31it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 192/225 [01:41<00:13,  2.51it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 193/225 [01:42<00:13,  2.34it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 194/225 [01:42<00:13,  2.37it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 195/225 [01:43<00:12,  2.31it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 196/225 [01:43<00:11,  2.49it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 197/225 [01:44<00:11,  2.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 198/225 [01:44<00:11,  2.43it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 199/225 [01:44<00:11,  2.36it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 200/225 [01:45<00:10,  2.36it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 201/225 [01:45<00:10,  2.37it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 202/225 [01:46<00:09,  2.47it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 203/225 [01:46<00:08,  2.48it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 204/225 [01:46<00:08,  2.52it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 205/225 [01:47<00:08,  2.28it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 206/225 [01:47<00:08,  2.25it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 207/225 [01:48<00:08,  2.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 208/225 [01:49<00:10,  1.61it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 209/225 [01:50<00:10,  1.57it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 210/225 [01:50<00:10,  1.44it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 211/225 [01:51<00:10,  1.37it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 212/225 [01:52<00:08,  1.51it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 213/225 [01:52<00:07,  1.58it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 214/225 [01:53<00:05,  1.89it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 215/225 [01:53<00:05,  1.81it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 216/225 [01:54<00:04,  2.05it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 217/225 [01:54<00:03,  2.05it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 218/225 [01:54<00:03,  2.18it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 219/225 [01:55<00:02,  2.29it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 220/225 [01:55<00:02,  2.46it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 221/225 [01:56<00:01,  2.37it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 222/225 [01:56<00:01,  2.48it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 223/225 [01:56<00:00,  2.48it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 224/225 [01:57<00:00,  2.49it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:57<00:00,  2.60it/s][INFO|trainer.py:1409] 2021-11-26 16:15:23,847 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 {'train_runtime': 130.5048, 'train_samples_per_second': 220.26, 'train_steps_per_second': 1.724, 'train_loss': 3.131396484375, 'epoch': 5.0}100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:57<00:00,  2.60it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:57<00:00,  1.91it/s]
[INFO|trainer.py:1995] 2021-11-26 16:15:23,967 >> Saving model checkpoint to ./models/stsb/exit12
[INFO|configuration_utils.py:417] 2021-11-26 16:15:23,970 >> Configuration saved in ./models/stsb/exit12/config.json
[INFO|modeling_utils.py:1058] 2021-11-26 16:15:30,551 >> Model weights saved in ./models/stsb/exit12/pytorch_model.bin
[INFO|tokenization_utils_base.py:2034] 2021-11-26 16:15:30,555 >> tokenizer config file saved in ./models/stsb/exit12/tokenizer_config.json
[INFO|tokenization_utils_base.py:2040] 2021-11-26 16:15:30,558 >> Special tokens file saved in ./models/stsb/exit12/special_tokens_map.json
***** train metrics *****
  epoch                    =        5.0
  train_loss               =     3.1314
  train_runtime            = 0:02:10.50
  train_samples            =       5749
  train_samples_per_second =     220.26
  train_steps_per_second   =      1.724

11/26/2021 16:15:30 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:541] 2021-11-26 16:15:30,728 >> The following columns in the evaluation set  don't have a corresponding argument in `BertWithSinglehead.forward` and have been ignored: sentence2, idx, sentence1.
[INFO|trainer.py:2243] 2021-11-26 16:15:30,735 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2021-11-26 16:15:30,735 >>   Num examples = 1500
[INFO|trainer.py:2248] 2021-11-26 16:15:30,735 >>   Batch size = 32
  0%|          | 0/47 [00:00<?, ?it/s]  4%|‚ñç         | 2/47 [00:00<00:02, 19.20it/s]  9%|‚ñä         | 4/47 [00:00<00:03, 12.43it/s] 13%|‚ñà‚ñé        | 6/47 [00:01<00:10,  3.83it/s] 17%|‚ñà‚ñã        | 8/47 [00:01<00:07,  5.08it/s] 19%|‚ñà‚ñâ        | 9/47 [00:01<00:06,  5.69it/s] 21%|‚ñà‚ñà‚ñè       | 10/47 [00:01<00:05,  6.32it/s] 23%|‚ñà‚ñà‚ñé       | 11/47 [00:01<00:05,  6.92it/s] 26%|‚ñà‚ñà‚ñå       | 12/47 [00:01<00:04,  7.54it/s] 28%|‚ñà‚ñà‚ñä       | 13/47 [00:02<00:06,  5.25it/s] 30%|‚ñà‚ñà‚ñâ       | 14/47 [00:02<00:05,  5.69it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 15/47 [00:02<00:04,  6.43it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 16/47 [00:02<00:04,  6.96it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 17/47 [00:02<00:05,  5.42it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 18/47 [00:02<00:04,  5.93it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 19/47 [00:03<00:04,  6.64it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 21/47 [00:03<00:04,  5.71it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 22/47 [00:03<00:04,  5.92it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 23/47 [00:03<00:03,  6.62it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 24/47 [00:03<00:03,  7.28it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 25/47 [00:04<00:04,  5.44it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 26/47 [00:04<00:03,  6.18it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 27/47 [00:04<00:02,  6.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 28/47 [00:04<00:02,  7.49it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 29/47 [00:04<00:02,  7.78it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 30/47 [00:04<00:03,  5.63it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 31/47 [00:05<00:02,  5.51it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 32/47 [00:05<00:02,  6.01it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 33/47 [00:05<00:02,  6.49it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 34/47 [00:05<00:02,  4.51it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 35/47 [00:05<00:02,  5.28it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 36/47 [00:05<00:01,  6.07it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 37/47 [00:06<00:01,  6.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 38/47 [00:06<00:01,  5.21it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 39/47 [00:06<00:01,  5.87it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 40/47 [00:06<00:01,  6.37it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 41/47 [00:06<00:00,  6.94it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 42/47 [00:07<00:00,  5.02it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 43/47 [00:07<00:00,  5.76it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 44/47 [00:07<00:00,  6.48it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 45/47 [00:07<00:00,  7.15it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 46/47 [00:07<00:00,  7.70it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:07<00:00,  7.95it/s]11/26/2021 16:15:38 - INFO - datasets.metric - Removing /home/slzhang/.cache/huggingface/metrics/glue/stsb/default_experiment-1-0.arrow
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:07<00:00,  6.16it/s]
***** eval metrics *****
  epoch                   =        5.0
  eval_combined_score     =     0.6204
  eval_loss               =     1.6782
  eval_pearson            =     0.5909
  eval_runtime            = 0:00:07.72
  eval_samples            =       1500
  eval_samples_per_second =    194.293
  eval_spearmanr          =       0.65
  eval_steps_per_second   =      6.088
wandb: Waiting for W&B process to finish, PID 3602835
wandb: Program ended successfully.
wandb: - 0.06MB of 0.06MB uploaded (0.00MB deduped)wandb: \ 0.06MB of 0.10MB uploaded (0.00MB deduped)wandb: | 0.08MB of 0.10MB uploaded (0.00MB deduped)wandb: / 0.09MB of 0.10MB uploaded (0.00MB deduped)wandb: - 0.09MB of 0.10MB uploaded (0.00MB deduped)wandb: \ 0.10MB of 0.10MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_161319-10icjd38/logs/debug.log
wandb: Find internal logs for this run at: /home/slzhang/projects/ETBA/Train/bert_train/wandb/run-20211126_161319-10icjd38/logs/debug-internal.log
wandb: Run summary:
wandb:              train/train_runtime 130.5048
wandb:   train/train_samples_per_second 220.26
wandb:     train/train_steps_per_second 1.724
wandb:                 train/total_flos 1890764845013760.0
wandb:                 train/train_loss 3.1314
wandb:                      train/epoch 5.0
wandb:                train/global_step 225
wandb:                         _runtime 139
wandb:                       _timestamp 1637914538
wandb:                            _step 1
wandb:                        eval/loss 1.67823
wandb:                     eval/pearson 0.5909
wandb:                   eval/spearmanr 0.64996
wandb:              eval/combined_score 0.62043
wandb:                     eval/runtime 7.7203
wandb:          eval/samples_per_second 194.293
wandb:            eval/steps_per_second 6.088
wandb: Run history:
wandb:              train/train_runtime ‚ñÅ
wandb:   train/train_samples_per_second ‚ñÅ
wandb:     train/train_steps_per_second ‚ñÅ
wandb:                 train/total_flos ‚ñÅ
wandb:                 train/train_loss ‚ñÅ
wandb:                      train/epoch ‚ñÅ‚ñÅ
wandb:                train/global_step ‚ñÅ‚ñÅ
wandb:                         _runtime ‚ñÅ‚ñà
wandb:                       _timestamp ‚ñÅ‚ñà
wandb:                            _step ‚ñÅ‚ñà
wandb:                        eval/loss ‚ñÅ
wandb:                     eval/pearson ‚ñÅ
wandb:                   eval/spearmanr ‚ñÅ
wandb:              eval/combined_score ‚ñÅ
wandb:                     eval/runtime ‚ñÅ
wandb:          eval/samples_per_second ‚ñÅ
wandb:            eval/steps_per_second ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced ./models/stsb/exit12: https://wandb.ai/zsl/huggingface/runs/10icjd38

